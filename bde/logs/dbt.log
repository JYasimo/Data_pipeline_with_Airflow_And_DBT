[0m12:09:15.512160 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type



WITH sorted_listing AS (
    SELECT 
        prop.property_type,
        room.room_type,
        list.accommodates,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
SELECT 
    property_type,
    room_type,
    accommodates,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,



    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:09:15.516501 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:15.516788 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:09:15.517116 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    

WITH Calculations AS (
  SELECT
    sub.Local_Government_Area,
    DATE_TRUNC('month', list.scraped_date) AS month_year,
    COUNT(DISTINCT host.host_id) AS number_of_distinct_host,
    SUM(CASE WHEN list.has_availability = 't' THEN (30 - list.availability_30) * list.price END) AS Estimated_Revenue
  FROM warehouse.dim_host host
  JOIN warehouse.dim_SUBURB sub ON host.host_neighbourhood = sub.Local_Government_Area_SUBURB
  JOIN warehouse.fact_listing list ON list.surrogate_key_host = host.surrogate_key_host
  GROUP BY sub.Local_Government_Area, month_year
)

SELECT
  Local_Government_Area,
  month_year,
  number_of_distinct_host,
  Estimated_Revenue,
  CASE WHEN number_of_distinct_host > 0 THEN Estimated_Revenue / number_of_distinct_host ELSE 0 END AS Estimated_revenue_per_host
FROM Calculations
  );
  
[0m12:09:15.518652 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:15.518924 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:09:15.519391 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:09:15.549767 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:09:15.555210 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:09:15.555580 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:09:15.566246 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:15.568313 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:09:15.568589 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:09:15.579403 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:15.591264 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:09:15.591565 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:09:15.591817 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:09:15.603264 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:15.608651 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:09:15.608920 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:09:15.621220 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:09:15.622246 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:09:15.388062 => 12:09:15.622122
[0m12:09:15.622516 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:09:15.623143 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e877f0>]}
[0m12:09:15.623587 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.29s]
[0m12:09:15.624019 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:09:15.624307 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m12:09:15.624678 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:09:15.625198 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m12:09:15.625454 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m12:09:15.627699 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:09:15.628250 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 12:09:15.625642 => 12:09:15.628139
[0m12:09:15.628493 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m12:09:15.631119 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:09:15.631564 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:09:15.631795 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m12:09:15.632005 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:09:15.748022 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:15.748524 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:09:15.748934 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:09:15.763134 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:09:15.766000 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:09:15.766305 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:09:15.775047 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:15.777328 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:09:15.777643 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:09:15.787911 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:15.789394 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:09:15.789728 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:09:15.790019 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:09:15.799413 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:15.802988 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:09:15.803333 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:09:15.816097 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:09:15.817416 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 12:09:15.628654 => 12:09:15.817243
[0m12:09:15.817793 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m12:09:15.818640 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e09f60>]}
[0m12:09:15.819201 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.19s]
[0m12:09:15.819712 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m12:09:15.820072 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m12:09:15.820558 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:09:15.821253 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m12:09:15.821615 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m12:09:15.824756 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:09:15.825608 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 12:09:15.821879 => 12:09:15.825445
[0m12:09:15.825943 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m12:09:15.829114 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:09:15.829649 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:09:15.829927 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m12:09:15.830193 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:09:15.862233 [debug] [Thread-1 (]: SQL status: SELECT 207 in 0.0 seconds
[0m12:09:15.865215 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:09:15.865553 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m12:09:15.875804 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:15.878198 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:09:15.878523 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m12:09:15.892401 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:15.896630 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:09:15.896962 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:09:15.897252 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:09:15.908429 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:15.911953 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:09:15.912284 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m12:09:15.930834 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:15.932172 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:09:15.383582 => 12:09:15.932000
[0m12:09:15.932542 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:09:15.933302 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e219c0>]}
[0m12:09:15.933872 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 207[0m in 0.60s]
[0m12:09:15.934433 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:09:15.934828 [debug] [Thread-1 (]: Began running node model.bde.stg_fact
[0m12:09:15.935231 [info ] [Thread-1 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:09:15.935798 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.stg_fact)
[0m12:09:15.936085 [debug] [Thread-1 (]: Began compiling node model.bde.stg_fact
[0m12:09:15.938686 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:09:15.939001 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:15.939369 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:09:15.939721 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:09:15.940249 [debug] [Thread-1 (]: Timing info for model.bde.stg_fact (compile): 12:09:15.936288 => 12:09:15.940115
[0m12:09:15.940557 [debug] [Thread-1 (]: Began executing node model.bde.stg_fact
[0m12:09:15.943540 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:09:15.944029 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:09:15.944284 [debug] [Thread-1 (]: On model.bde.stg_fact: BEGIN
[0m12:09:15.944512 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:09:15.951470 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:09:15.955000 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:09:15.955454 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:09:15.965284 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:15.967327 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:09:15.967621 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:09:15.976748 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:15.977650 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:09:15.977957 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:09:15.978144 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:09:15.987837 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:15.989285 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:09:15.989503 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:09:16.003353 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:09:16.004219 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 12:09:15.826145 => 12:09:16.004117
[0m12:09:16.005124 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m12:09:16.005642 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109bf2560>]}
[0m12:09:16.006003 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.18s]
[0m12:09:16.007850 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m12:09:16.008113 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m12:09:16.008504 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:09:16.008940 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_host)
[0m12:09:16.009201 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m12:09:16.011205 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:09:16.011709 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 12:09:16.009358 => 12:09:16.011605
[0m12:09:16.011922 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m12:09:16.014174 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:09:16.014544 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:09:16.014732 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m12:09:16.014909 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:09:16.047022 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:16.047359 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:09:16.047700 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:09:16.071107 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:09:16.073523 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:09:16.073823 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:09:16.083123 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.085037 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:09:16.085278 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:09:16.095879 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.097064 [debug] [Thread-1 (]: On model.bde.stg_fact: COMMIT
[0m12:09:16.097329 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:09:16.097563 [debug] [Thread-1 (]: On model.bde.stg_fact: COMMIT
[0m12:09:16.108686 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:16.110471 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:09:16.110966 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:09:16.123565 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:09:16.124715 [debug] [Thread-1 (]: Timing info for model.bde.stg_fact (execute): 12:09:15.940758 => 12:09:16.124583
[0m12:09:16.125004 [debug] [Thread-1 (]: On model.bde.stg_fact: Close
[0m12:09:16.125651 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e65150>]}
[0m12:09:16.126115 [info ] [Thread-1 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.19s]
[0m12:09:16.126532 [debug] [Thread-1 (]: Finished running node model.bde.stg_fact
[0m12:09:16.126828 [debug] [Thread-1 (]: Began running node model.bde.stg_property
[0m12:09:16.127274 [info ] [Thread-1 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:09:16.127767 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_property)
[0m12:09:16.128026 [debug] [Thread-1 (]: Began compiling node model.bde.stg_property
[0m12:09:16.130434 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:09:16.131040 [debug] [Thread-1 (]: Timing info for model.bde.stg_property (compile): 12:09:16.128197 => 12:09:16.130917
[0m12:09:16.131284 [debug] [Thread-1 (]: Began executing node model.bde.stg_property
[0m12:09:16.162869 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:16.164152 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:09:16.164444 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:09:16.164821 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:09:16.165267 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:09:16.165462 [debug] [Thread-1 (]: On model.bde.stg_property: BEGIN
[0m12:09:16.165638 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:09:16.181138 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:09:16.183190 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:09:16.183411 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:09:16.192178 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.193717 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:09:16.193945 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:09:16.204061 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.205013 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:09:16.205230 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:09:16.205425 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:09:16.217029 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:16.218686 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:09:16.218926 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:09:16.258220 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:09:16.259315 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 12:09:16.012064 => 12:09:16.259178
[0m12:09:16.259629 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m12:09:16.260279 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109eedb40>]}
[0m12:09:16.260762 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.25s]
[0m12:09:16.261219 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m12:09:16.261540 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m12:09:16.262005 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:09:16.262469 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_room)
[0m12:09:16.262718 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m12:09:16.264868 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:09:16.265387 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 12:09:16.262894 => 12:09:16.265272
[0m12:09:16.265635 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m12:09:16.268799 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:09:16.269498 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:09:16.269803 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m12:09:16.270054 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:09:16.300200 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:16.300600 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:09:16.300940 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:09:16.318427 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:09:16.320982 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:09:16.321296 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:09:16.335573 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.337628 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:09:16.337910 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:09:16.347030 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.348411 [debug] [Thread-1 (]: On model.bde.stg_property: COMMIT
[0m12:09:16.348708 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:09:16.348960 [debug] [Thread-1 (]: On model.bde.stg_property: COMMIT
[0m12:09:16.358677 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:16.361845 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:09:16.362145 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:09:16.372892 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:09:16.373946 [debug] [Thread-1 (]: Timing info for model.bde.stg_property (execute): 12:09:16.131457 => 12:09:16.373801
[0m12:09:16.374250 [debug] [Thread-1 (]: On model.bde.stg_property: Close
[0m12:09:16.374894 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f1a9b0>]}
[0m12:09:16.375360 [info ] [Thread-1 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.25s]
[0m12:09:16.375820 [debug] [Thread-1 (]: Finished running node model.bde.stg_property
[0m12:09:16.376134 [debug] [Thread-1 (]: Began running node model.bde.stg_suburb
[0m12:09:16.376562 [info ] [Thread-1 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:09:16.377135 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_suburb)
[0m12:09:16.377426 [debug] [Thread-1 (]: Began compiling node model.bde.stg_suburb
[0m12:09:16.379494 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:09:16.380076 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (compile): 12:09:16.377611 => 12:09:16.379949
[0m12:09:16.380350 [debug] [Thread-1 (]: Began executing node model.bde.stg_suburb
[0m12:09:16.383167 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:09:16.383627 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:09:16.383877 [debug] [Thread-1 (]: On model.bde.stg_suburb: BEGIN
[0m12:09:16.384108 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:09:16.384687 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:16.384931 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:09:16.385206 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:09:16.398904 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:09:16.401251 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:09:16.401523 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:09:16.411883 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.413902 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:09:16.414175 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:09:16.424712 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.425877 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:09:16.426153 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:09:16.426388 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:09:16.440697 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:16.442595 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:09:16.442889 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:09:16.455424 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:09:16.456429 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 12:09:16.265809 => 12:09:16.456294
[0m12:09:16.456716 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m12:09:16.457345 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d53550>]}
[0m12:09:16.457801 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.20s]
[0m12:09:16.458253 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m12:09:16.458582 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m12:09:16.459060 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:09:16.459633 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.dim_LGA)
[0m12:09:16.459928 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m12:09:16.462370 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:09:16.462964 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 12:09:16.460125 => 12:09:16.462828
[0m12:09:16.463248 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m12:09:16.466076 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:09:16.466511 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:09:16.466773 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m12:09:16.467016 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:09:16.496131 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:16.496523 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:09:16.496782 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:09:16.511056 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:09:16.514793 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:09:16.515079 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:09:16.524167 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.526159 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:09:16.526421 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:09:16.545204 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.546388 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:09:16.546660 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:09:16.546896 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:09:16.556411 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:16.558224 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:09:16.558515 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:09:16.569766 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:09:16.570817 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (execute): 12:09:16.380539 => 12:09:16.570679
[0m12:09:16.571108 [debug] [Thread-1 (]: On model.bde.stg_suburb: Close
[0m12:09:16.571764 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ea25c0>]}
[0m12:09:16.572253 [info ] [Thread-1 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.19s]
[0m12:09:16.572711 [debug] [Thread-1 (]: Finished running node model.bde.stg_suburb
[0m12:09:16.573021 [debug] [Thread-1 (]: Began running node model.bde.fact_G01
[0m12:09:16.573453 [info ] [Thread-1 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:09:16.574035 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.fact_G01)
[0m12:09:16.574362 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G01
[0m12:09:16.576945 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:09:16.577555 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (compile): 12:09:16.574570 => 12:09:16.577424
[0m12:09:16.577813 [debug] [Thread-1 (]: Began executing node model.bde.fact_G01
[0m12:09:16.580524 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:09:16.580791 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:16.581081 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:09:16.581327 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:09:16.581562 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:09:16.581954 [debug] [Thread-1 (]: On model.bde.fact_G01: BEGIN
[0m12:09:16.582172 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:09:16.598402 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:09:16.600524 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:09:16.600785 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:09:16.610211 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.612014 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:09:16.612285 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:09:16.621806 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.622915 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:09:16.623147 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:09:16.623358 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:09:16.635180 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:16.636865 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:09:16.637116 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:09:16.654069 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:16.655156 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 12:09:16.463446 => 12:09:16.655015
[0m12:09:16.655455 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m12:09:16.656211 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081e44f0>]}
[0m12:09:16.656721 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.20s]
[0m12:09:16.657178 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m12:09:16.657523 [debug] [Thread-4 (]: Began running node model.bde.fact_G02
[0m12:09:16.657929 [info ] [Thread-4 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:09:16.658440 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G02)
[0m12:09:16.658704 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G02
[0m12:09:16.661263 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:09:16.661946 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (compile): 12:09:16.658884 => 12:09:16.661822
[0m12:09:16.662203 [debug] [Thread-4 (]: Began executing node model.bde.fact_G02
[0m12:09:16.667244 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:09:16.668069 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:09:16.668418 [debug] [Thread-4 (]: On model.bde.fact_G02: BEGIN
[0m12:09:16.668671 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:09:16.687123 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:16.687441 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:09:16.687693 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:09:16.718540 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:09:16.721507 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:09:16.721834 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:09:16.733090 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.735493 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:09:16.735822 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:09:16.746834 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.748423 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:09:16.748720 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:09:16.748982 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:09:16.758727 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:16.760771 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:09:16.761074 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:09:16.780316 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:16.781540 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (execute): 12:09:16.577987 => 12:09:16.781376
[0m12:09:16.781928 [debug] [Thread-1 (]: On model.bde.fact_G01: Close
[0m12:09:16.782694 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e58100>]}
[0m12:09:16.783242 [info ] [Thread-1 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.21s]
[0m12:09:16.783762 [debug] [Thread-1 (]: Finished running node model.bde.fact_G01
[0m12:09:16.784097 [debug] [Thread-1 (]: Began running node model.bde.fact_listing
[0m12:09:16.784431 [info ] [Thread-1 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:09:16.785053 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_listing)
[0m12:09:16.785451 [debug] [Thread-1 (]: Began compiling node model.bde.fact_listing
[0m12:09:16.788157 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:09:16.788816 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (compile): 12:09:16.785652 => 12:09:16.788683
[0m12:09:16.789092 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:16.789383 [debug] [Thread-1 (]: Began executing node model.bde.fact_listing
[0m12:09:16.789658 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:09:16.793023 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:09:16.793357 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:09:16.793874 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:09:16.794114 [debug] [Thread-1 (]: On model.bde.fact_listing: BEGIN
[0m12:09:16.794346 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:09:16.819372 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:09:16.822058 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:09:16.822368 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:09:16.831126 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.833435 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:09:16.833758 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:09:16.869648 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:16.871324 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:09:16.871676 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:09:16.871970 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:09:16.882000 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:16.885983 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:09:16.886334 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:09:16.901959 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:16.903168 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (execute): 12:09:16.662381 => 12:09:16.903013
[0m12:09:16.903506 [debug] [Thread-4 (]: On model.bde.fact_G02: Close
[0m12:09:16.904255 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081e6290>]}
[0m12:09:16.904790 [info ] [Thread-4 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.25s]
[0m12:09:16.905310 [debug] [Thread-4 (]: Finished running node model.bde.fact_G02
[0m12:09:16.905685 [debug] [Thread-4 (]: Began running node model.bde.dim_host
[0m12:09:16.906164 [info ] [Thread-4 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:09:16.906765 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m12:09:16.907061 [debug] [Thread-4 (]: Began compiling node model.bde.dim_host
[0m12:09:16.909677 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:09:16.910440 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (compile): 12:09:16.907265 => 12:09:16.910267
[0m12:09:16.910764 [debug] [Thread-4 (]: Began executing node model.bde.dim_host
[0m12:09:16.913887 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:09:16.914397 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:09:16.914644 [debug] [Thread-4 (]: On model.bde.dim_host: BEGIN
[0m12:09:16.914870 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:09:16.930577 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:16.930885 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:09:16.931164 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:09:17.052285 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:17.052933 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:09:17.053469 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:09:17.778020 [debug] [Thread-4 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m12:09:17.786406 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:09:17.787133 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:09:19.682051 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m12:09:19.689954 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:09:19.690747 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:09:19.713784 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:19.718917 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:09:19.719476 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:09:19.738492 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:19.742576 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:09:19.743128 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:09:19.743570 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:09:19.784626 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:19.792030 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:09:19.793119 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:09:19.814789 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:19.819363 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:09:15.358193 => 12:09:19.819005
[0m12:09:19.820153 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:09:19.822020 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e46d10>]}
[0m12:09:19.823052 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 4.49s]
[0m12:09:19.823890 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:09:19.824678 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m12:09:19.825645 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:09:19.826723 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m12:09:19.827235 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m12:09:19.831588 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:09:19.832864 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 12:09:19.827575 => 12:09:19.832638
[0m12:09:19.833309 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m12:09:19.839413 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:09:19.840286 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:09:19.840627 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m12:09:19.840945 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:09:20.041152 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:20.042707 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:09:20.043391 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:09:20.313353 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 5.0 seconds
[0m12:09:20.321165 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:09:20.321959 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m12:09:20.342074 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:20.347304 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:09:20.347857 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m12:09:20.361760 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:20.365520 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:09:20.366026 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:09:20.366465 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:09:20.406681 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:20.407722 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 3.0 seconds
[0m12:09:20.414006 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:09:20.418003 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:09:20.418444 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m12:09:20.418859 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:09:20.435386 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:20.437859 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:09:20.438327 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:09:20.438756 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:09:20.453242 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:20.456338 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:09:20.456817 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:09:20.470556 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:20.473920 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:09:15.385871 => 12:09:20.473688
[0m12:09:20.474427 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:09:20.475689 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e0a980>]}
[0m12:09:20.476488 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 5.14s]
[0m12:09:20.477231 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:09:20.477660 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m12:09:20.478198 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:09:20.478924 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m12:09:20.479310 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m12:09:20.482795 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:09:20.483270 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:20.485318 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (execute): 12:09:16.910981 => 12:09:20.485119
[0m12:09:20.485922 [debug] [Thread-4 (]: On model.bde.dim_host: Close
[0m12:09:20.486356 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 12:09:20.479570 => 12:09:20.486194
[0m12:09:20.486765 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m12:09:20.487420 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fb28f0>]}
[0m12:09:20.491403 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:09:20.491933 [info ] [Thread-4 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 3.58s]
[0m12:09:20.492500 [debug] [Thread-4 (]: Finished running node model.bde.dim_host
[0m12:09:20.492869 [debug] [Thread-4 (]: Began running node model.bde.dim_suburb
[0m12:09:20.493174 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:09:20.493557 [info ] [Thread-4 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:09:20.493997 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m12:09:20.494560 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_host, now model.bde.dim_suburb)
[0m12:09:20.494871 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:09:20.495195 [debug] [Thread-4 (]: Began compiling node model.bde.dim_suburb
[0m12:09:20.497915 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:09:20.498488 [debug] [Thread-4 (]: Timing info for model.bde.dim_suburb (compile): 12:09:20.495546 => 12:09:20.498344
[0m12:09:20.498771 [debug] [Thread-4 (]: Began executing node model.bde.dim_suburb
[0m12:09:20.502986 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:09:20.503432 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:09:20.503678 [debug] [Thread-4 (]: On model.bde.dim_suburb: BEGIN
[0m12:09:20.503910 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:09:20.632582 [debug] [Thread-1 (]: SQL status: SELECT 340945 in 4.0 seconds
[0m12:09:20.633171 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m12:09:20.637130 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:09:20.640149 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:09:20.640536 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:09:20.640881 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:09:20.644462 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:20.644780 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:09:20.645079 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:09:20.645455 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:09:20.645811 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:09:20.646201 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:09:20.653958 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:20.656442 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:09:20.656759 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:20.657094 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:09:20.659634 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:09:20.660040 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:09:20.667710 [debug] [Thread-4 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:09:20.670378 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:09:20.670705 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:20.670984 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:20.671302 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:09:20.672901 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:09:20.674206 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:09:20.674547 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:09:20.674829 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:09:20.675102 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:09:20.675374 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:09:20.683042 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:20.685217 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:09:20.685586 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:09:20.692104 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:20.693932 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:09:20.694218 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:09:20.694571 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:20.697846 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:09:20.698172 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:09:20.734551 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:20.734911 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:20.736491 [debug] [Thread-4 (]: On model.bde.dim_suburb: COMMIT
[0m12:09:20.737493 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 12:09:19.833585 => 12:09:20.737360
[0m12:09:20.737771 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:09:20.738033 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m12:09:20.738275 [debug] [Thread-4 (]: On model.bde.dim_suburb: COMMIT
[0m12:09:20.739004 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e221d0>]}
[0m12:09:20.739470 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 0.91s]
[0m12:09:20.739907 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m12:09:20.751622 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:20.752655 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (execute): 12:09:16.789917 => 12:09:20.752536
[0m12:09:20.752919 [debug] [Thread-1 (]: On model.bde.fact_listing: Close
[0m12:09:20.753162 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:20.755300 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:09:20.755925 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f011db0>]}
[0m12:09:20.756330 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:09:20.756881 [info ] [Thread-1 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 3.97s]
[0m12:09:20.757480 [debug] [Thread-1 (]: Finished running node model.bde.fact_listing
[0m12:09:20.775617 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:20.776811 [debug] [Thread-4 (]: Timing info for model.bde.dim_suburb (execute): 12:09:20.498963 => 12:09:20.776687
[0m12:09:20.777088 [debug] [Thread-4 (]: On model.bde.dim_suburb: Close
[0m12:09:20.777716 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fdc850>]}
[0m12:09:20.778127 [info ] [Thread-4 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.28s]
[0m12:09:20.778533 [debug] [Thread-4 (]: Finished running node model.bde.dim_suburb
[0m12:09:20.820654 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:09:20.823561 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:09:20.823899 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:09:20.833683 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:20.835936 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:09:20.836246 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:09:20.845781 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:20.847208 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:09:20.847487 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:09:20.847888 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:09:20.873093 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:09:20.875315 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:09:20.875659 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:09:20.896018 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:20.897313 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 12:09:20.487671 => 12:09:20.897138
[0m12:09:20.897674 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m12:09:20.898457 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be021621-1984-43c8-a861-d0db438b3e3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fb2980>]}
[0m12:09:20.898994 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.42s]
[0m12:09:20.899507 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m12:09:20.901006 [debug] [MainThread]: Using postgres connection "master"
[0m12:09:20.901323 [debug] [MainThread]: On master: BEGIN
[0m12:09:20.901584 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:09:21.010985 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:09:21.012442 [debug] [MainThread]: On master: COMMIT
[0m12:09:21.013003 [debug] [MainThread]: Using postgres connection "master"
[0m12:09:21.014097 [debug] [MainThread]: On master: COMMIT
[0m12:09:21.023086 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:09:21.024275 [debug] [MainThread]: On master: Close
[0m12:09:21.028170 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:09:21.028620 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:09:21.028985 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m12:09:21.029344 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:09:21.029675 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:09:21.030214 [info ] [MainThread]: 
[0m12:09:21.030678 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 6.24 seconds (6.24s).
[0m12:09:21.034072 [debug] [MainThread]: Command end result
[0m12:09:21.044257 [info ] [MainThread]: 
[0m12:09:21.044661 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:09:21.044967 [info ] [MainThread]: 
[0m12:09:21.045270 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m12:09:21.045918 [debug] [MainThread]: Command `dbt run` succeeded at 12:09:21.045837 after 6.37 seconds
[0m12:09:21.046310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107430f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f89420>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109dbf190>]}
[0m12:09:21.046680 [debug] [MainThread]: Flushing usage events
[0m12:10:53.573202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d0d5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c65ae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c65420>]}


============================== 12:10:53.576103 | 1aa4a11c-99d1-4bc2-88cf-af995d4bf916 ==============================
[0m12:10:53.576103 [info ] [MainThread]: Running with dbt=1.6.6
[0m12:10:53.576448 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:10:53.631393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c65630>]}
[0m12:10:53.638915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070ad180>]}
[0m12:10:53.639271 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m12:10:53.648316 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m12:10:53.673715 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:10:53.673943 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:10:53.674567 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.raw
- models.bde.median
[0m12:10:53.677866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076380d0>]}
[0m12:10:53.684470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074cace0>]}
[0m12:10:53.684713 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m12:10:53.684891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074c80d0>]}
[0m12:10:53.686053 [info ] [MainThread]: 
[0m12:10:53.686439 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:10:53.687298 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:10:53.687722 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:10:53.688061 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:10:53.692845 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:10:53.693858 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:10:53.695060 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:10:53.695267 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:10:53.695461 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:10:53.695632 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:10:53.695782 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:10:53.695928 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:10:53.696065 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:10:53.859790 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:10:53.861022 [debug] [ThreadPool]: On list_postgres: Close
[0m12:10:53.869198 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:10:53.869888 [debug] [ThreadPool]: On list_postgres: Close
[0m12:10:53.903346 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:10:53.904349 [debug] [ThreadPool]: On list_postgres: Close
[0m12:10:53.906098 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_staging)
[0m12:10:53.906588 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m12:10:53.907012 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_warehouse)
[0m12:10:53.911079 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:10:53.911860 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_raw'
[0m12:10:53.913453 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:10:53.914709 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:10:53.914963 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m12:10:53.916097 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:10:53.916323 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m12:10:53.916500 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m12:10:53.916703 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:10:53.916896 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m12:10:53.917055 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:10:53.917211 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:10:53.917509 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:10:54.019705 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:10:54.020165 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:10:54.020442 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m12:10:54.035282 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:10:54.035552 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:10:54.035851 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:10:54.036096 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:10:54.036317 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:10:54.036588 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m12:10:54.036898 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m12:10:54.037141 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:10:54.037470 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m12:10:54.040652 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:10:54.041771 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m12:10:54.056594 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:10:54.056888 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m12:10:54.057142 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:10:54.057370 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:10:54.058398 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m12:10:54.059510 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m12:10:54.061608 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m12:10:54.069904 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m12:10:54.070164 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m12:10:54.071042 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m12:10:54.077656 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:54.077948 [debug] [MainThread]: On master: BEGIN
[0m12:10:54.078171 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:10:54.180961 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:10:54.181451 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:54.181922 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:10:54.207391 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:10:54.209900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074c8b20>]}
[0m12:10:54.210320 [debug] [MainThread]: On master: ROLLBACK
[0m12:10:54.220862 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:54.221210 [debug] [MainThread]: On master: BEGIN
[0m12:10:54.240390 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:10:54.240717 [debug] [MainThread]: On master: COMMIT
[0m12:10:54.240925 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:54.241123 [debug] [MainThread]: On master: COMMIT
[0m12:10:54.254080 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:10:54.254447 [debug] [MainThread]: On master: Close
[0m12:10:54.255119 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:10:54.255343 [info ] [MainThread]: 
[0m12:10:54.257341 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m12:10:54.257627 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m12:10:54.257871 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m12:10:54.258110 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m12:10:54.258468 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m12:10:54.258774 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m12:10:54.259177 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m12:10:54.259546 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m12:10:54.259959 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.dm_host_neighbourhod)
[0m12:10:54.260296 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_listing_neighbourhood)
[0m12:10:54.260640 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.dm_property_type)
[0m12:10:54.260960 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.stg_G01)
[0m12:10:54.261196 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m12:10:54.261409 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m12:10:54.261609 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m12:10:54.261793 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m12:10:54.266533 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m12:10:54.268615 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m12:10:54.271323 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m12:10:54.273182 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m12:10:54.274394 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 12:10:54.268871 => 12:10:54.274244
[0m12:10:54.274670 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 12:10:54.261943 => 12:10:54.274573
[0m12:10:54.274981 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 12:10:54.266722 => 12:10:54.274845
[0m12:10:54.275203 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m12:10:54.275417 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 12:10:54.271520 => 12:10:54.275327
[0m12:10:54.275631 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m12:10:54.275818 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m12:10:54.296132 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m12:10:54.296477 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m12:10:54.298519 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m12:10:54.300361 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m12:10:54.309748 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m12:10:54.310190 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:10:54.310499 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:10:54.310694 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m12:10:54.311012 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m12:10:54.311217 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:10:54.311390 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:10:54.311567 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:10:54.311738 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:10:54.311905 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m12:10:54.312071 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m12:10:54.312409 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:10:54.312599 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:10:54.420958 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:54.421330 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:54.421661 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:10:54.421953 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:10:54.422407 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m12:10:54.423027 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type



WITH sorted_listing AS (
    SELECT 
        prop.property_type,
        room.room_type,
        list.accommodates,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
SELECT 
    property_type,
    room_type,
    accommodates,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,



    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:10:54.437163 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:54.437446 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:10:54.437722 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    

WITH Calculations AS (
  SELECT
    sub.Local_Government_Area,
    DATE_TRUNC('month', list.scraped_date) AS month_year,
    COUNT(DISTINCT host.host_id) AS number_of_distinct_host,
    SUM(CASE WHEN list.has_availability = 't' THEN (30 - list.availability_30) * list.price END) AS Estimated_Revenue
  FROM warehouse.dim_host host
  JOIN warehouse.dim_SUBURB sub ON host.host_neighbourhood = sub.Local_Government_Area_SUBURB
  JOIN warehouse.fact_listing list ON list.surrogate_key_host = host.surrogate_key_host
  GROUP BY sub.Local_Government_Area, month_year
)

SELECT
  Local_Government_Area,
  month_year,
  number_of_distinct_host,
  Estimated_Revenue,
  CASE WHEN number_of_distinct_host > 0 THEN Estimated_Revenue / number_of_distinct_host ELSE 0 END AS Estimated_revenue_per_host
FROM Calculations
  );
  
[0m12:10:54.549043 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:54.549707 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:10:54.550413 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:10:54.580636 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:10:54.588768 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:10:54.589176 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:10:54.599618 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:54.602892 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:10:54.603325 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:10:54.614212 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:54.629123 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:10:54.629546 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:10:54.629837 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:10:54.655094 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:54.662191 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:10:54.662564 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:10:54.675371 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:10:54.676617 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:10:54.300589 => 12:10:54.676459
[0m12:10:54.676952 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:10:54.677686 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10775f880>]}
[0m12:10:54.678205 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.42s]
[0m12:10:54.678689 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:10:54.679017 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m12:10:54.679448 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:10:54.680039 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m12:10:54.680367 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m12:10:54.682887 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:10:54.683517 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 12:10:54.680577 => 12:10:54.683384
[0m12:10:54.683791 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m12:10:54.686593 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:10:54.687061 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:10:54.687307 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m12:10:54.687542 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:10:54.820222 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:54.820930 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:10:54.821576 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:10:54.837377 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:10:54.842083 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:10:54.842544 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:10:54.852476 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:54.856291 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:10:54.856725 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:10:54.869302 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:54.871474 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:10:54.871957 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:10:54.872379 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:10:54.884142 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:54.889295 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:10:54.889780 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:10:54.902092 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:10:54.903453 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 12:10:54.683969 => 12:10:54.903287
[0m12:10:54.903824 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m12:10:54.904662 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076ab040>]}
[0m12:10:54.905184 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.22s]
[0m12:10:54.905652 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m12:10:54.906045 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m12:10:54.906500 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:10:54.907058 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m12:10:54.907354 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m12:10:54.910024 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:10:54.911633 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 12:10:54.907558 => 12:10:54.911476
[0m12:10:54.911942 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m12:10:54.914789 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:10:54.915280 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:10:54.915523 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m12:10:54.915750 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:10:55.028298 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:55.028914 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:10:55.029384 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:10:55.043253 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:10:55.047061 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:10:55.047494 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:10:55.056820 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.059811 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:10:55.060228 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:10:55.068440 [debug] [Thread-1 (]: SQL status: SELECT 207 in 1.0 seconds
[0m12:10:55.071586 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:10:55.071995 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m12:10:55.072487 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.074315 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:10:55.074681 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:10:55.074999 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:10:55.081405 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.084287 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:10:55.084717 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m12:10:55.085171 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:55.087385 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:10:55.087705 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:10:55.094882 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.099938 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:10:55.100314 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:10:55.100645 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:10:55.114944 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:10:55.116182 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 12:10:54.912153 => 12:10:55.116019
[0m12:10:55.116522 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m12:10:55.117370 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076ab010>]}
[0m12:10:55.117992 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.21s]
[0m12:10:55.118548 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m12:10:55.118964 [debug] [Thread-4 (]: Began running node model.bde.stg_fact
[0m12:10:55.119600 [info ] [Thread-4 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:10:55.120547 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_fact)
[0m12:10:55.121051 [debug] [Thread-4 (]: Began compiling node model.bde.stg_fact
[0m12:10:55.125386 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:10:55.126072 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:55.129803 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:10:55.130163 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m12:10:55.130581 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (compile): 12:10:55.121318 => 12:10:55.130428
[0m12:10:55.130877 [debug] [Thread-4 (]: Began executing node model.bde.stg_fact
[0m12:10:55.133825 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:10:55.134269 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:10:55.134508 [debug] [Thread-4 (]: On model.bde.stg_fact: BEGIN
[0m12:10:55.134731 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:10:55.145311 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:10:55.146414 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:10:54.296658 => 12:10:55.146291
[0m12:10:55.146694 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:10:55.147340 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c8585e0>]}
[0m12:10:55.147787 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 207[0m in 0.89s]
[0m12:10:55.148193 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:10:55.148473 [debug] [Thread-1 (]: Began running node model.bde.stg_host
[0m12:10:55.148841 [info ] [Thread-1 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:10:55.149344 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.stg_host)
[0m12:10:55.149594 [debug] [Thread-1 (]: Began compiling node model.bde.stg_host
[0m12:10:55.151932 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:10:55.152959 [debug] [Thread-1 (]: Timing info for model.bde.stg_host (compile): 12:10:55.149764 => 12:10:55.152843
[0m12:10:55.153210 [debug] [Thread-1 (]: Began executing node model.bde.stg_host
[0m12:10:55.156013 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:10:55.156561 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_host"
[0m12:10:55.156783 [debug] [Thread-1 (]: On model.bde.stg_host: BEGIN
[0m12:10:55.156996 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:10:55.255421 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:55.255929 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:10:55.256368 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:10:55.258769 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:55.259104 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_host"
[0m12:10:55.259475 [debug] [Thread-1 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:10:55.277255 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:10:55.279968 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_host"
[0m12:10:55.280234 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:10:55.280518 [debug] [Thread-1 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:10:55.282805 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:10:55.283187 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:10:55.292995 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.294900 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_host"
[0m12:10:55.295153 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.295411 [debug] [Thread-1 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:10:55.297288 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:10:55.297600 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:10:55.306847 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.309194 [debug] [Thread-1 (]: On model.bde.stg_host: COMMIT
[0m12:10:55.309448 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.309697 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_host"
[0m12:10:55.310742 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:10:55.311000 [debug] [Thread-1 (]: On model.bde.stg_host: COMMIT
[0m12:10:55.311240 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:10:55.311526 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:10:55.322575 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:55.322799 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:55.350733 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_host"
[0m12:10:55.352254 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:10:55.352506 [debug] [Thread-1 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:10:55.352726 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:10:55.365329 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:10:55.366254 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (execute): 12:10:55.131072 => 12:10:55.366155
[0m12:10:55.366464 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:10:55.366742 [debug] [Thread-4 (]: On model.bde.stg_fact: Close
[0m12:10:55.367512 [debug] [Thread-1 (]: Timing info for model.bde.stg_host (execute): 12:10:55.153370 => 12:10:55.367419
[0m12:10:55.367764 [debug] [Thread-1 (]: On model.bde.stg_host: Close
[0m12:10:55.368174 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077925c0>]}
[0m12:10:55.368917 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c884a90>]}
[0m12:10:55.368583 [info ] [Thread-4 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.25s]
[0m12:10:55.369276 [info ] [Thread-1 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.22s]
[0m12:10:55.369586 [debug] [Thread-4 (]: Finished running node model.bde.stg_fact
[0m12:10:55.369852 [debug] [Thread-1 (]: Finished running node model.bde.stg_host
[0m12:10:55.370095 [debug] [Thread-4 (]: Began running node model.bde.stg_property
[0m12:10:55.370464 [debug] [Thread-1 (]: Began running node model.bde.stg_room
[0m12:10:55.370775 [info ] [Thread-4 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:10:55.371077 [info ] [Thread-1 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:10:55.371447 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_property)
[0m12:10:55.371757 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_room)
[0m12:10:55.371961 [debug] [Thread-4 (]: Began compiling node model.bde.stg_property
[0m12:10:55.372148 [debug] [Thread-1 (]: Began compiling node model.bde.stg_room
[0m12:10:55.374060 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:10:55.375912 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:10:55.377632 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (compile): 12:10:55.372288 => 12:10:55.377493
[0m12:10:55.377900 [debug] [Thread-1 (]: Timing info for model.bde.stg_room (compile): 12:10:55.374236 => 12:10:55.377792
[0m12:10:55.378113 [debug] [Thread-4 (]: Began executing node model.bde.stg_property
[0m12:10:55.378311 [debug] [Thread-1 (]: Began executing node model.bde.stg_room
[0m12:10:55.380554 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:10:55.382533 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:10:55.382918 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:10:55.383156 [debug] [Thread-4 (]: On model.bde.stg_property: BEGIN
[0m12:10:55.383348 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_room"
[0m12:10:55.383552 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:10:55.383737 [debug] [Thread-1 (]: On model.bde.stg_room: BEGIN
[0m12:10:55.384003 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:10:55.495486 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:55.495987 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:10:55.496273 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:55.496679 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:10:55.497036 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_room"
[0m12:10:55.497407 [debug] [Thread-1 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:10:55.512177 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:10:55.512462 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:10:55.515188 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_room"
[0m12:10:55.517408 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:10:55.517690 [debug] [Thread-1 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:10:55.517949 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:10:55.527413 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.530499 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_room"
[0m12:10:55.530762 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.531026 [debug] [Thread-1 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:10:55.532964 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:10:55.533315 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:10:55.545285 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.545521 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.546630 [debug] [Thread-1 (]: On model.bde.stg_room: COMMIT
[0m12:10:55.547659 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:10:55.547931 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_room"
[0m12:10:55.548186 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:10:55.548419 [debug] [Thread-1 (]: On model.bde.stg_room: COMMIT
[0m12:10:55.548654 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:10:55.563611 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:55.565561 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:10:55.565827 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:55.566097 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:10:55.567847 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_room"
[0m12:10:55.568145 [debug] [Thread-1 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:10:55.578970 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:10:55.579929 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (execute): 12:10:55.378443 => 12:10:55.579801
[0m12:10:55.580202 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:10:55.580516 [debug] [Thread-4 (]: On model.bde.stg_property: Close
[0m12:10:55.581496 [debug] [Thread-1 (]: Timing info for model.bde.stg_room (execute): 12:10:55.380715 => 12:10:55.581379
[0m12:10:55.581812 [debug] [Thread-1 (]: On model.bde.stg_room: Close
[0m12:10:55.582322 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10762abc0>]}
[0m12:10:55.583275 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107629930>]}
[0m12:10:55.582834 [info ] [Thread-4 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.21s]
[0m12:10:55.583741 [info ] [Thread-1 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.21s]
[0m12:10:55.584156 [debug] [Thread-4 (]: Finished running node model.bde.stg_property
[0m12:10:55.584505 [debug] [Thread-1 (]: Finished running node model.bde.stg_room
[0m12:10:55.584802 [debug] [Thread-4 (]: Began running node model.bde.stg_suburb
[0m12:10:55.585204 [debug] [Thread-1 (]: Began running node model.bde.dim_LGA
[0m12:10:55.585575 [info ] [Thread-4 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:10:55.585905 [info ] [Thread-1 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:10:55.586369 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_suburb)
[0m12:10:55.586754 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.dim_LGA)
[0m12:10:55.587007 [debug] [Thread-4 (]: Began compiling node model.bde.stg_suburb
[0m12:10:55.587219 [debug] [Thread-1 (]: Began compiling node model.bde.dim_LGA
[0m12:10:55.589232 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:10:55.591160 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:10:55.592924 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (compile): 12:10:55.587382 => 12:10:55.592722
[0m12:10:55.593297 [debug] [Thread-1 (]: Timing info for model.bde.dim_LGA (compile): 12:10:55.589463 => 12:10:55.593135
[0m12:10:55.593596 [debug] [Thread-4 (]: Began executing node model.bde.stg_suburb
[0m12:10:55.593838 [debug] [Thread-1 (]: Began executing node model.bde.dim_LGA
[0m12:10:55.596417 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:10:55.598912 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:10:55.599445 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:10:55.599671 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:10:55.599885 [debug] [Thread-1 (]: On model.bde.dim_LGA: BEGIN
[0m12:10:55.600101 [debug] [Thread-4 (]: On model.bde.stg_suburb: BEGIN
[0m12:10:55.600308 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:10:55.600505 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:10:55.706628 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:55.707116 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:10:55.707473 [debug] [Thread-1 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:10:55.712121 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:55.712441 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:10:55.712772 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:10:55.723413 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:10:55.723790 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:10:55.728801 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:10:55.731662 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:10:55.731983 [debug] [Thread-1 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:10:55.732274 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:10:55.741244 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.741598 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.744008 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:10:55.746264 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:10:55.746557 [debug] [Thread-1 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:10:55.746838 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:10:55.761024 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.762523 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m12:10:55.762867 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:10:55.763166 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m12:10:55.773026 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:55.775342 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:10:55.775685 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:10:55.786903 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:10:55.788293 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (execute): 12:10:55.594015 => 12:10:55.788098
[0m12:10:55.788750 [debug] [Thread-4 (]: On model.bde.stg_suburb: Close
[0m12:10:55.789643 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c84a740>]}
[0m12:10:55.790222 [info ] [Thread-4 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.20s]
[0m12:10:55.790785 [debug] [Thread-4 (]: Finished running node model.bde.stg_suburb
[0m12:10:55.791165 [debug] [Thread-4 (]: Began running node model.bde.fact_G01
[0m12:10:55.791829 [info ] [Thread-4 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:10:55.792477 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.fact_G01)
[0m12:10:55.792820 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G01
[0m12:10:55.796011 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:10:55.797053 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (compile): 12:10:55.793062 => 12:10:55.796874
[0m12:10:55.797426 [debug] [Thread-4 (]: Began executing node model.bde.fact_G01
[0m12:10:55.800644 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:10:55.801166 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:10:55.801451 [debug] [Thread-4 (]: On model.bde.fact_G01: BEGIN
[0m12:10:55.801710 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:10:55.916270 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:55.916891 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:10:55.917267 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:10:55.942773 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:10:55.946394 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:10:55.946764 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:10:55.957517 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.960471 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:10:55.960862 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:10:55.965881 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.967473 [debug] [Thread-1 (]: On model.bde.dim_LGA: COMMIT
[0m12:10:55.967793 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:10:55.968082 [debug] [Thread-1 (]: On model.bde.dim_LGA: COMMIT
[0m12:10:55.972769 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:55.974423 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m12:10:55.974777 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:10:55.975092 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m12:10:55.977442 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:55.979682 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:10:55.979999 [debug] [Thread-1 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:10:55.985005 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:55.987583 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:10:55.987927 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:10:55.994870 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:10:55.996145 [debug] [Thread-1 (]: Timing info for model.bde.dim_LGA (execute): 12:10:55.596613 => 12:10:55.995974
[0m12:10:55.996521 [debug] [Thread-1 (]: On model.bde.dim_LGA: Close
[0m12:10:55.997345 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c844610>]}
[0m12:10:55.997918 [info ] [Thread-1 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.41s]
[0m12:10:55.998484 [debug] [Thread-1 (]: Finished running node model.bde.dim_LGA
[0m12:10:55.998910 [debug] [Thread-1 (]: Began running node model.bde.fact_G02
[0m12:10:55.999401 [info ] [Thread-1 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:10:56.000093 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G02)
[0m12:10:56.000448 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G02
[0m12:10:56.003464 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:10:56.004148 [debug] [Thread-1 (]: Timing info for model.bde.fact_G02 (compile): 12:10:56.000690 => 12:10:56.004006
[0m12:10:56.004452 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:10:56.004815 [debug] [Thread-1 (]: Began executing node model.bde.fact_G02
[0m12:10:56.005937 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (execute): 12:10:55.797636 => 12:10:56.005803
[0m12:10:56.009200 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:10:56.009553 [debug] [Thread-4 (]: On model.bde.fact_G01: Close
[0m12:10:56.010478 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c893bb0>]}
[0m12:10:56.010919 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:10:56.011426 [info ] [Thread-4 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.22s]
[0m12:10:56.011775 [debug] [Thread-1 (]: On model.bde.fact_G02: BEGIN
[0m12:10:56.012213 [debug] [Thread-4 (]: Finished running node model.bde.fact_G01
[0m12:10:56.012498 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:10:56.012810 [debug] [Thread-4 (]: Began running node model.bde.fact_listing
[0m12:10:56.013368 [info ] [Thread-4 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:10:56.013883 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_listing)
[0m12:10:56.014170 [debug] [Thread-4 (]: Began compiling node model.bde.fact_listing
[0m12:10:56.016583 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:10:56.017443 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (compile): 12:10:56.014356 => 12:10:56.017278
[0m12:10:56.017752 [debug] [Thread-4 (]: Began executing node model.bde.fact_listing
[0m12:10:56.020659 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:10:56.021127 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:10:56.021365 [debug] [Thread-4 (]: On model.bde.fact_listing: BEGIN
[0m12:10:56.021587 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:10:56.122739 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:56.123295 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:10:56.123698 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:10:56.127326 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:56.127653 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:10:56.128053 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:10:56.150017 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:10:56.153744 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:10:56.154190 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:10:56.165164 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:56.168076 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:10:56.168471 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:10:56.177366 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:56.181108 [debug] [Thread-1 (]: On model.bde.fact_G02: COMMIT
[0m12:10:56.181498 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:10:56.181840 [debug] [Thread-1 (]: On model.bde.fact_G02: COMMIT
[0m12:10:56.196102 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:56.198780 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:10:56.199183 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:10:56.216896 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:10:56.218604 [debug] [Thread-1 (]: Timing info for model.bde.fact_G02 (execute): 12:10:56.006180 => 12:10:56.218370
[0m12:10:56.219080 [debug] [Thread-1 (]: On model.bde.fact_G02: Close
[0m12:10:56.220241 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c8252a0>]}
[0m12:10:56.221066 [info ] [Thread-1 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.22s]
[0m12:10:56.221820 [debug] [Thread-1 (]: Finished running node model.bde.fact_G02
[0m12:10:56.222347 [debug] [Thread-1 (]: Began running node model.bde.dim_host
[0m12:10:56.222994 [info ] [Thread-1 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:10:56.223794 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m12:10:56.224270 [debug] [Thread-1 (]: Began compiling node model.bde.dim_host
[0m12:10:56.228039 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:10:56.230278 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (compile): 12:10:56.224532 => 12:10:56.230073
[0m12:10:56.230631 [debug] [Thread-1 (]: Began executing node model.bde.dim_host
[0m12:10:56.234171 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:10:56.234964 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:10:56.235359 [debug] [Thread-1 (]: On model.bde.dim_host: BEGIN
[0m12:10:56.235677 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:10:56.339309 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:56.339768 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:10:56.340035 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:10:57.066101 [debug] [Thread-1 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m12:10:57.073218 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:10:57.073953 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:10:58.331694 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m12:10:58.334776 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:10:58.335082 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:10:58.344354 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:58.346306 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:10:58.346587 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:10:58.356363 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:58.357488 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:10:58.357720 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:10:58.357931 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:10:58.385162 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:58.387126 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:10:58.387394 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:10:58.412458 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:10:58.413403 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:10:54.298690 => 12:10:58.413280
[0m12:10:58.413669 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:10:58.414316 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c8e2740>]}
[0m12:10:58.414730 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 4.15s]
[0m12:10:58.415146 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:10:58.415432 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m12:10:58.415794 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:10:58.416282 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m12:10:58.416543 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m12:10:58.418758 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:10:58.420186 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 12:10:58.416725 => 12:10:58.420059
[0m12:10:58.420441 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m12:10:58.423991 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:10:58.424431 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:10:58.424662 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m12:10:58.424885 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:10:58.552040 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:58.552578 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:10:58.553166 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:10:59.215718 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m12:10:59.217380 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 5.0 seconds
[0m12:10:59.225475 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:10:59.229347 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:10:59.229814 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:10:59.230244 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m12:10:59.241709 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:59.244819 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:10:59.245289 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m12:10:59.254299 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:59.256334 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:10:59.256787 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:10:59.257132 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:10:59.290907 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:59.291926 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 2.0 seconds
[0m12:10:59.292508 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:59.296871 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:10:59.300586 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:10:59.303447 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:10:59.303871 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m12:10:59.304259 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:10:59.304639 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:10:59.316438 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:59.318295 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m12:10:59.318664 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:59.319016 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:10:59.320824 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:10:59.321190 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m12:10:59.321487 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:10:59.321844 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:10:59.327147 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:10:59.328510 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:10:54.275958 => 12:10:59.328320
[0m12:10:59.328916 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:10:59.329749 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077387f0>]}
[0m12:10:59.330320 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 5.07s]
[0m12:10:59.330872 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:10:59.331250 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m12:10:59.331705 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:10:59.332357 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m12:10:59.332683 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m12:10:59.335760 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:10:59.336247 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:59.339659 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:10:59.339999 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:59.340332 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:10:59.340667 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 12:10:59.332905 => 12:10:59.340531
[0m12:10:59.342598 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:10:59.343025 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m12:10:59.343347 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:10:59.346303 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:10:59.346971 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:10:59.347249 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m12:10:59.347491 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:10:59.392446 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:10:59.394006 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (execute): 12:10:56.230854 => 12:10:59.393848
[0m12:10:59.394376 [debug] [Thread-1 (]: On model.bde.dim_host: Close
[0m12:10:59.395143 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107628d60>]}
[0m12:10:59.395676 [info ] [Thread-1 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 3.17s]
[0m12:10:59.396191 [debug] [Thread-1 (]: Finished running node model.bde.dim_host
[0m12:10:59.396534 [debug] [Thread-1 (]: Began running node model.bde.dim_suburb
[0m12:10:59.396953 [info ] [Thread-1 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:10:59.397526 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dim_host, now model.bde.dim_suburb)
[0m12:10:59.397835 [debug] [Thread-1 (]: Began compiling node model.bde.dim_suburb
[0m12:10:59.400470 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:10:59.400755 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:10:59.401864 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 12:10:58.420605 => 12:10:59.401725
[0m12:10:59.402194 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m12:10:59.402868 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (compile): 12:10:59.398040 => 12:10:59.402553
[0m12:10:59.403502 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c8c0820>]}
[0m12:10:59.403868 [debug] [Thread-1 (]: Began executing node model.bde.dim_suburb
[0m12:10:59.404240 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 0.99s]
[0m12:10:59.407289 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:10:59.407758 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m12:10:59.408376 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:10:59.408662 [debug] [Thread-1 (]: On model.bde.dim_suburb: BEGIN
[0m12:10:59.408914 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:10:59.461925 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:59.462394 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:10:59.462720 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:10:59.518081 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:10:59.518429 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:10:59.518776 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:10:59.541545 [debug] [Thread-1 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:10:59.545146 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:10:59.545567 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:10:59.556647 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:59.559508 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:10:59.559906 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:10:59.569553 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:59.571451 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m12:10:59.571824 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:10:59.572163 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m12:10:59.602125 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:59.607849 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:10:59.608403 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:10:59.634077 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:10:59.635757 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (execute): 12:10:59.404499 => 12:10:59.635580
[0m12:10:59.636149 [debug] [Thread-1 (]: On model.bde.dim_suburb: Close
[0m12:10:59.637073 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076f69e0>]}
[0m12:10:59.637670 [info ] [Thread-1 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.24s]
[0m12:10:59.638229 [debug] [Thread-1 (]: Finished running node model.bde.dim_suburb
[0m12:10:59.754097 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:10:59.762162 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:10:59.762724 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:10:59.772356 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:59.777599 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:10:59.778017 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:10:59.791289 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:59.793382 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:10:59.793764 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:10:59.794116 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:10:59.818446 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:59.821646 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:10:59.822118 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:10:59.850734 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:10:59.854306 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 12:10:59.343572 => 12:10:59.854036
[0m12:10:59.854840 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m12:10:59.856041 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c8e1cf0>]}
[0m12:10:59.856847 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.52s]
[0m12:10:59.857619 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m12:10:59.874247 [debug] [Thread-4 (]: SQL status: SELECT 340945 in 4.0 seconds
[0m12:10:59.878024 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:10:59.878299 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:10:59.891330 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:59.894405 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:10:59.894854 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:10:59.904395 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:10:59.906311 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m12:10:59.906690 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:10:59.907030 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m12:10:59.917815 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:10:59.920539 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:10:59.920936 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:10:59.957957 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:10:59.959810 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (execute): 12:10:56.017939 => 12:10:59.959565
[0m12:10:59.960298 [debug] [Thread-4 (]: On model.bde.fact_listing: Close
[0m12:10:59.961377 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa4a11c-99d1-4bc2-88cf-af995d4bf916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107623f40>]}
[0m12:10:59.962174 [info ] [Thread-4 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 3.95s]
[0m12:10:59.962931 [debug] [Thread-4 (]: Finished running node model.bde.fact_listing
[0m12:10:59.964887 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:59.965321 [debug] [MainThread]: On master: BEGIN
[0m12:10:59.965668 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:11:00.072028 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:11:00.073209 [debug] [MainThread]: On master: COMMIT
[0m12:11:00.073667 [debug] [MainThread]: Using postgres connection "master"
[0m12:11:00.074070 [debug] [MainThread]: On master: COMMIT
[0m12:11:00.083443 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:11:00.084028 [debug] [MainThread]: On master: Close
[0m12:11:00.085411 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:11:00.085864 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:11:00.086220 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m12:11:00.086547 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:11:00.086847 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:11:00.087405 [info ] [MainThread]: 
[0m12:11:00.087828 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 6.40 seconds (6.40s).
[0m12:11:00.090242 [debug] [MainThread]: Command end result
[0m12:11:00.100228 [info ] [MainThread]: 
[0m12:11:00.100718 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:11:00.101039 [info ] [MainThread]: 
[0m12:11:00.101347 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m12:11:00.102026 [debug] [MainThread]: Command `dbt run` succeeded at 12:11:00.101923 after 6.54 seconds
[0m12:11:00.102430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d0d5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c807fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077b6da0>]}
[0m12:11:00.102828 [debug] [MainThread]: Flushing usage events
[0m12:12:16.450637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1031d98a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b4dae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b4d3c0>]}


============================== 12:12:16.453253 | a59ecf79-5680-4046-87c5-6597ed2b0fa8 ==============================
[0m12:12:16.453253 [info ] [MainThread]: Running with dbt=1.6.6
[0m12:12:16.453570 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:12:16.503905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b4d630>]}
[0m12:12:16.511519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106039180>]}
[0m12:12:16.511885 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m12:12:16.520653 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m12:12:16.543575 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:12:16.543794 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:12:16.544402 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.raw
- models.bde.median
[0m12:12:16.547626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067700d0>]}
[0m12:12:16.553653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106602ce0>]}
[0m12:12:16.553904 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m12:12:16.554087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066000d0>]}
[0m12:12:16.555223 [info ] [MainThread]: 
[0m12:12:16.555628 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:12:16.556489 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:12:16.556898 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:12:16.561670 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:12:16.561989 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:12:16.563042 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:12:16.563249 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:12:16.564438 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:12:16.564612 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:12:16.564775 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:12:16.564928 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:12:16.565067 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:12:16.566677 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:12:16.712535 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:12:16.712906 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:12:16.713924 [debug] [ThreadPool]: On list_postgres: Close
[0m12:12:16.714113 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:12:16.714766 [debug] [ThreadPool]: On list_postgres: Close
[0m12:12:16.715400 [debug] [ThreadPool]: On list_postgres: Close
[0m12:12:16.717410 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_warehouse)
[0m12:12:16.717953 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m12:12:16.718389 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_staging)
[0m12:12:16.721951 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:12:16.722453 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_raw'
[0m12:12:16.723486 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:12:16.724429 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:12:16.724624 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m12:12:16.725590 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:12:16.725770 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m12:12:16.725926 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m12:12:16.726082 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:12:16.726240 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m12:12:16.726407 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:12:16.726561 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:12:16.726820 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:12:16.828903 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:12:16.829303 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:12:16.829523 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:12:16.829801 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m12:12:16.830050 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:12:16.830311 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m12:12:16.833754 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:12:16.833930 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:12:16.834131 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:12:16.834321 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:12:16.834534 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m12:12:16.834770 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m12:12:16.848043 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:12:16.848239 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:12:16.849194 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m12:12:16.849987 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m12:12:16.853185 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:12:16.854025 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m12:12:16.854240 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:12:16.855055 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m12:12:16.858771 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m12:12:16.861603 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m12:12:16.868000 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m12:12:16.868288 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m12:12:16.874768 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:16.875068 [debug] [MainThread]: On master: BEGIN
[0m12:12:16.875303 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:12:16.975124 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:12:16.975590 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:16.976193 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:12:17.002181 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:12:17.007091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067beef0>]}
[0m12:12:17.008245 [debug] [MainThread]: On master: ROLLBACK
[0m12:12:17.017452 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:17.018164 [debug] [MainThread]: On master: BEGIN
[0m12:12:17.036026 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:12:17.037351 [debug] [MainThread]: On master: COMMIT
[0m12:12:17.038369 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:17.038947 [debug] [MainThread]: On master: COMMIT
[0m12:12:17.048439 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:12:17.049468 [debug] [MainThread]: On master: Close
[0m12:12:17.051306 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:12:17.052258 [info ] [MainThread]: 
[0m12:12:17.057891 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m12:12:17.058589 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m12:12:17.059206 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m12:12:17.059781 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m12:12:17.060459 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m12:12:17.060986 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m12:12:17.061476 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m12:12:17.061941 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m12:12:17.062680 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.dm_host_neighbourhod)
[0m12:12:17.063297 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_listing_neighbourhood)
[0m12:12:17.063897 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.dm_property_type)
[0m12:12:17.064496 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.stg_G01)
[0m12:12:17.064892 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m12:12:17.065260 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m12:12:17.065620 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m12:12:17.066002 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m12:12:17.073730 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m12:12:17.076196 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m12:12:17.079826 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m12:12:17.082677 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m12:12:17.083392 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 12:12:17.066264 => 12:12:17.083225
[0m12:12:17.084023 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m12:12:17.084479 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 12:12:17.076453 => 12:12:17.084324
[0m12:12:17.084815 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 12:12:17.074018 => 12:12:17.084673
[0m12:12:17.091490 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 12:12:17.080126 => 12:12:17.091318
[0m12:12:17.110357 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m12:12:17.110631 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m12:12:17.110874 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m12:12:17.111085 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m12:12:17.113354 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m12:12:17.115546 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m12:12:17.122108 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:12:17.126220 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m12:12:17.126727 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m12:12:17.127064 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:12:17.127312 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:12:17.127537 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:12:17.127801 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m12:12:17.127997 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:12:17.128191 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m12:12:17.128478 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:12:17.128677 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m12:12:17.128875 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:12:17.129164 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:17.246527 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:17.246890 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:17.247222 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:12:17.247518 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:12:17.248037 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m12:12:17.248540 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:17.249071 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type



WITH sorted_listing AS (
    SELECT 
        prop.property_type,
        room.room_type,
        list.accommodates,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
SELECT 
    property_type,
    room_type,
    accommodates,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,



    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:12:17.249560 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:17.249896 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:12:17.250240 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:12:17.250539 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    

WITH Calculations AS (
  SELECT
    sub.Local_Government_Area,
    DATE_TRUNC('month', list.scraped_date) AS month_year,
    COUNT(DISTINCT host.host_id) AS number_of_distinct_host,
    SUM(CASE WHEN list.has_availability = 't' THEN (30 - list.availability_30) * list.price END) AS Estimated_Revenue
  FROM warehouse.dim_host host
  JOIN warehouse.dim_SUBURB sub ON host.host_neighbourhood = sub.Local_Government_Area_SUBURB
  JOIN warehouse.fact_listing list ON list.surrogate_key_host = host.surrogate_key_host
  GROUP BY sub.Local_Government_Area, month_year
)

SELECT
  Local_Government_Area,
  month_year,
  number_of_distinct_host,
  Estimated_Revenue,
  CASE WHEN number_of_distinct_host > 0 THEN Estimated_Revenue / number_of_distinct_host ELSE 0 END AS Estimated_revenue_per_host
FROM Calculations
  );
  
[0m12:12:17.250996 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:12:17.289992 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:17.294964 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:12:17.295305 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:12:17.305652 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:17.307843 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:12:17.308119 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:12:17.318513 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:17.330715 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:12:17.331025 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:12:17.331281 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:12:17.341904 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:17.347378 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:12:17.347651 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:12:17.359684 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:17.360645 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:12:17.115739 => 12:12:17.360516
[0m12:12:17.360917 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:12:17.361536 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070978e0>]}
[0m12:12:17.361962 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.30s]
[0m12:12:17.362374 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:12:17.362668 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m12:12:17.363039 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:12:17.363532 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m12:12:17.363790 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m12:12:17.365954 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:12:17.366507 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 12:12:17.363967 => 12:12:17.366394
[0m12:12:17.366751 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m12:12:17.369293 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:12:17.369717 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:12:17.369959 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m12:12:17.370195 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:17.494199 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:17.494704 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:12:17.495234 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:12:17.510210 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:17.514603 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:12:17.515104 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:12:17.524725 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:17.528449 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:12:17.528953 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:12:17.538202 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:17.540275 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:12:17.540745 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:12:17.541174 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:12:17.550879 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:17.555960 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:12:17.556444 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:12:17.568208 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:17.569866 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 12:12:17.366916 => 12:12:17.569645
[0m12:12:17.570347 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m12:12:17.571383 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107737370>]}
[0m12:12:17.572056 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.21s]
[0m12:12:17.572661 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m12:12:17.573098 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m12:12:17.573866 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:12:17.574814 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m12:12:17.575243 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m12:12:17.578834 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:12:17.579707 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 12:12:17.575524 => 12:12:17.579532
[0m12:12:17.580046 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m12:12:17.584283 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:12:17.585141 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:12:17.585479 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m12:12:17.585748 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:17.603153 [debug] [Thread-1 (]: SQL status: SELECT 207 in 0.0 seconds
[0m12:12:17.606309 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:12:17.606633 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m12:12:17.615884 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:17.618444 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:12:17.618754 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m12:12:17.627884 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:17.632477 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:12:17.632813 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:12:17.633085 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:12:17.643619 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:17.647258 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:12:17.647607 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m12:12:17.661689 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:17.662888 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:12:17.085020 => 12:12:17.662735
[0m12:12:17.663218 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:12:17.663876 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106733ee0>]}
[0m12:12:17.664356 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 207[0m in 0.60s]
[0m12:12:17.664828 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:12:17.665157 [debug] [Thread-1 (]: Began running node model.bde.stg_fact
[0m12:12:17.665501 [info ] [Thread-1 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:12:17.666109 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.stg_fact)
[0m12:12:17.666471 [debug] [Thread-1 (]: Began compiling node model.bde.stg_fact
[0m12:12:17.668915 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:12:17.669512 [debug] [Thread-1 (]: Timing info for model.bde.stg_fact (compile): 12:12:17.666699 => 12:12:17.669380
[0m12:12:17.669963 [debug] [Thread-1 (]: Began executing node model.bde.stg_fact
[0m12:12:17.672953 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:12:17.673432 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:12:17.673685 [debug] [Thread-1 (]: On model.bde.stg_fact: BEGIN
[0m12:12:17.673919 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:12:17.697014 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:17.697463 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:12:17.697833 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:12:17.710683 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:17.714944 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:12:17.715269 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:12:17.724666 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:17.726981 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:12:17.727311 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:12:17.736288 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:17.737742 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:12:17.738043 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:12:17.738309 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:12:17.748240 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:17.750194 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:12:17.750492 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:12:17.761208 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:17.762209 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 12:12:17.580307 => 12:12:17.762069
[0m12:12:17.762504 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m12:12:17.763166 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107749420>]}
[0m12:12:17.763636 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.19s]
[0m12:12:17.764095 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m12:12:17.764425 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m12:12:17.764937 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:12:17.765462 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_host)
[0m12:12:17.765765 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m12:12:17.768408 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:12:17.768990 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 12:12:17.766002 => 12:12:17.768866
[0m12:12:17.769256 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m12:12:17.772143 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:12:17.772603 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:12:17.772846 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m12:12:17.773080 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:17.789617 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:17.789986 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:12:17.790357 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:12:17.808972 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:17.811790 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:12:17.812111 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:12:17.831047 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:17.833356 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:12:17.833670 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:12:17.844784 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:17.846091 [debug] [Thread-1 (]: On model.bde.stg_fact: COMMIT
[0m12:12:17.846418 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:12:17.846713 [debug] [Thread-1 (]: On model.bde.stg_fact: COMMIT
[0m12:12:17.857467 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:17.859622 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:12:17.859963 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:12:17.875144 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:17.876294 [debug] [Thread-1 (]: Timing info for model.bde.stg_fact (execute): 12:12:17.670170 => 12:12:17.876142
[0m12:12:17.876628 [debug] [Thread-1 (]: On model.bde.stg_fact: Close
[0m12:12:17.877324 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10778f6d0>]}
[0m12:12:17.877838 [info ] [Thread-1 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.21s]
[0m12:12:17.878356 [debug] [Thread-1 (]: Finished running node model.bde.stg_fact
[0m12:12:17.878729 [debug] [Thread-1 (]: Began running node model.bde.stg_property
[0m12:12:17.879298 [info ] [Thread-1 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:12:17.879980 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_property)
[0m12:12:17.880349 [debug] [Thread-1 (]: Began compiling node model.bde.stg_property
[0m12:12:17.883106 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:12:17.883712 [debug] [Thread-1 (]: Timing info for model.bde.stg_property (compile): 12:12:17.880592 => 12:12:17.883569
[0m12:12:17.884011 [debug] [Thread-1 (]: Began executing node model.bde.stg_property
[0m12:12:17.921377 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:17.922921 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:12:17.923245 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:12:17.923655 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:12:17.924135 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:12:17.924337 [debug] [Thread-1 (]: On model.bde.stg_property: BEGIN
[0m12:12:17.924522 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:12:17.938916 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:17.941101 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:12:17.941325 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:12:17.950917 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:17.952534 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:12:17.952762 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:12:17.963834 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:17.964803 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:12:17.965034 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:12:17.965242 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:12:17.977623 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:17.979286 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:12:17.979526 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:12:17.990344 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:17.991318 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 12:12:17.769486 => 12:12:17.991175
[0m12:12:17.991589 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m12:12:17.992211 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070fd660>]}
[0m12:12:17.992637 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.23s]
[0m12:12:17.993067 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m12:12:17.993381 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m12:12:17.993853 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:12:17.994316 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_room)
[0m12:12:17.994556 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m12:12:17.996668 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:12:17.997213 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 12:12:17.994715 => 12:12:17.997089
[0m12:12:17.997455 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m12:12:18.000436 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:12:18.001065 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:12:18.001326 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m12:12:18.001564 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:18.034931 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:18.035321 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:12:18.035662 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:12:18.049846 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:18.052360 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:12:18.052647 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:12:18.062478 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:18.064412 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:12:18.064700 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:12:18.076058 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:18.077544 [debug] [Thread-1 (]: On model.bde.stg_property: COMMIT
[0m12:12:18.077862 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:12:18.078134 [debug] [Thread-1 (]: On model.bde.stg_property: COMMIT
[0m12:12:18.088418 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:18.091595 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:12:18.091906 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:12:18.104732 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:18.105830 [debug] [Thread-1 (]: Timing info for model.bde.stg_property (execute): 12:12:17.884208 => 12:12:18.105688
[0m12:12:18.106133 [debug] [Thread-1 (]: On model.bde.stg_property: Close
[0m12:12:18.106769 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066016f0>]}
[0m12:12:18.107245 [info ] [Thread-1 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.23s]
[0m12:12:18.107701 [debug] [Thread-1 (]: Finished running node model.bde.stg_property
[0m12:12:18.108025 [debug] [Thread-1 (]: Began running node model.bde.stg_suburb
[0m12:12:18.108494 [info ] [Thread-1 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:12:18.109021 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_suburb)
[0m12:12:18.109306 [debug] [Thread-1 (]: Began compiling node model.bde.stg_suburb
[0m12:12:18.111630 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:12:18.112278 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (compile): 12:12:18.109518 => 12:12:18.112144
[0m12:12:18.112564 [debug] [Thread-1 (]: Began executing node model.bde.stg_suburb
[0m12:12:18.115661 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:12:18.115936 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:18.116268 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:12:18.116585 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:12:18.116865 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:12:18.117146 [debug] [Thread-1 (]: On model.bde.stg_suburb: BEGIN
[0m12:12:18.117382 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:12:18.130754 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:18.133099 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:12:18.133375 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:12:18.143040 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:18.145118 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:12:18.145399 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:12:18.154844 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:18.156048 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:12:18.156335 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:12:18.156590 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:12:18.167466 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:18.169400 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:12:18.169693 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:12:18.182240 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:18.183252 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 12:12:17.997638 => 12:12:18.183119
[0m12:12:18.183544 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m12:12:18.184168 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070e7e80>]}
[0m12:12:18.184642 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.19s]
[0m12:12:18.185080 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m12:12:18.185408 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m12:12:18.185874 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:12:18.186402 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.dim_LGA)
[0m12:12:18.186690 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m12:12:18.189119 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:12:18.189745 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 12:12:18.186890 => 12:12:18.189610
[0m12:12:18.190026 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m12:12:18.192965 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:12:18.193471 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:12:18.193719 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m12:12:18.193963 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:18.219674 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:18.220056 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:12:18.220385 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:12:18.231554 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:18.235619 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:12:18.235946 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:12:18.245193 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:18.247367 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:12:18.247693 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:12:18.257224 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:18.258456 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:12:18.258741 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:12:18.258998 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:12:18.270923 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:18.273102 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:12:18.273439 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:12:18.285000 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:18.286053 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (execute): 12:12:18.112845 => 12:12:18.285905
[0m12:12:18.286401 [debug] [Thread-1 (]: On model.bde.stg_suburb: Close
[0m12:12:18.287123 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070e44f0>]}
[0m12:12:18.287657 [info ] [Thread-1 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.18s]
[0m12:12:18.288137 [debug] [Thread-1 (]: Finished running node model.bde.stg_suburb
[0m12:12:18.288463 [debug] [Thread-1 (]: Began running node model.bde.fact_G01
[0m12:12:18.288919 [info ] [Thread-1 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:12:18.289449 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.fact_G01)
[0m12:12:18.289733 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G01
[0m12:12:18.292430 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:12:18.293043 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (compile): 12:12:18.289932 => 12:12:18.292910
[0m12:12:18.293326 [debug] [Thread-1 (]: Began executing node model.bde.fact_G01
[0m12:12:18.296499 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:12:18.297123 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:12:18.297378 [debug] [Thread-1 (]: On model.bde.fact_G01: BEGIN
[0m12:12:18.297620 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:12:18.306923 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:18.307497 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:12:18.307781 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:12:18.323811 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:12:18.326641 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:12:18.326964 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:12:18.336498 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:18.338701 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:12:18.339016 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:12:18.348257 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:18.349729 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:12:18.350023 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:12:18.350274 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:12:18.360660 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:18.362646 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:12:18.362934 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:12:18.376932 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:18.377948 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 12:12:18.190215 => 12:12:18.377814
[0m12:12:18.378247 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m12:12:18.378872 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067bff10>]}
[0m12:12:18.379383 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.19s]
[0m12:12:18.379836 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m12:12:18.380164 [debug] [Thread-4 (]: Began running node model.bde.fact_G02
[0m12:12:18.380592 [info ] [Thread-4 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:12:18.381176 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G02)
[0m12:12:18.381482 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G02
[0m12:12:18.384175 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:12:18.384787 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (compile): 12:12:18.381687 => 12:12:18.384661
[0m12:12:18.385062 [debug] [Thread-4 (]: Began executing node model.bde.fact_G02
[0m12:12:18.389150 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:12:18.389614 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:12:18.389862 [debug] [Thread-4 (]: On model.bde.fact_G02: BEGIN
[0m12:12:18.390106 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:18.406079 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:18.406390 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:12:18.406647 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:12:18.434015 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:12:18.436712 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:12:18.437028 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:12:18.446252 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:18.448411 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:12:18.448714 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:12:18.457944 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:18.459616 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:12:18.459940 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:12:18.460233 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:12:18.472038 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:18.474361 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:12:18.474708 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:12:18.493086 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:18.494239 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (execute): 12:12:18.293524 => 12:12:18.494086
[0m12:12:18.494566 [debug] [Thread-1 (]: On model.bde.fact_G01: Close
[0m12:12:18.495284 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067e0730>]}
[0m12:12:18.495802 [info ] [Thread-1 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.21s]
[0m12:12:18.496318 [debug] [Thread-1 (]: Finished running node model.bde.fact_G01
[0m12:12:18.496746 [debug] [Thread-1 (]: Began running node model.bde.fact_listing
[0m12:12:18.497197 [info ] [Thread-1 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:12:18.497792 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_listing)
[0m12:12:18.498118 [debug] [Thread-1 (]: Began compiling node model.bde.fact_listing
[0m12:12:18.500710 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:12:18.501363 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (compile): 12:12:18.498340 => 12:12:18.501224
[0m12:12:18.501652 [debug] [Thread-1 (]: Began executing node model.bde.fact_listing
[0m12:12:18.504717 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:12:18.505211 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:12:18.505489 [debug] [Thread-1 (]: On model.bde.fact_listing: BEGIN
[0m12:12:18.505746 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:12:18.519042 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:18.519364 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:12:18.519657 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:12:18.537682 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:12:18.540262 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:12:18.540562 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:12:18.550757 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:18.553015 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:12:18.553316 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:12:18.563600 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:18.565175 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:12:18.565530 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:12:18.565827 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:12:18.612908 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:18.613327 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:12:18.613747 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:12:18.708498 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:18.712348 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:12:18.712661 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:12:18.729755 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:18.730759 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (execute): 12:12:18.385241 => 12:12:18.730654
[0m12:12:18.731002 [debug] [Thread-4 (]: On model.bde.fact_G02: Close
[0m12:12:18.731606 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070195d0>]}
[0m12:12:18.731973 [info ] [Thread-4 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.35s]
[0m12:12:18.732314 [debug] [Thread-4 (]: Finished running node model.bde.fact_G02
[0m12:12:18.732573 [debug] [Thread-4 (]: Began running node model.bde.dim_host
[0m12:12:18.732923 [info ] [Thread-4 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:12:18.733401 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m12:12:18.733649 [debug] [Thread-4 (]: Began compiling node model.bde.dim_host
[0m12:12:18.735546 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:12:18.736059 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (compile): 12:12:18.733801 => 12:12:18.735957
[0m12:12:18.736275 [debug] [Thread-4 (]: Began executing node model.bde.dim_host
[0m12:12:18.738586 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:12:18.739006 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:12:18.739208 [debug] [Thread-4 (]: On model.bde.dim_host: BEGIN
[0m12:12:18.739386 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:18.842528 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:18.842982 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:12:18.843362 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:12:19.600825 [debug] [Thread-4 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m12:12:19.611793 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:12:19.612335 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:12:20.828894 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m12:12:20.830976 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:12:20.831211 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:12:20.840443 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:20.841929 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:12:20.842140 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:12:20.851493 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:20.852572 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:12:20.852780 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:12:20.852967 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:12:20.869729 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:20.871353 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:12:20.871595 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:12:20.892328 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:20.893250 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:12:17.113580 => 12:12:20.893113
[0m12:12:20.893526 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:12:20.894153 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077660b0>]}
[0m12:12:20.894580 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 3.83s]
[0m12:12:20.895000 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:12:20.895293 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m12:12:20.895698 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:12:20.896238 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m12:12:20.896518 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m12:12:20.898659 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:12:20.900661 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 12:12:20.896702 => 12:12:20.900548
[0m12:12:20.900890 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m12:12:20.904534 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:12:20.904948 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:12:20.905161 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m12:12:20.905361 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:12:21.013834 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:21.014362 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:12:21.014776 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:12:21.546627 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m12:12:21.555302 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:12:21.555968 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:12:21.955898 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 5.0 seconds
[0m12:12:21.964401 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:12:21.965437 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m12:12:21.975680 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:21.981215 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:12:21.981836 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m12:12:21.991116 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:21.994653 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:12:21.995268 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:12:21.995736 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:12:22.021871 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:22.022568 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 2.0 seconds
[0m12:12:22.023166 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:22.028064 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:12:22.032231 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:12:22.034888 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:12:22.035317 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:12:22.035707 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:12:22.036087 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m12:12:22.045814 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:22.046216 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:22.048446 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:12:22.050234 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:12:22.050593 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:12:22.050910 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:12:22.051219 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:12:22.051521 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:12:22.058640 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:22.060053 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:12:17.111308 => 12:12:22.059856
[0m12:12:22.060449 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:12:22.061384 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070741f0>]}
[0m12:12:22.062030 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 5.00s]
[0m12:12:22.062608 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:12:22.062974 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m12:12:22.063437 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:12:22.064030 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m12:12:22.064353 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m12:12:22.067353 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:12:22.068071 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:22.071066 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:12:22.071496 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:22.071862 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:12:22.072227 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 12:12:22.064574 => 12:12:22.072062
[0m12:12:22.076110 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:12:22.076583 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m12:12:22.076921 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:12:22.080029 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:12:22.080683 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:12:22.080967 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m12:12:22.081208 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:12:22.147921 [debug] [Thread-1 (]: SQL status: SELECT 340945 in 4.0 seconds
[0m12:12:22.151647 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:12:22.152084 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:12:22.164030 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:22.167013 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:12:22.167440 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:22.167867 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:22.168309 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:12:22.169756 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (execute): 12:12:18.736425 => 12:12:22.169597
[0m12:12:22.170929 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 12:12:20.901055 => 12:12:22.170777
[0m12:12:22.171353 [debug] [Thread-4 (]: On model.bde.dim_host: Close
[0m12:12:22.171707 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m12:12:22.172459 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077e6e30>]}
[0m12:12:22.173034 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067e2230>]}
[0m12:12:22.173584 [info ] [Thread-4 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 3.44s]
[0m12:12:22.174100 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 1.28s]
[0m12:12:22.174623 [debug] [Thread-4 (]: Finished running node model.bde.dim_host
[0m12:12:22.175079 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m12:12:22.175453 [debug] [Thread-4 (]: Began running node model.bde.dim_suburb
[0m12:12:22.176001 [info ] [Thread-4 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:12:22.176610 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_host, now model.bde.dim_suburb)
[0m12:12:22.176956 [debug] [Thread-4 (]: Began compiling node model.bde.dim_suburb
[0m12:12:22.179474 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:12:22.180595 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:22.182069 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:12:22.182438 [debug] [Thread-4 (]: Timing info for model.bde.dim_suburb (compile): 12:12:22.177198 => 12:12:22.182275
[0m12:12:22.182748 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:12:22.183027 [debug] [Thread-4 (]: Began executing node model.bde.dim_suburb
[0m12:12:22.183294 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:12:22.186310 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:12:22.186832 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:12:22.187093 [debug] [Thread-4 (]: On model.bde.dim_suburb: BEGIN
[0m12:12:22.187319 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:22.198587 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:22.200533 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:12:22.200801 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:12:22.201440 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:22.201683 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:12:22.201927 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:12:22.235512 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:22.236668 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (execute): 12:12:18.501850 => 12:12:22.236534
[0m12:12:22.236972 [debug] [Thread-1 (]: On model.bde.fact_listing: Close
[0m12:12:22.237595 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10703d120>]}
[0m12:12:22.238063 [info ] [Thread-1 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 3.74s]
[0m12:12:22.238528 [debug] [Thread-1 (]: Finished running node model.bde.fact_listing
[0m12:12:22.299483 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:22.300002 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:12:22.300403 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:12:22.324551 [debug] [Thread-4 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:12:22.328769 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:12:22.329306 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:12:22.338774 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:22.344048 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:12:22.344465 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:12:22.353414 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:22.355325 [debug] [Thread-4 (]: On model.bde.dim_suburb: COMMIT
[0m12:12:22.355712 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:12:22.356060 [debug] [Thread-4 (]: On model.bde.dim_suburb: COMMIT
[0m12:12:22.371394 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:12:22.375157 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:12:22.375640 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:12:22.377023 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:22.379998 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:12:22.380480 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:12:22.384753 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:22.388239 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:12:22.388654 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:12:22.393812 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:22.395462 [debug] [Thread-4 (]: Timing info for model.bde.dim_suburb (execute): 12:12:22.183490 => 12:12:22.395248
[0m12:12:22.395947 [debug] [Thread-4 (]: On model.bde.dim_suburb: Close
[0m12:12:22.396883 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067e24d0>]}
[0m12:12:22.397325 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:22.397991 [info ] [Thread-4 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.22s]
[0m12:12:22.400239 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:12:22.400871 [debug] [Thread-4 (]: Finished running node model.bde.dim_suburb
[0m12:12:22.401274 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:12:22.401791 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:12:22.411219 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:22.413704 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:12:22.414053 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:12:22.430488 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:22.431794 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 12:12:22.077155 => 12:12:22.431630
[0m12:12:22.432144 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m12:12:22.432971 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a59ecf79-5680-4046-87c5-6597ed2b0fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077ef8e0>]}
[0m12:12:22.433497 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.37s]
[0m12:12:22.434019 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m12:12:22.435588 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:22.435926 [debug] [MainThread]: On master: BEGIN
[0m12:12:22.436200 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:12:22.535065 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:12:22.536253 [debug] [MainThread]: On master: COMMIT
[0m12:12:22.536766 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:22.537188 [debug] [MainThread]: On master: COMMIT
[0m12:12:22.545982 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:12:22.546536 [debug] [MainThread]: On master: Close
[0m12:12:22.547962 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:12:22.548365 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:12:22.548708 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m12:12:22.549056 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:12:22.549601 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:12:22.550373 [info ] [MainThread]: 
[0m12:12:22.550885 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 5.99 seconds (5.99s).
[0m12:12:22.554299 [debug] [MainThread]: Command end result
[0m12:12:22.566558 [info ] [MainThread]: 
[0m12:12:22.566967 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:12:22.567294 [info ] [MainThread]: 
[0m12:12:22.567616 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m12:12:22.568252 [debug] [MainThread]: Command `dbt run` succeeded at 12:12:22.568167 after 6.13 seconds
[0m12:12:22.568631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1031d98a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107736800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106770370>]}
[0m12:12:22.568981 [debug] [MainThread]: Flushing usage events
[0m12:12:44.771243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055ad690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107505ab0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107505390>]}


============================== 12:12:44.773686 | 00a7e14f-1d8a-459d-8ec7-5b3e64f659fb ==============================
[0m12:12:44.773686 [info ] [MainThread]: Running with dbt=1.6.6
[0m12:12:44.773982 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --full-refresh', 'send_anonymous_usage_stats': 'True'}
[0m12:12:44.827816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107505600>]}
[0m12:12:44.835288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107951150>]}
[0m12:12:44.835643 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m12:12:44.843812 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m12:12:44.868764 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:12:44.868987 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:12:44.869594 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.median
- models.bde.raw
[0m12:12:44.872827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ed80d0>]}
[0m12:12:44.878834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d6acb0>]}
[0m12:12:44.879094 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m12:12:44.879277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d680a0>]}
[0m12:12:44.880454 [info ] [MainThread]: 
[0m12:12:44.880828 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:12:44.881667 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:12:44.882102 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:12:44.886979 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:12:44.887276 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:12:44.888217 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:12:44.888409 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:12:44.889523 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:12:44.889713 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:12:44.889881 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:12:44.890049 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:12:44.890195 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:12:44.890890 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:12:45.031967 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:12:45.032364 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:12:45.033786 [debug] [ThreadPool]: On list_postgres: Close
[0m12:12:45.034053 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:12:45.034916 [debug] [ThreadPool]: On list_postgres: Close
[0m12:12:45.035716 [debug] [ThreadPool]: On list_postgres: Close
[0m12:12:45.038186 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m12:12:45.038864 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m12:12:45.039409 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_staging)
[0m12:12:45.043840 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:12:45.044385 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_warehouse'
[0m12:12:45.045624 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:12:45.046775 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:12:45.047003 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m12:12:45.048163 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:12:45.048388 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m12:12:45.048583 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m12:12:45.048771 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:12:45.048962 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m12:12:45.049145 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:12:45.049329 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:12:45.049625 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:12:45.147320 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:12:45.147729 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:12:45.148021 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m12:12:45.151713 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:12:45.151952 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:12:45.152197 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:12:45.152503 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m12:12:45.152815 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:12:45.153165 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m12:12:45.153533 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:12:45.153756 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:12:45.154011 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m12:12:45.169532 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:12:45.170743 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m12:12:45.171082 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:12:45.171347 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:12:45.172489 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m12:12:45.173439 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m12:12:45.173723 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:12:45.174711 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m12:12:45.180209 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m12:12:45.183759 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m12:12:45.183986 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m12:12:45.184215 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m12:12:45.191752 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:45.192061 [debug] [MainThread]: On master: BEGIN
[0m12:12:45.192290 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:12:45.535703 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:12:45.536978 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:45.538083 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:12:45.569201 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:12:45.571390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d68b20>]}
[0m12:12:45.571734 [debug] [MainThread]: On master: ROLLBACK
[0m12:12:45.580765 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:45.580997 [debug] [MainThread]: On master: BEGIN
[0m12:12:45.599143 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:12:45.599474 [debug] [MainThread]: On master: COMMIT
[0m12:12:45.599701 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:45.599892 [debug] [MainThread]: On master: COMMIT
[0m12:12:45.610133 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:12:45.610348 [debug] [MainThread]: On master: Close
[0m12:12:45.610896 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:12:45.611131 [info ] [MainThread]: 
[0m12:12:45.613698 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m12:12:45.613954 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m12:12:45.614204 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m12:12:45.614521 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m12:12:45.614797 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m12:12:45.615069 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m12:12:45.615357 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m12:12:45.615791 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_host_neighbourhod)
[0m12:12:45.616053 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m12:12:45.616478 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_listing_neighbourhood)
[0m12:12:45.616951 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.dm_property_type)
[0m12:12:45.617215 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m12:12:45.617586 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.stg_G01)
[0m12:12:45.617834 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m12:12:45.618049 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m12:12:45.622973 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m12:12:45.623204 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m12:12:45.624953 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m12:12:45.627534 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m12:12:45.629574 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m12:12:45.630106 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 12:12:45.618226 => 12:12:45.629885
[0m12:12:45.630634 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 12:12:45.625125 => 12:12:45.630483
[0m12:12:45.630951 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m12:12:45.631227 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 12:12:45.623364 => 12:12:45.631100
[0m12:12:45.631472 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m12:12:45.631743 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 12:12:45.627807 => 12:12:45.631635
[0m12:12:45.652334 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m12:12:45.652564 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m12:12:45.654553 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m12:12:45.654768 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m12:12:45.656683 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m12:12:45.663278 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:12:45.666179 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m12:12:45.666497 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:12:45.666684 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m12:12:45.666947 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m12:12:45.667118 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:12:45.667331 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:12:45.667495 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:12:45.667673 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:12:45.667860 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m12:12:45.668118 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m12:12:45.668361 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:12:45.668526 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:45.764876 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:45.765219 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:12:45.765493 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:45.766000 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m12:12:45.766475 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:12:45.766833 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    

WITH Calculations AS (
  SELECT
    sub.Local_Government_Area,
    DATE_TRUNC('month', list.scraped_date) AS month_year,
    COUNT(DISTINCT host.host_id) AS number_of_distinct_host,
    SUM(CASE WHEN list.has_availability = 't' THEN (30 - list.availability_30) * list.price END) AS Estimated_Revenue
  FROM warehouse.dim_host host
  JOIN warehouse.dim_SUBURB sub ON host.host_neighbourhood = sub.Local_Government_Area_SUBURB
  JOIN warehouse.fact_listing list ON list.surrogate_key_host = host.surrogate_key_host
  GROUP BY sub.Local_Government_Area, month_year
)

SELECT
  Local_Government_Area,
  month_year,
  number_of_distinct_host,
  Estimated_Revenue,
  CASE WHEN number_of_distinct_host > 0 THEN Estimated_Revenue / number_of_distinct_host ELSE 0 END AS Estimated_revenue_per_host
FROM Calculations
  );
  
[0m12:12:45.771365 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:45.771610 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:45.771847 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:12:45.772091 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:12:45.772502 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:12:45.773113 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type



WITH sorted_listing AS (
    SELECT 
        prop.property_type,
        room.room_type,
        list.accommodates,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
SELECT 
    property_type,
    room_type,
    accommodates,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,



    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:12:45.801620 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:45.806937 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:12:45.807291 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:12:45.817441 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:45.819688 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:12:45.820002 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:12:45.830423 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:45.842539 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:12:45.842845 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:12:45.843100 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:12:45.854478 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:45.860131 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:12:45.860433 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:12:45.872568 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:45.873592 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:12:45.656929 => 12:12:45.873466
[0m12:12:45.873870 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:12:45.874488 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080037c0>]}
[0m12:12:45.874896 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.26s]
[0m12:12:45.875292 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:12:45.875573 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m12:12:45.875943 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:12:45.876408 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m12:12:45.876652 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m12:12:45.878785 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:12:45.879357 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 12:12:45.876814 => 12:12:45.879241
[0m12:12:45.879598 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m12:12:45.882218 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:12:45.882644 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:12:45.882862 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m12:12:45.883062 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:45.999926 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:46.000421 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:12:46.000929 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:12:46.019767 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:46.024187 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:12:46.024723 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:12:46.035335 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.039132 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:12:46.039631 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:12:46.052448 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.054521 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:12:46.054905 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:12:46.055250 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:12:46.065369 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:46.070370 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:12:46.070798 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:12:46.082201 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:46.083842 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 12:12:45.879768 => 12:12:46.083622
[0m12:12:46.084315 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m12:12:46.085220 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080a3340>]}
[0m12:12:46.085881 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.21s]
[0m12:12:46.086478 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m12:12:46.086927 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m12:12:46.087502 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:12:46.088263 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m12:12:46.088662 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m12:12:46.091991 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:12:46.092728 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 12:12:46.088936 => 12:12:46.092556
[0m12:12:46.093072 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m12:12:46.096699 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:12:46.097279 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:12:46.097589 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m12:12:46.097881 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:46.262137 [debug] [Thread-1 (]: SQL status: SELECT 207 in 0.0 seconds
[0m12:12:46.269741 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:12:46.270516 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m12:12:46.279918 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.283572 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:12:46.284155 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m12:12:46.293256 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.300203 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:12:46.300755 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:12:46.301161 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:12:46.302250 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:46.302616 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:12:46.303096 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:12:46.311384 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:46.316636 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:12:46.316996 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:46.317350 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m12:12:46.320325 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:12:46.320806 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:12:46.332317 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.334962 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:12:46.335264 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:12:46.336242 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:46.337381 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:12:45.631901 => 12:12:46.337220
[0m12:12:46.337708 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:12:46.338430 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e9bd60>]}
[0m12:12:46.338952 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 207[0m in 0.72s]
[0m12:12:46.339424 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:12:46.339752 [debug] [Thread-1 (]: Began running node model.bde.stg_fact
[0m12:12:46.340090 [info ] [Thread-1 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:12:46.340655 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.stg_fact)
[0m12:12:46.340944 [debug] [Thread-1 (]: Began compiling node model.bde.stg_fact
[0m12:12:46.344735 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:12:46.345008 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.346232 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:12:46.346590 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:12:46.346957 [debug] [Thread-1 (]: Timing info for model.bde.stg_fact (compile): 12:12:46.341135 => 12:12:46.346818
[0m12:12:46.347237 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:12:46.347514 [debug] [Thread-1 (]: Began executing node model.bde.stg_fact
[0m12:12:46.351221 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:12:46.351954 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:12:46.352233 [debug] [Thread-1 (]: On model.bde.stg_fact: BEGIN
[0m12:12:46.352487 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:12:46.359808 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:46.363055 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:12:46.363353 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:12:46.373709 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:46.374676 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 12:12:46.093306 => 12:12:46.374563
[0m12:12:46.374945 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m12:12:46.375517 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080ac670>]}
[0m12:12:46.375917 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.29s]
[0m12:12:46.376316 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m12:12:46.376595 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m12:12:46.377013 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:12:46.377474 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_host)
[0m12:12:46.377716 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m12:12:46.380053 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:12:46.380779 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 12:12:46.377885 => 12:12:46.380658
[0m12:12:46.381029 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m12:12:46.383785 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:12:46.384240 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:12:46.384471 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m12:12:46.384683 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:46.456845 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:46.457308 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:12:46.457731 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:12:46.475270 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:46.478509 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:12:46.478870 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:12:46.489412 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.491912 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:12:46.492251 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:12:46.502284 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.502578 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:46.503965 [debug] [Thread-1 (]: On model.bde.stg_fact: COMMIT
[0m12:12:46.504320 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:12:46.504632 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:12:46.505054 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:12:46.505473 [debug] [Thread-1 (]: On model.bde.stg_fact: COMMIT
[0m12:12:46.518718 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:46.521275 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:12:46.521654 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:46.522044 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:12:46.526571 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:12:46.527024 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:12:46.536479 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.580349 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:46.581295 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:12:46.582322 [debug] [Thread-1 (]: Timing info for model.bde.stg_fact (execute): 12:12:46.347841 => 12:12:46.582209
[0m12:12:46.582590 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:12:46.582842 [debug] [Thread-1 (]: On model.bde.stg_fact: Close
[0m12:12:46.583516 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078f3040>]}
[0m12:12:46.583951 [info ] [Thread-1 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.24s]
[0m12:12:46.584327 [debug] [Thread-1 (]: Finished running node model.bde.stg_fact
[0m12:12:46.584586 [debug] [Thread-1 (]: Began running node model.bde.stg_property
[0m12:12:46.584958 [info ] [Thread-1 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:12:46.585362 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_property)
[0m12:12:46.585562 [debug] [Thread-1 (]: Began compiling node model.bde.stg_property
[0m12:12:46.587326 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:12:46.587833 [debug] [Thread-1 (]: Timing info for model.bde.stg_property (compile): 12:12:46.585695 => 12:12:46.587737
[0m12:12:46.588027 [debug] [Thread-1 (]: Began executing node model.bde.stg_property
[0m12:12:46.590147 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:12:46.590531 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:12:46.590716 [debug] [Thread-1 (]: On model.bde.stg_property: BEGIN
[0m12:12:46.590890 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:12:46.593114 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.594134 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:12:46.594328 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:12:46.594506 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:12:46.603653 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:46.605072 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:12:46.605274 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:12:46.616097 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:46.616935 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 12:12:46.381205 => 12:12:46.616843
[0m12:12:46.617143 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m12:12:46.617636 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078f32e0>]}
[0m12:12:46.617961 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.24s]
[0m12:12:46.618296 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m12:12:46.618527 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m12:12:46.618861 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:12:46.619219 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_room)
[0m12:12:46.619420 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m12:12:46.621220 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:12:46.621664 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 12:12:46.619573 => 12:12:46.621567
[0m12:12:46.621869 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m12:12:46.623978 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:12:46.624332 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:12:46.624520 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m12:12:46.624715 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:46.693844 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:46.694166 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:12:46.694488 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:12:46.707756 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:46.710539 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:12:46.710857 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:12:46.719845 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.722204 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:12:46.722502 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:12:46.731453 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.732668 [debug] [Thread-1 (]: On model.bde.stg_property: COMMIT
[0m12:12:46.732945 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:12:46.733200 [debug] [Thread-1 (]: On model.bde.stg_property: COMMIT
[0m12:12:46.738434 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:46.738693 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:12:46.738975 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:12:46.743379 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:46.746437 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:12:46.746757 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:12:46.753905 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:46.756440 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:12:46.756765 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:12:46.759531 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:46.760525 [debug] [Thread-1 (]: Timing info for model.bde.stg_property (execute): 12:12:46.588160 => 12:12:46.760394
[0m12:12:46.760818 [debug] [Thread-1 (]: On model.bde.stg_property: Close
[0m12:12:46.761440 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10803e950>]}
[0m12:12:46.761897 [info ] [Thread-1 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.18s]
[0m12:12:46.762355 [debug] [Thread-1 (]: Finished running node model.bde.stg_property
[0m12:12:46.762667 [debug] [Thread-1 (]: Began running node model.bde.stg_suburb
[0m12:12:46.763110 [info ] [Thread-1 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:12:46.763616 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_suburb)
[0m12:12:46.763888 [debug] [Thread-1 (]: Began compiling node model.bde.stg_suburb
[0m12:12:46.766074 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:12:46.766659 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (compile): 12:12:46.764078 => 12:12:46.766526
[0m12:12:46.766940 [debug] [Thread-1 (]: Began executing node model.bde.stg_suburb
[0m12:12:46.769798 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:12:46.770169 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.772108 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:12:46.772400 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:12:46.772654 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:12:46.772971 [debug] [Thread-1 (]: On model.bde.stg_suburb: BEGIN
[0m12:12:46.773202 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:12:46.781467 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.782541 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:12:46.782797 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:12:46.783023 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:12:46.796245 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:46.798074 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:12:46.798335 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:12:46.809254 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:46.810271 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 12:12:46.622023 => 12:12:46.810150
[0m12:12:46.810561 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m12:12:46.811140 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ecba00>]}
[0m12:12:46.811555 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.19s]
[0m12:12:46.811972 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m12:12:46.812255 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m12:12:46.812675 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:12:46.813151 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.dim_LGA)
[0m12:12:46.813396 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m12:12:46.815486 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:12:46.816018 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 12:12:46.813568 => 12:12:46.815901
[0m12:12:46.816288 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m12:12:46.819216 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:12:46.819686 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:12:46.819927 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m12:12:46.820140 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:46.873302 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:46.873662 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:12:46.873991 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:12:46.885374 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:12:46.889591 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:12:46.889930 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:12:46.899045 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.901440 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:12:46.901802 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:12:46.910888 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:46.912239 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:12:46.912575 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:12:46.913027 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:12:46.923687 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:46.926222 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:12:46.926610 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:12:46.939589 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:12:46.941032 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (execute): 12:12:46.767133 => 12:12:46.940840
[0m12:12:46.941426 [debug] [Thread-1 (]: On model.bde.stg_suburb: Close
[0m12:12:46.942284 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108031f90>]}
[0m12:12:46.942888 [info ] [Thread-1 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.18s]
[0m12:12:46.943507 [debug] [Thread-1 (]: Finished running node model.bde.stg_suburb
[0m12:12:46.943958 [debug] [Thread-1 (]: Began running node model.bde.fact_G01
[0m12:12:46.944610 [info ] [Thread-1 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:12:46.945351 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.fact_G01)
[0m12:12:46.945744 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G01
[0m12:12:46.948961 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:12:46.949692 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (compile): 12:12:46.946057 => 12:12:46.949530
[0m12:12:46.950026 [debug] [Thread-1 (]: Began executing node model.bde.fact_G01
[0m12:12:46.953440 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:12:46.953923 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:12:46.954196 [debug] [Thread-1 (]: On model.bde.fact_G01: BEGIN
[0m12:12:46.954459 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:12:47.126965 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:47.128350 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:12:47.129012 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:12:47.149949 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:47.151178 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:12:47.152314 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:12:47.158273 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:12:47.159132 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:12:47.159689 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:12:47.172237 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:47.176433 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:12:47.176863 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:12:47.177273 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:12:47.180495 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:12:47.181032 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:12:47.189514 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:47.191408 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:12:47.191779 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:47.192182 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:12:47.194861 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:12:47.196814 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:12:47.197152 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:12:47.207366 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:47.208902 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:12:47.209216 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:47.209527 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:12:47.211829 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:12:47.212190 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:12:47.212501 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:12:47.221865 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:47.224262 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:12:47.224599 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:12:47.226310 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:47.227641 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (execute): 12:12:46.950257 => 12:12:47.227471
[0m12:12:47.227976 [debug] [Thread-1 (]: On model.bde.fact_G01: Close
[0m12:12:47.228826 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ffd090>]}
[0m12:12:47.229439 [info ] [Thread-1 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.28s]
[0m12:12:47.229998 [debug] [Thread-1 (]: Finished running node model.bde.fact_G01
[0m12:12:47.230378 [debug] [Thread-1 (]: Began running node model.bde.fact_G02
[0m12:12:47.230832 [info ] [Thread-1 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:12:47.231425 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_G02)
[0m12:12:47.231759 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G02
[0m12:12:47.234782 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:12:47.235585 [debug] [Thread-1 (]: Timing info for model.bde.fact_G02 (compile): 12:12:47.231984 => 12:12:47.235445
[0m12:12:47.235881 [debug] [Thread-1 (]: Began executing node model.bde.fact_G02
[0m12:12:47.239884 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:12:47.240402 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:47.241861 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 12:12:46.816511 => 12:12:47.241737
[0m12:12:47.242144 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m12:12:47.242569 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:12:47.243089 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080991b0>]}
[0m12:12:47.243360 [debug] [Thread-1 (]: On model.bde.fact_G02: BEGIN
[0m12:12:47.243782 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.43s]
[0m12:12:47.244120 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:12:47.244502 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m12:12:47.244926 [debug] [Thread-4 (]: Began running node model.bde.fact_listing
[0m12:12:47.245270 [info ] [Thread-4 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:12:47.245736 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_listing)
[0m12:12:47.245998 [debug] [Thread-4 (]: Began compiling node model.bde.fact_listing
[0m12:12:47.248312 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:12:47.248804 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (compile): 12:12:47.246176 => 12:12:47.248683
[0m12:12:47.249071 [debug] [Thread-4 (]: Began executing node model.bde.fact_listing
[0m12:12:47.251914 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:12:47.252318 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:12:47.252542 [debug] [Thread-4 (]: On model.bde.fact_listing: BEGIN
[0m12:12:47.252756 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:12:47.369303 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:47.369796 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:47.370241 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:12:47.370652 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:12:47.371059 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:12:47.371520 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:12:47.394314 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:12:47.398165 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:12:47.398598 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:12:47.411267 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:47.414897 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:12:47.415314 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:12:47.424822 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:47.429411 [debug] [Thread-1 (]: On model.bde.fact_G02: COMMIT
[0m12:12:47.429815 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:12:47.430168 [debug] [Thread-1 (]: On model.bde.fact_G02: COMMIT
[0m12:12:47.447200 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:47.450372 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:12:47.450861 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:12:47.470457 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:47.472156 [debug] [Thread-1 (]: Timing info for model.bde.fact_G02 (execute): 12:12:47.236098 => 12:12:47.471954
[0m12:12:47.472562 [debug] [Thread-1 (]: On model.bde.fact_G02: Close
[0m12:12:47.473553 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080984c0>]}
[0m12:12:47.474272 [info ] [Thread-1 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.24s]
[0m12:12:47.474913 [debug] [Thread-1 (]: Finished running node model.bde.fact_G02
[0m12:12:47.475376 [debug] [Thread-1 (]: Began running node model.bde.dim_host
[0m12:12:47.475937 [info ] [Thread-1 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:12:47.476676 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m12:12:47.477058 [debug] [Thread-1 (]: Began compiling node model.bde.dim_host
[0m12:12:47.480347 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:12:47.481231 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (compile): 12:12:47.477289 => 12:12:47.481061
[0m12:12:47.481570 [debug] [Thread-1 (]: Began executing node model.bde.dim_host
[0m12:12:47.484998 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:12:47.485480 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:12:47.485759 [debug] [Thread-1 (]: On model.bde.dim_host: BEGIN
[0m12:12:47.486011 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:12:47.596655 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:47.597480 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:12:47.598008 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:12:48.375301 [debug] [Thread-1 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m12:12:48.382682 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:12:48.383297 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:12:49.502009 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m12:12:49.511827 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:12:49.512443 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:12:49.524367 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:49.527791 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:12:49.528189 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:12:49.550318 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:49.552331 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:12:49.552755 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:12:49.553119 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:12:49.650449 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:49.657631 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:12:49.658229 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:12:49.686637 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:49.688076 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:12:45.654971 => 12:12:49.687930
[0m12:12:49.688400 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:12:49.689198 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080d8f40>]}
[0m12:12:49.689675 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 4.07s]
[0m12:12:49.690103 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:12:49.690424 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m12:12:49.690827 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:12:49.691365 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m12:12:49.691652 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m12:12:49.693854 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:12:49.694429 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 12:12:49.691848 => 12:12:49.694310
[0m12:12:49.694671 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m12:12:49.698658 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:12:49.699340 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:12:49.699606 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m12:12:49.699846 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:12:49.817196 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:49.817769 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:12:49.818163 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:12:50.378838 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m12:12:50.388822 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:12:50.389327 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:12:50.544259 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 5.0 seconds
[0m12:12:50.552936 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:12:50.553734 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m12:12:50.567013 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:50.572430 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:12:50.573042 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m12:12:50.589078 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:50.592333 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:12:50.592847 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:12:50.593284 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:12:50.645650 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 2.0 seconds
[0m12:12:50.647044 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:50.647751 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:50.652895 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:12:50.656196 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:12:50.659119 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:12:50.659542 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:12:50.659938 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m12:12:50.660324 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:12:50.671686 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:50.672078 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:50.674168 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:12:50.675970 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m12:12:50.676358 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:12:50.676731 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:12:50.677101 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:12:50.677463 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m12:12:50.685922 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:50.687401 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:12:45.652733 => 12:12:50.687180
[0m12:12:50.687802 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:12:50.688780 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f871f0>]}
[0m12:12:50.689449 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 5.07s]
[0m12:12:50.690101 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:12:50.690508 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:50.690954 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m12:12:50.691383 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:50.693910 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:12:50.694338 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:12:50.698074 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:12:50.698443 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:12:50.699005 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m12:12:50.699357 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:12:50.699742 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m12:12:50.702375 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:12:50.703223 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 12:12:50.700012 => 12:12:50.703071
[0m12:12:50.703535 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m12:12:50.706652 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:12:50.707166 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:12:50.707414 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m12:12:50.707639 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:12:50.725914 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:50.727200 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 12:12:49.694831 => 12:12:50.727061
[0m12:12:50.727540 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m12:12:50.728225 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081524d0>]}
[0m12:12:50.728651 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 1.04s]
[0m12:12:50.729079 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m12:12:50.729368 [debug] [Thread-2 (]: Began running node model.bde.dim_suburb
[0m12:12:50.729726 [info ] [Thread-2 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:12:50.730211 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dim_property, now model.bde.dim_suburb)
[0m12:12:50.730472 [debug] [Thread-2 (]: Began compiling node model.bde.dim_suburb
[0m12:12:50.732700 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:12:50.733109 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:50.734035 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (execute): 12:12:47.481808 => 12:12:50.733920
[0m12:12:50.734334 [debug] [Thread-2 (]: Timing info for model.bde.dim_suburb (compile): 12:12:50.730648 => 12:12:50.734213
[0m12:12:50.734594 [debug] [Thread-1 (]: On model.bde.dim_host: Close
[0m12:12:50.734859 [debug] [Thread-2 (]: Began executing node model.bde.dim_suburb
[0m12:12:50.737697 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:12:50.738182 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f286d0>]}
[0m12:12:50.738614 [info ] [Thread-1 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 3.26s]
[0m12:12:50.739026 [debug] [Thread-1 (]: Finished running node model.bde.dim_host
[0m12:12:50.739261 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:12:50.739561 [debug] [Thread-2 (]: On model.bde.dim_suburb: BEGIN
[0m12:12:50.739777 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:12:50.809277 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:50.809680 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:12:50.810002 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:12:50.844433 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:12:50.844826 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:12:50.845171 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:12:50.873658 [debug] [Thread-2 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:12:50.877653 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:12:50.878081 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:12:50.887888 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:50.890905 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:12:50.891317 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:12:50.901071 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:50.903493 [debug] [Thread-2 (]: On model.bde.dim_suburb: COMMIT
[0m12:12:50.904009 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:12:50.904456 [debug] [Thread-2 (]: On model.bde.dim_suburb: COMMIT
[0m12:12:51.024459 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:51.031501 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:12:51.032265 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:12:51.057834 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:51.059780 [debug] [Thread-2 (]: Timing info for model.bde.dim_suburb (execute): 12:12:50.735101 => 12:12:51.059542
[0m12:12:51.060290 [debug] [Thread-2 (]: On model.bde.dim_suburb: Close
[0m12:12:51.061471 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10808d120>]}
[0m12:12:51.062272 [info ] [Thread-2 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.33s]
[0m12:12:51.063035 [debug] [Thread-2 (]: Finished running node model.bde.dim_suburb
[0m12:12:51.122393 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:12:51.130322 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:12:51.131007 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:12:51.145705 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:51.152996 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:12:51.153535 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:12:51.155955 [debug] [Thread-4 (]: SQL status: SELECT 340945 in 4.0 seconds
[0m12:12:51.159152 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:12:51.159571 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:12:51.164363 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:51.166135 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:12:51.166518 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:12:51.166857 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:12:51.173015 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:51.175824 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:12:51.176216 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:12:51.187007 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:12:51.188872 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m12:12:51.189251 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:12:51.189599 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m12:12:51.192016 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:51.194756 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:12:51.195146 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:12:51.200668 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:12:51.203252 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:12:51.203648 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:12:51.210927 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:51.213017 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 12:12:50.703739 => 12:12:51.212771
[0m12:12:51.213558 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m12:12:51.214700 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080d9e10>]}
[0m12:12:51.215528 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.52s]
[0m12:12:51.216238 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m12:12:51.240911 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:12:51.244033 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (execute): 12:12:47.249250 => 12:12:51.243760
[0m12:12:51.244625 [debug] [Thread-4 (]: On model.bde.fact_listing: Close
[0m12:12:51.245714 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00a7e14f-1d8a-459d-8ec7-5b3e64f659fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f2add0>]}
[0m12:12:51.246463 [info ] [Thread-4 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 4.00s]
[0m12:12:51.247133 [debug] [Thread-4 (]: Finished running node model.bde.fact_listing
[0m12:12:51.249202 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:51.249969 [debug] [MainThread]: On master: BEGIN
[0m12:12:51.250328 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:12:51.361198 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:12:51.362905 [debug] [MainThread]: On master: COMMIT
[0m12:12:51.363952 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:51.364949 [debug] [MainThread]: On master: COMMIT
[0m12:12:51.377174 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:12:51.378218 [debug] [MainThread]: On master: Close
[0m12:12:51.379977 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:12:51.380508 [debug] [MainThread]: Connection 'model.bde.dim_host' was properly closed.
[0m12:12:51.380931 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:12:51.381305 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:12:51.381677 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:12:51.382380 [info ] [MainThread]: 
[0m12:12:51.382899 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 6.50 seconds (6.50s).
[0m12:12:51.387106 [debug] [MainThread]: Command end result
[0m12:12:51.398505 [info ] [MainThread]: 
[0m12:12:51.398966 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:12:51.399334 [info ] [MainThread]: 
[0m12:12:51.399665 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m12:12:51.400326 [debug] [MainThread]: Command `dbt run` succeeded at 12:12:51.400239 after 6.64 seconds
[0m12:12:51.400728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055ad690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f4e6b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fde050>]}
[0m12:12:51.401104 [debug] [MainThread]: Flushing usage events
[0m12:13:54.056532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1029d98a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d4dae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d4d3c0>]}


============================== 12:13:54.059039 | 1e875b48-64a8-47b3-a2be-eec32849a254 ==============================
[0m12:13:54.059039 [info ] [MainThread]: Running with dbt=1.6.6
[0m12:13:54.059364 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:13:54.108745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d4d630>]}
[0m12:13:54.116459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106239180>]}
[0m12:13:54.116854 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m12:13:54.125580 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m12:13:54.147878 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:13:54.148272 [debug] [MainThread]: Partial parsing: updated file: bde://models/datamart/dm_host_neighbourhod.sql
[0m12:13:54.168282 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.raw
- models.bde.median
[0m12:13:54.171284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106844c40>]}
[0m12:13:54.176845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10665ad10>]}
[0m12:13:54.177081 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m12:13:54.177262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10665aef0>]}
[0m12:13:54.178406 [info ] [MainThread]: 
[0m12:13:54.178758 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:13:54.179534 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:13:54.179988 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:13:54.184788 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:13:54.185104 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:13:54.186053 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:13:54.186236 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:13:54.187110 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:13:54.187274 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:13:54.187476 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:13:54.187632 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:13:54.187770 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:13:54.188590 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:13:54.336458 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:13:54.337784 [debug] [ThreadPool]: On list_postgres: Close
[0m12:13:54.338410 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:13:54.338653 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:13:54.339498 [debug] [ThreadPool]: On list_postgres: Close
[0m12:13:54.340252 [debug] [ThreadPool]: On list_postgres: Close
[0m12:13:54.343175 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m12:13:54.343701 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_warehouse)
[0m12:13:54.344170 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_staging)
[0m12:13:54.348837 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:13:54.349352 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_datamart'
[0m12:13:54.350578 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:13:54.351772 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:13:54.351999 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m12:13:54.353124 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:13:54.353346 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m12:13:54.353546 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m12:13:54.353740 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:13:54.353922 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m12:13:54.354110 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:13:54.354291 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:13:54.354572 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:13:54.457424 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:13:54.457853 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:13:54.458137 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m12:13:54.458417 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:13:54.458677 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:13:54.458965 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:13:54.459198 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:13:54.459458 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m12:13:54.459750 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m12:13:54.460020 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:13:54.460322 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:13:54.460574 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m12:13:54.472980 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:13:54.474015 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m12:13:54.475476 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:13:54.476321 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m12:13:54.478498 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:13:54.479286 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m12:13:54.479522 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:13:54.480358 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m12:13:54.482442 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m12:13:54.486484 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m12:13:54.488185 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m12:13:54.489436 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m12:13:54.494418 [debug] [MainThread]: Using postgres connection "master"
[0m12:13:54.494699 [debug] [MainThread]: On master: BEGIN
[0m12:13:54.494931 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:13:54.588837 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:13:54.589261 [debug] [MainThread]: Using postgres connection "master"
[0m12:13:54.589705 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:13:54.614210 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:13:54.616634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067f9750>]}
[0m12:13:54.617072 [debug] [MainThread]: On master: ROLLBACK
[0m12:13:54.626871 [debug] [MainThread]: Using postgres connection "master"
[0m12:13:54.627284 [debug] [MainThread]: On master: BEGIN
[0m12:13:54.644133 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:13:54.644479 [debug] [MainThread]: On master: COMMIT
[0m12:13:54.644804 [debug] [MainThread]: Using postgres connection "master"
[0m12:13:54.645112 [debug] [MainThread]: On master: COMMIT
[0m12:13:54.655067 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:13:54.655408 [debug] [MainThread]: On master: Close
[0m12:13:54.656332 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:13:54.656730 [info ] [MainThread]: 
[0m12:13:54.661268 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m12:13:54.661719 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m12:13:54.662129 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m12:13:54.662500 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m12:13:54.662983 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m12:13:54.663672 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m12:13:54.664457 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m12:13:54.665046 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m12:13:54.665725 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_host_neighbourhod)
[0m12:13:54.666299 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.dm_listing_neighbourhood)
[0m12:13:54.666840 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.dm_property_type)
[0m12:13:54.667347 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.stg_G01)
[0m12:13:54.667689 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m12:13:54.668037 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m12:13:54.668360 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m12:13:54.668655 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m12:13:54.676037 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m12:13:54.678863 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m12:13:54.682270 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m12:13:54.684757 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m12:13:54.685499 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 12:13:54.668895 => 12:13:54.685347
[0m12:13:54.685944 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m12:13:54.686346 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 12:13:54.676397 => 12:13:54.686185
[0m12:13:54.693033 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 12:13:54.679156 => 12:13:54.692894
[0m12:13:54.699613 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 12:13:54.682537 => 12:13:54.699477
[0m12:13:54.711704 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m12:13:54.711964 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m12:13:54.712202 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m12:13:54.712404 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m12:13:54.714692 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m12:13:54.716861 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m12:13:54.717118 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:13:54.726971 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m12:13:54.727447 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m12:13:54.727690 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:13:54.727903 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:13:54.728152 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:13:54.728375 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m12:13:54.728553 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:13:54.728741 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m12:13:54.729020 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:13:54.729207 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m12:13:54.729383 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:13:54.729641 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:13:54.831296 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:54.831688 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:13:54.832102 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type



WITH sorted_listing AS (
    SELECT 
        prop.property_type,
        room.room_type,
        list.accommodates,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
SELECT 
    property_type,
    room_type,
    accommodates,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,



    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:13:54.833137 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:54.833349 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:13:54.833687 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:13:54.835354 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:54.835557 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:13:54.835916 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m12:13:54.839162 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:54.839361 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:13:54.839625 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.lga_name AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM 
        warehouse.dim_host host
    LEFT JOIN 
        warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.suburb_name
),
distinct_host_count AS (
    SELECT
        TO_CHAR(h.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        COUNT(DISTINCT h.host_id) AS num_distinct_hosts
    FROM
        host_neighbourhood_lga_transform h
    GROUP BY
        TO_CHAR(h.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
),
estimated_revenue AS (
    SELECT
        TO_CHAR(l.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        SUM((30 - l.availability_30) * l.price) AS total_estimated_revenue
    FROM
        warehouse.facts_listings l
    LEFT JOIN
        host_neighbourhood_lga_transform h ON l.surrogate_key_host = h.surrogate_key_host
    WHERE
        l.has_availability = 't'
    GROUP BY
        TO_CHAR(l.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
)
SELECT
    dhct.month_year,
    dhct.host_neighbourhood_lga,
    dhct.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dhct.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dhct.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM
    distinct_host_count dhct
LEFT JOIN
    estimated_revenue er ON dhct.month_year = er.month_year AND dhct.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY
    dhct.month_year, dhct.host_neighbourhood_lga
  );
  
[0m12:13:54.861548 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:13:54.866676 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:13:54.866986 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column suburb.suburb_name does not exist
LINE 22: ...se.dim_suburb suburb ON host.host_neighbourhood = suburb.sub...
                                                              ^

[0m12:13:54.867291 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:13:54.867566 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: ROLLBACK
[0m12:13:54.878575 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:13:54.686613 => 12:13:54.878399
[0m12:13:54.878848 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:54.879160 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:13:54.881125 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:13:54.881420 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:13:54.886488 [debug] [Thread-1 (]: Database Error in model dm_host_neighbourhod (models/datamart/dm_host_neighbourhod.sql)
  column suburb.suburb_name does not exist
  LINE 22: ...se.dim_suburb suburb ON host.host_neighbourhood = suburb.sub...
                                                                ^
  compiled Code at target/run/bde/models/datamart/dm_host_neighbourhod.sql
[0m12:13:54.886822 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106876bc0>]}
[0m12:13:54.887235 [error] [Thread-1 (]: 1 of 19 ERROR creating sql table model datamart.dm_host_neighbourhod ........... [[31mERROR[0m in 0.22s]
[0m12:13:54.887591 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:13:54.887830 [debug] [Thread-1 (]: Began running node model.bde.stg_G02
[0m12:13:54.888129 [info ] [Thread-1 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:13:54.888478 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.stg_G02)
[0m12:13:54.888677 [debug] [Thread-1 (]: Began compiling node model.bde.stg_G02
[0m12:13:54.890645 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:13:54.891079 [debug] [Thread-1 (]: Timing info for model.bde.stg_G02 (compile): 12:13:54.888820 => 12:13:54.890982
[0m12:13:54.891274 [debug] [Thread-1 (]: Began executing node model.bde.stg_G02
[0m12:13:54.893553 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:13:54.893771 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:54.902505 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:13:54.902755 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:13:54.902953 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:13:54.903179 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:13:54.903391 [debug] [Thread-1 (]: On model.bde.stg_G02: BEGIN
[0m12:13:54.903599 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:13:54.913670 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:54.918608 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:13:54.918979 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:13:54.931108 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:13:54.932072 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:13:54.717270 => 12:13:54.931960
[0m12:13:54.932310 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:13:54.932839 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106916bf0>]}
[0m12:13:54.933183 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.27s]
[0m12:13:54.933517 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:13:54.933752 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m12:13:54.934047 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:13:54.934441 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_LGA)
[0m12:13:54.934668 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m12:13:54.936608 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:13:54.937110 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 12:13:54.934807 => 12:13:54.937014
[0m12:13:54.937309 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m12:13:54.939512 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:13:54.939892 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:13:54.940077 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m12:13:54.940244 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:13:55.012887 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:55.013331 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:13:55.013659 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:13:55.029598 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:13:55.032297 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:13:55.032605 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:13:55.043597 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.046885 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:13:55.047156 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:13:55.049404 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:55.049657 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:13:55.049937 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:13:55.057255 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.058386 [debug] [Thread-1 (]: On model.bde.stg_G02: COMMIT
[0m12:13:55.058642 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:13:55.058878 [debug] [Thread-1 (]: On model.bde.stg_G02: COMMIT
[0m12:13:55.063735 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:13:55.066086 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:13:55.066365 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:13:55.071688 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:55.073516 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:13:55.073808 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:13:55.075945 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.077867 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:13:55.078157 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:13:55.085354 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:13:55.086338 [debug] [Thread-1 (]: Timing info for model.bde.stg_G02 (execute): 12:13:54.891414 => 12:13:55.086207
[0m12:13:55.086621 [debug] [Thread-1 (]: On model.bde.stg_G02: Close
[0m12:13:55.087316 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106659840>]}
[0m12:13:55.088002 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.087765 [info ] [Thread-1 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.20s]
[0m12:13:55.089228 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:13:55.089616 [debug] [Thread-1 (]: Finished running node model.bde.stg_G02
[0m12:13:55.089877 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:13:55.090185 [debug] [Thread-1 (]: Began running node model.bde.stg_fact
[0m12:13:55.090510 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:13:55.090844 [info ] [Thread-1 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:13:55.091340 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_fact)
[0m12:13:55.091580 [debug] [Thread-1 (]: Began compiling node model.bde.stg_fact
[0m12:13:55.094066 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:13:55.094687 [debug] [Thread-1 (]: Timing info for model.bde.stg_fact (compile): 12:13:55.091771 => 12:13:55.094565
[0m12:13:55.094935 [debug] [Thread-1 (]: Began executing node model.bde.stg_fact
[0m12:13:55.097597 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:13:55.098062 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:13:55.098298 [debug] [Thread-1 (]: On model.bde.stg_fact: BEGIN
[0m12:13:55.098498 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:13:55.111563 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:55.113421 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:13:55.113669 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:13:55.124081 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:13:55.125006 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 12:13:54.937445 => 12:13:55.124892
[0m12:13:55.125266 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m12:13:55.125950 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106879d50>]}
[0m12:13:55.126400 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.19s]
[0m12:13:55.126818 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m12:13:55.127115 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m12:13:55.127556 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:13:55.128038 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_host)
[0m12:13:55.128336 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m12:13:55.130710 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:13:55.131292 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 12:13:55.128540 => 12:13:55.131173
[0m12:13:55.131534 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m12:13:55.135038 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:13:55.135440 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:13:55.135652 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m12:13:55.135853 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:13:55.218882 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:55.219323 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:13:55.219757 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:13:55.237006 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:13:55.267125 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:55.268368 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:13:55.268666 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:13:55.268919 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:13:55.269234 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:13:55.279058 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.280876 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:13:55.281107 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:13:55.285455 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:13:55.287643 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:13:55.287887 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:13:55.290924 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.291961 [debug] [Thread-1 (]: On model.bde.stg_fact: COMMIT
[0m12:13:55.292194 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:13:55.292404 [debug] [Thread-1 (]: On model.bde.stg_fact: COMMIT
[0m12:13:55.296427 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.298211 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:13:55.298449 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:13:55.302592 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:55.304279 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:13:55.304519 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:13:55.307159 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.308151 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:13:55.308384 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:13:55.308610 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:13:55.315904 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:13:55.316811 [debug] [Thread-1 (]: Timing info for model.bde.stg_fact (execute): 12:13:55.095113 => 12:13:55.316682
[0m12:13:55.317084 [debug] [Thread-1 (]: On model.bde.stg_fact: Close
[0m12:13:55.317682 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c036a0>]}
[0m12:13:55.318321 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:55.318125 [info ] [Thread-1 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.23s]
[0m12:13:55.320083 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:13:55.320462 [debug] [Thread-1 (]: Finished running node model.bde.stg_fact
[0m12:13:55.320717 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:13:55.320991 [debug] [Thread-1 (]: Began running node model.bde.stg_property
[0m12:13:55.321439 [info ] [Thread-1 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:13:55.321883 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_property)
[0m12:13:55.322113 [debug] [Thread-1 (]: Began compiling node model.bde.stg_property
[0m12:13:55.324308 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:13:55.324921 [debug] [Thread-1 (]: Timing info for model.bde.stg_property (compile): 12:13:55.322269 => 12:13:55.324808
[0m12:13:55.325183 [debug] [Thread-1 (]: Began executing node model.bde.stg_property
[0m12:13:55.328468 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:13:55.328896 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:13:55.329131 [debug] [Thread-1 (]: On model.bde.stg_property: BEGIN
[0m12:13:55.329335 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:13:55.330547 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:13:55.331310 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 12:13:55.131698 => 12:13:55.331217
[0m12:13:55.331532 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m12:13:55.331989 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c2d420>]}
[0m12:13:55.332322 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.20s]
[0m12:13:55.332663 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m12:13:55.332916 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m12:13:55.333238 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:13:55.333619 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_room)
[0m12:13:55.333830 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m12:13:55.335576 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:13:55.336001 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 12:13:55.333978 => 12:13:55.335901
[0m12:13:55.336202 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m12:13:55.338402 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:13:55.338918 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:13:55.339226 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m12:13:55.339447 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:13:55.438759 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:55.439250 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:13:55.439613 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:13:55.445945 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:55.446295 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:13:55.446600 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:13:55.453320 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:13:55.456226 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:13:55.456519 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:13:55.458693 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:13:55.461050 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:13:55.461351 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:13:55.466418 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.468385 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:13:55.468652 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:13:55.470980 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.472857 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:13:55.473123 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:13:55.479180 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.480356 [debug] [Thread-1 (]: On model.bde.stg_property: COMMIT
[0m12:13:55.480642 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:13:55.480889 [debug] [Thread-1 (]: On model.bde.stg_property: COMMIT
[0m12:13:55.483887 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.484986 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:13:55.485230 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:13:55.485447 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:13:55.490964 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:55.493150 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:13:55.493491 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:13:55.495086 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:55.497078 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:13:55.497390 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:13:55.506178 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:13:55.508547 [debug] [Thread-1 (]: Timing info for model.bde.stg_property (execute): 12:13:55.325343 => 12:13:55.508413
[0m12:13:55.508820 [debug] [Thread-1 (]: On model.bde.stg_property: Close
[0m12:13:55.509439 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106659270>]}
[0m12:13:55.509860 [info ] [Thread-1 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.19s]
[0m12:13:55.510244 [debug] [Thread-1 (]: Finished running node model.bde.stg_property
[0m12:13:55.510548 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:13:55.510842 [debug] [Thread-1 (]: Began running node model.bde.stg_suburb
[0m12:13:55.511827 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 12:13:55.336344 => 12:13:55.511720
[0m12:13:55.512214 [info ] [Thread-1 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:13:55.512489 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m12:13:55.512904 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_suburb)
[0m12:13:55.513225 [debug] [Thread-1 (]: Began compiling node model.bde.stg_suburb
[0m12:13:55.513672 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069167d0>]}
[0m12:13:55.515858 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:13:55.516233 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.18s]
[0m12:13:55.516752 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m12:13:55.517065 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m12:13:55.517481 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:13:55.517784 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (compile): 12:13:55.513855 => 12:13:55.517659
[0m12:13:55.518210 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.dim_LGA)
[0m12:13:55.518446 [debug] [Thread-1 (]: Began executing node model.bde.stg_suburb
[0m12:13:55.518660 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m12:13:55.521294 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:13:55.523071 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:13:55.523710 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:13:55.524042 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 12:13:55.521498 => 12:13:55.523911
[0m12:13:55.524327 [debug] [Thread-1 (]: On model.bde.stg_suburb: BEGIN
[0m12:13:55.524584 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m12:13:55.524879 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:13:55.527432 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:13:55.528100 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:13:55.528389 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m12:13:55.528600 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:13:55.723118 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:55.723931 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:13:55.724412 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:13:55.725227 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:55.725633 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:13:55.726065 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:13:55.736576 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:13:55.740167 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:13:55.740530 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:13:55.742258 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:13:55.744733 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:13:55.745060 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:13:55.749544 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.751672 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:13:55.751959 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:13:55.755567 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.757622 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:13:55.757911 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:13:55.760537 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.761662 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:13:55.763296 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:13:55.763535 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:13:55.766629 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.770511 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:13:55.770818 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:13:55.771084 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:13:55.773452 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:55.775269 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:13:55.775546 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:13:55.781671 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:55.784822 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:13:55.785110 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:13:55.790276 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:13:55.791234 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (execute): 12:13:55.518815 => 12:13:55.791106
[0m12:13:55.791516 [debug] [Thread-1 (]: On model.bde.stg_suburb: Close
[0m12:13:55.792164 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106796d40>]}
[0m12:13:55.792619 [info ] [Thread-1 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.28s]
[0m12:13:55.793028 [debug] [Thread-1 (]: Finished running node model.bde.stg_suburb
[0m12:13:55.793343 [debug] [Thread-1 (]: Began running node model.bde.fact_G01
[0m12:13:55.793787 [info ] [Thread-1 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:13:55.794283 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.fact_G01)
[0m12:13:55.794540 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G01
[0m12:13:55.796782 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:13:55.797410 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (compile): 12:13:55.794727 => 12:13:55.797276
[0m12:13:55.797665 [debug] [Thread-1 (]: Began executing node model.bde.fact_G01
[0m12:13:55.800363 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:13:55.800648 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:13:55.801633 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 12:13:55.525057 => 12:13:55.801526
[0m12:13:55.801874 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m12:13:55.802217 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:13:55.802635 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bf63e0>]}
[0m12:13:55.802863 [debug] [Thread-1 (]: On model.bde.fact_G01: BEGIN
[0m12:13:55.803197 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.28s]
[0m12:13:55.803483 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:13:55.803847 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m12:13:55.804217 [debug] [Thread-4 (]: Began running node model.bde.fact_G02
[0m12:13:55.804534 [info ] [Thread-4 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:13:55.804932 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G02)
[0m12:13:55.805143 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G02
[0m12:13:55.807115 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:13:55.807566 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (compile): 12:13:55.805291 => 12:13:55.807458
[0m12:13:55.807780 [debug] [Thread-4 (]: Began executing node model.bde.fact_G02
[0m12:13:55.810311 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:13:55.810827 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:13:55.811045 [debug] [Thread-4 (]: On model.bde.fact_G02: BEGIN
[0m12:13:55.811237 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:13:55.923904 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:55.924358 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:13:55.924656 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:13:55.925810 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:55.926129 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:13:55.926397 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:13:55.944744 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:13:55.947541 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:13:55.947788 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:13:55.948066 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:13:55.951300 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:13:55.951635 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:13:55.960527 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.962393 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:13:55.962634 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.962889 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:13:55.964690 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:13:55.964994 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:13:55.974843 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.975096 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:55.976573 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:13:55.977788 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:13:55.978066 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:13:55.978332 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:13:55.978567 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:13:55.978796 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:13:55.991525 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:55.991760 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:55.993564 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:13:55.995293 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:13:55.995554 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:13:55.995794 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:13:56.010894 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:13:56.012060 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (execute): 12:13:55.797828 => 12:13:56.011911
[0m12:13:56.012322 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:13:56.012623 [debug] [Thread-1 (]: On model.bde.fact_G01: Close
[0m12:13:56.013519 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (execute): 12:13:55.807932 => 12:13:56.013408
[0m12:13:56.013839 [debug] [Thread-4 (]: On model.bde.fact_G02: Close
[0m12:13:56.014329 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b84d30>]}
[0m12:13:56.015222 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10623b580>]}
[0m12:13:56.014799 [info ] [Thread-1 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.22s]
[0m12:13:56.015684 [info ] [Thread-4 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.21s]
[0m12:13:56.016076 [debug] [Thread-1 (]: Finished running node model.bde.fact_G01
[0m12:13:56.016423 [debug] [Thread-4 (]: Finished running node model.bde.fact_G02
[0m12:13:56.016736 [debug] [Thread-1 (]: Began running node model.bde.fact_listing
[0m12:13:56.017076 [debug] [Thread-4 (]: Began running node model.bde.dim_host
[0m12:13:56.017406 [info ] [Thread-1 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:13:56.017771 [info ] [Thread-4 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:13:56.018224 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_listing)
[0m12:13:56.018615 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m12:13:56.018859 [debug] [Thread-1 (]: Began compiling node model.bde.fact_listing
[0m12:13:56.019083 [debug] [Thread-4 (]: Began compiling node model.bde.dim_host
[0m12:13:56.021337 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:13:56.023105 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:13:56.023711 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (compile): 12:13:56.021525 => 12:13:56.023602
[0m12:13:56.023972 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (compile): 12:13:56.019253 => 12:13:56.023860
[0m12:13:56.024206 [debug] [Thread-4 (]: Began executing node model.bde.dim_host
[0m12:13:56.024471 [debug] [Thread-1 (]: Began executing node model.bde.fact_listing
[0m12:13:56.027134 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:13:56.030596 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:13:56.031090 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:13:56.031311 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:13:56.031517 [debug] [Thread-1 (]: On model.bde.fact_listing: BEGIN
[0m12:13:56.031720 [debug] [Thread-4 (]: On model.bde.dim_host: BEGIN
[0m12:13:56.031919 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:13:56.032112 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:13:56.141964 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:56.142422 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:13:56.142804 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:13:56.144222 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:56.144674 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:13:56.145081 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:13:56.928395 [debug] [Thread-4 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m12:13:56.935805 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:13:56.936596 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:13:58.725019 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m12:13:58.734560 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:13:58.735384 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:13:58.744727 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:58.748447 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:13:58.748887 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:13:58.761109 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:58.763090 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:13:58.763487 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:13:58.763849 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:13:58.780472 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:58.783859 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:13:58.784359 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:13:58.802940 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:13:58.806686 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:13:54.712610 => 12:13:58.806354
[0m12:13:58.807459 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:13:58.809096 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068d9090>]}
[0m12:13:58.810100 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 4.14s]
[0m12:13:58.811013 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:13:58.811589 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m12:13:58.812262 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:13:58.813207 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m12:13:58.813678 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m12:13:58.817479 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:13:58.818557 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 12:13:58.813943 => 12:13:58.818350
[0m12:13:58.818972 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m12:13:58.823145 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:13:58.823790 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:13:58.824113 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m12:13:58.824422 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:13:58.930641 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:58.931586 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:13:58.932152 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:13:59.441540 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m12:13:59.450284 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:13:59.451396 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:13:59.453713 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 5.0 seconds
[0m12:13:59.458143 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:13:59.458622 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m12:13:59.468774 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:59.473783 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:13:59.474199 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m12:13:59.484740 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:59.486594 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:13:59.487022 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:13:59.487397 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:13:59.517333 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:59.518253 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:59.518810 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 3.0 seconds
[0m12:13:59.523555 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:13:59.527432 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:13:59.530341 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:13:59.530775 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m12:13:59.531190 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:13:59.531585 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:13:59.541890 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:59.543727 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:13:59.544108 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:59.544494 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:13:59.546258 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:13:59.546647 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:13:59.547014 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:13:59.547469 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:13:59.625993 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:13:59.627588 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:59.628700 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:59.631459 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:13:54.714905 => 12:13:59.631169
[0m12:13:59.636048 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:13:59.639636 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:13:59.640119 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:13:59.640560 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:13:59.640960 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:13:59.642086 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10688ae90>]}
[0m12:13:59.642763 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 4.98s]
[0m12:13:59.643403 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:13:59.643843 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m12:13:59.644348 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:13:59.645054 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m12:13:59.645410 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m12:13:59.648460 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:13:59.649350 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 12:13:59.645646 => 12:13:59.649173
[0m12:13:59.649711 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m12:13:59.653208 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:13:59.653778 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:13:59.654059 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m12:13:59.654358 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:13:59.665210 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:13:59.666559 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 12:13:58.819260 => 12:13:59.666413
[0m12:13:59.666879 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m12:13:59.667609 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106be0370>]}
[0m12:13:59.668102 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 0.85s]
[0m12:13:59.668559 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m12:13:59.668888 [debug] [Thread-2 (]: Began running node model.bde.dim_suburb
[0m12:13:59.669273 [info ] [Thread-2 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:13:59.669750 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dim_property, now model.bde.dim_suburb)
[0m12:13:59.669998 [debug] [Thread-2 (]: Began compiling node model.bde.dim_suburb
[0m12:13:59.673450 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:13:59.673725 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:13:59.674758 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (execute): 12:13:56.024638 => 12:13:59.674631
[0m12:13:59.675237 [debug] [Thread-4 (]: On model.bde.dim_host: Close
[0m12:13:59.675698 [debug] [Thread-2 (]: Timing info for model.bde.dim_suburb (compile): 12:13:59.670177 => 12:13:59.675505
[0m12:13:59.676069 [debug] [Thread-2 (]: Began executing node model.bde.dim_suburb
[0m12:13:59.676520 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b7a1a0>]}
[0m12:13:59.679301 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:13:59.679692 [info ] [Thread-4 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 3.66s]
[0m12:13:59.680204 [debug] [Thread-4 (]: Finished running node model.bde.dim_host
[0m12:13:59.680633 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:13:59.680872 [debug] [Thread-2 (]: On model.bde.dim_suburb: BEGIN
[0m12:13:59.681100 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:13:59.754437 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:59.754907 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:13:59.755286 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:13:59.794173 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:13:59.794524 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:13:59.794862 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:13:59.816809 [debug] [Thread-2 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:13:59.819240 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:13:59.819515 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:13:59.839665 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:59.841575 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:13:59.841836 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:13:59.851813 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:13:59.853183 [debug] [Thread-2 (]: On model.bde.dim_suburb: COMMIT
[0m12:13:59.853453 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:13:59.853689 [debug] [Thread-2 (]: On model.bde.dim_suburb: COMMIT
[0m12:13:59.878028 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:13:59.879954 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:13:59.880249 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:13:59.899751 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:13:59.900789 [debug] [Thread-2 (]: Timing info for model.bde.dim_suburb (execute): 12:13:59.676733 => 12:13:59.900657
[0m12:13:59.901086 [debug] [Thread-2 (]: On model.bde.dim_suburb: Close
[0m12:13:59.901715 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ccd1e0>]}
[0m12:13:59.902147 [info ] [Thread-2 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.23s]
[0m12:13:59.902566 [debug] [Thread-2 (]: Finished running node model.bde.dim_suburb
[0m12:14:00.010846 [debug] [Thread-1 (]: SQL status: SELECT 340945 in 4.0 seconds
[0m12:14:00.013679 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:14:00.014005 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:14:00.014395 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:14:00.016508 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:14:00.016785 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:14:00.022884 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:00.024949 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:14:00.025233 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:14:00.025526 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:00.027531 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:14:00.027782 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:14:00.035115 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:00.037643 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:14:00.037900 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:00.038152 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:14:00.039353 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:14:00.039601 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:14:00.039835 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:14:00.040121 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:14:00.107370 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:14:00.107694 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:14:00.110067 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:14:00.112334 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:14:00.112695 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:14:00.113031 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:14:00.130887 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:14:00.132104 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 12:13:59.649954 => 12:14:00.131957
[0m12:14:00.132419 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m12:14:00.133123 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e02d750>]}
[0m12:14:00.133602 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.49s]
[0m12:14:00.134065 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m12:14:00.150122 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:14:00.151273 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (execute): 12:13:56.027363 => 12:14:00.151136
[0m12:14:00.151601 [debug] [Thread-1 (]: On model.bde.fact_listing: Close
[0m12:14:00.152308 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e875b48-64a8-47b3-a2be-eec32849a254', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106659150>]}
[0m12:14:00.152758 [info ] [Thread-1 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 4.13s]
[0m12:14:00.153222 [debug] [Thread-1 (]: Finished running node model.bde.fact_listing
[0m12:14:00.154440 [debug] [MainThread]: Using postgres connection "master"
[0m12:14:00.154698 [debug] [MainThread]: On master: BEGIN
[0m12:14:00.154926 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:14:00.248248 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:14:00.248772 [debug] [MainThread]: On master: COMMIT
[0m12:14:00.249110 [debug] [MainThread]: Using postgres connection "master"
[0m12:14:00.249423 [debug] [MainThread]: On master: COMMIT
[0m12:14:00.259171 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:14:00.259510 [debug] [MainThread]: On master: Close
[0m12:14:00.260322 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:14:00.260634 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:14:00.260931 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:14:00.261200 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:14:00.261476 [debug] [MainThread]: Connection 'model.bde.dim_host' was properly closed.
[0m12:14:00.261900 [info ] [MainThread]: 
[0m12:14:00.262285 [info ] [MainThread]: Finished running 11 table models, 8 view models in 0 hours 0 minutes and 6.08 seconds (6.08s).
[0m12:14:00.265269 [debug] [MainThread]: Command end result
[0m12:14:00.275933 [info ] [MainThread]: 
[0m12:14:00.276468 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m12:14:00.276760 [info ] [MainThread]: 
[0m12:14:00.277027 [error] [MainThread]:   Database Error in model dm_host_neighbourhod (models/datamart/dm_host_neighbourhod.sql)
  column suburb.suburb_name does not exist
  LINE 22: ...se.dim_suburb suburb ON host.host_neighbourhood = suburb.sub...
                                                                ^
  compiled Code at target/run/bde/models/datamart/dm_host_neighbourhod.sql
[0m12:14:00.277316 [info ] [MainThread]: 
[0m12:14:00.277583 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m12:14:00.278158 [debug] [MainThread]: Command `dbt run` failed at 12:14:00.278082 after 6.23 seconds
[0m12:14:00.278537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1029d98a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10623b250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068e5d20>]}
[0m12:14:00.278890 [debug] [MainThread]: Flushing usage events
[0m12:15:34.146090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103511810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10684db10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10684d3f0>]}


============================== 12:15:34.148642 | b1bb283f-e7c6-4a3e-b3cb-ed099289a59f ==============================
[0m12:15:34.148642 [info ] [MainThread]: Running with dbt=1.6.6
[0m12:15:34.148962 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:15:34.206618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10684d660>]}
[0m12:15:34.214793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bb11b0>]}
[0m12:15:34.215302 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m12:15:34.225239 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m12:15:34.248262 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:15:34.248644 [debug] [MainThread]: Partial parsing: updated file: bde://models/datamart/dm_host_neighbourhod.sql
[0m12:15:34.268927 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.median
- models.bde.raw
[0m12:15:34.271719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107210c70>]}
[0m12:15:34.277935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107026d40>]}
[0m12:15:34.278194 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m12:15:34.278372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107026f20>]}
[0m12:15:34.279498 [info ] [MainThread]: 
[0m12:15:34.279888 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:15:34.280715 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:15:34.281153 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:15:34.285877 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:15:34.286172 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:15:34.287069 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:15:34.287267 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:15:34.288083 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:15:34.288249 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:15:34.288442 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:15:34.288586 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:15:34.288724 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:15:34.289537 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:15:34.435325 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:15:34.436721 [debug] [ThreadPool]: On list_postgres: Close
[0m12:15:34.440723 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:15:34.440959 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:15:34.441778 [debug] [ThreadPool]: On list_postgres: Close
[0m12:15:34.442569 [debug] [ThreadPool]: On list_postgres: Close
[0m12:15:34.444657 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m12:15:34.445146 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m12:15:34.445633 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_warehouse)
[0m12:15:34.450137 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:15:34.450588 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_staging'
[0m12:15:34.451839 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:15:34.452927 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:15:34.453138 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m12:15:34.454287 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:15:34.454496 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m12:15:34.454682 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m12:15:34.454856 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:15:34.455033 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m12:15:34.455201 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:15:34.455374 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:15:34.455653 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:15:34.546706 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:15:34.547161 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:15:34.547446 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m12:15:34.549376 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:15:34.549600 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:15:34.549838 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m12:15:34.562619 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:15:34.563681 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m12:15:34.563931 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:15:34.564192 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:15:34.564493 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:15:34.564738 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:15:34.564996 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m12:15:34.565284 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m12:15:34.565654 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:15:34.566530 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m12:15:34.574530 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m12:15:34.578492 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m12:15:34.583056 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:15:34.583899 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m12:15:34.586286 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:15:34.587169 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m12:15:34.592464 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m12:15:34.598426 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m12:15:34.603056 [debug] [MainThread]: Using postgres connection "master"
[0m12:15:34.603318 [debug] [MainThread]: On master: BEGIN
[0m12:15:34.603518 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:15:34.693696 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:15:34.694023 [debug] [MainThread]: Using postgres connection "master"
[0m12:15:34.694355 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:15:34.724558 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:15:34.726788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107186bf0>]}
[0m12:15:34.727197 [debug] [MainThread]: On master: ROLLBACK
[0m12:15:34.735539 [debug] [MainThread]: Using postgres connection "master"
[0m12:15:34.735794 [debug] [MainThread]: On master: BEGIN
[0m12:15:34.753092 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:15:34.753412 [debug] [MainThread]: On master: COMMIT
[0m12:15:34.753743 [debug] [MainThread]: Using postgres connection "master"
[0m12:15:34.753989 [debug] [MainThread]: On master: COMMIT
[0m12:15:34.762610 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:15:34.762996 [debug] [MainThread]: On master: Close
[0m12:15:34.763740 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:15:34.764073 [info ] [MainThread]: 
[0m12:15:34.767477 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m12:15:34.767842 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m12:15:34.768174 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m12:15:34.768472 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m12:15:34.768857 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m12:15:34.769285 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m12:15:34.769985 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m12:15:34.770623 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m12:15:34.771245 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_host_neighbourhod)
[0m12:15:34.771700 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_listing_neighbourhood)
[0m12:15:34.772116 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.dm_property_type)
[0m12:15:34.772527 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.stg_G01)
[0m12:15:34.772830 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m12:15:34.773125 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m12:15:34.773376 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m12:15:34.773621 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m12:15:34.779806 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m12:15:34.782439 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m12:15:34.785610 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m12:15:34.787739 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m12:15:34.788482 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 12:15:34.773814 => 12:15:34.788346
[0m12:15:34.788808 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 12:15:34.780134 => 12:15:34.788676
[0m12:15:34.789101 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 12:15:34.782723 => 12:15:34.788991
[0m12:15:34.789369 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m12:15:34.789649 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m12:15:34.789912 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 12:15:34.785836 => 12:15:34.789794
[0m12:15:34.790148 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m12:15:34.812171 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m12:15:34.814303 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m12:15:34.814584 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m12:15:34.816579 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m12:15:34.826660 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m12:15:34.827257 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:15:34.827513 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:15:34.827751 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m12:15:34.827989 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m12:15:34.828190 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:15:34.828394 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:15:34.828578 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:15:34.828774 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:15:34.828956 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m12:15:34.829136 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m12:15:34.829521 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:15:34.829721 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:15:34.920455 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:34.920918 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:15:34.921275 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.lga_name AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM 
        warehouse.dim_host host
    LEFT JOIN 
        warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
distinct_host_count AS (
    SELECT
        TO_CHAR(h.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        COUNT(DISTINCT h.host_id) AS num_distinct_hosts
    FROM
        host_neighbourhood_lga_transform h
    GROUP BY
        TO_CHAR(h.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
),
estimated_revenue AS (
    SELECT
        TO_CHAR(l.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        SUM((30 - l.availability_30) * l.price) AS total_estimated_revenue
    FROM
        warehouse.fact_listing l
    LEFT JOIN
        host_neighbourhood_lga_transform h ON l.surrogate_key_host = h.surrogate_key_host
    WHERE
        l.has_availability = 't'
    GROUP BY
        TO_CHAR(l.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
)
SELECT
    dhct.month_year,
    dhct.host_neighbourhood_lga,
    dhct.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dhct.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dhct.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM
    distinct_host_count dhct
LEFT JOIN
    estimated_revenue er ON dhct.month_year = er.month_year AND dhct.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY
    dhct.month_year, dhct.host_neighbourhood_lga
  );
  
[0m12:15:34.930043 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:34.930346 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:15:34.930801 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m12:15:34.935427 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:34.935661 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:15:34.936072 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type



WITH sorted_listing AS (
    SELECT 
        prop.property_type,
        room.room_type,
        list.accommodates,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
SELECT 
    property_type,
    room_type,
    accommodates,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,



    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:15:34.936514 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:34.936848 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:15:34.937223 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:15:34.937652 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column suburb.lga_name does not exist
LINE 17:         suburb.lga_name AS host_neighbourhood_lga,
                 ^

[0m12:15:34.937977 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: ROLLBACK
[0m12:15:34.964846 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:15:34.790320 => 12:15:34.964669
[0m12:15:34.965140 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:15:34.970523 [debug] [Thread-1 (]: Database Error in model dm_host_neighbourhod (models/datamart/dm_host_neighbourhod.sql)
  column suburb.lga_name does not exist
  LINE 17:         suburb.lga_name AS host_neighbourhood_lga,
                   ^
  compiled Code at target/run/bde/models/datamart/dm_host_neighbourhod.sql
[0m12:15:34.970921 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107024cd0>]}
[0m12:15:34.971395 [error] [Thread-1 (]: 1 of 19 ERROR creating sql table model datamart.dm_host_neighbourhod ........... [[31mERROR[0m in 0.20s]
[0m12:15:34.971807 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:15:34.972084 [debug] [Thread-1 (]: Began running node model.bde.stg_G02
[0m12:15:34.972480 [info ] [Thread-1 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:15:34.972961 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.stg_G02)
[0m12:15:34.973217 [debug] [Thread-1 (]: Began compiling node model.bde.stg_G02
[0m12:15:34.976622 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:15:34.976886 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:15:34.981253 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:15:34.981587 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:15:34.981879 [debug] [Thread-1 (]: Timing info for model.bde.stg_G02 (compile): 12:15:34.973387 => 12:15:34.981766
[0m12:15:34.982168 [debug] [Thread-1 (]: Began executing node model.bde.stg_G02
[0m12:15:34.984727 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:15:34.985171 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:15:34.985395 [debug] [Thread-1 (]: On model.bde.stg_G02: BEGIN
[0m12:15:34.985599 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:15:34.992681 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:34.994487 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:15:34.994723 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:15:35.006003 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.016028 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:15:35.016300 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:15:35.016504 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:15:35.026066 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:35.031106 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:15:35.031357 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:15:35.045419 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:15:35.046333 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:15:34.816895 => 12:15:35.046222
[0m12:15:35.046565 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:15:35.047093 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074bea10>]}
[0m12:15:35.047473 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.27s]
[0m12:15:35.047844 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:15:35.048097 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m12:15:35.048424 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:15:35.048866 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_LGA)
[0m12:15:35.049110 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m12:15:35.051011 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:15:35.051548 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 12:15:35.049281 => 12:15:35.051429
[0m12:15:35.051763 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m12:15:35.054117 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:15:35.054542 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:15:35.054746 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m12:15:35.054930 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:15:35.105229 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:35.105680 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:15:35.106047 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:15:35.124246 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:15:35.126907 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:15:35.127186 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:15:35.136247 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.139379 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:15:35.139724 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:15:35.148969 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.150101 [debug] [Thread-1 (]: On model.bde.stg_G02: COMMIT
[0m12:15:35.150373 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:15:35.150608 [debug] [Thread-1 (]: On model.bde.stg_G02: COMMIT
[0m12:15:35.160910 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:35.162903 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:15:35.163198 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:15:35.164772 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:35.165031 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:15:35.165330 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:15:35.175159 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:15:35.176208 [debug] [Thread-1 (]: Timing info for model.bde.stg_G02 (execute): 12:15:34.982341 => 12:15:35.176056
[0m12:15:35.176507 [debug] [Thread-1 (]: On model.bde.stg_G02: Close
[0m12:15:35.177198 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077b25c0>]}
[0m12:15:35.177675 [info ] [Thread-1 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.20s]
[0m12:15:35.178129 [debug] [Thread-1 (]: Finished running node model.bde.stg_G02
[0m12:15:35.178460 [debug] [Thread-1 (]: Began running node model.bde.stg_fact
[0m12:15:35.178810 [info ] [Thread-1 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:15:35.179427 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_fact)
[0m12:15:35.179712 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:15:35.179971 [debug] [Thread-1 (]: Began compiling node model.bde.stg_fact
[0m12:15:35.182228 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:15:35.184812 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:15:35.185280 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:15:35.186002 [debug] [Thread-1 (]: Timing info for model.bde.stg_fact (compile): 12:15:35.182433 => 12:15:35.185823
[0m12:15:35.186326 [debug] [Thread-1 (]: Began executing node model.bde.stg_fact
[0m12:15:35.189403 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:15:35.189865 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:15:35.190119 [debug] [Thread-1 (]: On model.bde.stg_fact: BEGIN
[0m12:15:35.190355 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:15:35.194977 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.196896 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:15:35.197151 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:15:35.205708 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.206800 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:15:35.207046 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:15:35.207258 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:15:35.219434 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:35.221247 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:15:35.221523 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:15:35.238567 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:15:35.239596 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 12:15:35.051907 => 12:15:35.239474
[0m12:15:35.239867 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m12:15:35.240460 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077bfb20>]}
[0m12:15:35.240916 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.19s]
[0m12:15:35.241354 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m12:15:35.241665 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m12:15:35.242167 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:15:35.242708 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_host)
[0m12:15:35.242996 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m12:15:35.245519 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:15:35.246079 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 12:15:35.243186 => 12:15:35.245967
[0m12:15:35.246320 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m12:15:35.249875 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:15:35.250329 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:15:35.250559 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m12:15:35.250768 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:15:35.289151 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:35.289494 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:15:35.289852 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:15:35.308957 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:15:35.339753 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:15:35.340149 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:15:35.349339 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.351110 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:15:35.351379 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:15:35.359703 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.360766 [debug] [Thread-1 (]: On model.bde.stg_fact: COMMIT
[0m12:15:35.361118 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:15:35.361325 [debug] [Thread-1 (]: On model.bde.stg_fact: COMMIT
[0m12:15:35.368121 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:35.368357 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:15:35.368631 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:15:35.371541 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:35.373050 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:15:35.373278 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:15:35.384340 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:15:35.385200 [debug] [Thread-1 (]: Timing info for model.bde.stg_fact (execute): 12:15:35.186518 => 12:15:35.385094
[0m12:15:35.385425 [debug] [Thread-1 (]: On model.bde.stg_fact: Close
[0m12:15:35.385974 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071549d0>]}
[0m12:15:35.386359 [info ] [Thread-1 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.21s]
[0m12:15:35.386718 [debug] [Thread-1 (]: Finished running node model.bde.stg_fact
[0m12:15:35.386977 [debug] [Thread-1 (]: Began running node model.bde.stg_property
[0m12:15:35.387337 [info ] [Thread-1 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:15:35.387756 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_property)
[0m12:15:35.387986 [debug] [Thread-1 (]: Began compiling node model.bde.stg_property
[0m12:15:35.390004 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:15:35.390544 [debug] [Thread-1 (]: Timing info for model.bde.stg_property (compile): 12:15:35.388146 => 12:15:35.390439
[0m12:15:35.390761 [debug] [Thread-1 (]: Began executing node model.bde.stg_property
[0m12:15:35.393210 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:15:35.393680 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:15:35.393896 [debug] [Thread-1 (]: On model.bde.stg_property: BEGIN
[0m12:15:35.394084 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:15:35.395457 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:15:35.397360 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:15:35.397591 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:15:35.407233 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.408995 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:15:35.409229 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:15:35.433914 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.435047 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:15:35.435285 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:15:35.435489 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:15:35.449734 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:35.451497 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:15:35.451744 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:15:35.462678 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:15:35.464797 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 12:15:35.246487 => 12:15:35.464680
[0m12:15:35.465036 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m12:15:35.465611 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107450580>]}
[0m12:15:35.466043 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.22s]
[0m12:15:35.466446 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m12:15:35.466725 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m12:15:35.467117 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:15:35.467577 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_room)
[0m12:15:35.467815 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m12:15:35.469851 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:15:35.470446 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 12:15:35.467976 => 12:15:35.470345
[0m12:15:35.470691 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m12:15:35.473576 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:15:35.474260 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:15:35.474502 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m12:15:35.474716 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:15:35.499199 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:35.499590 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:15:35.499900 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:15:35.513684 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:15:35.516209 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:15:35.516461 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:15:35.526402 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.528268 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:15:35.528512 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:15:35.537918 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.538977 [debug] [Thread-1 (]: On model.bde.stg_property: COMMIT
[0m12:15:35.539244 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:15:35.539592 [debug] [Thread-1 (]: On model.bde.stg_property: COMMIT
[0m12:15:35.553711 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:35.555559 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:15:35.555826 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:15:35.566681 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:15:35.567648 [debug] [Thread-1 (]: Timing info for model.bde.stg_property (execute): 12:15:35.390913 => 12:15:35.567522
[0m12:15:35.567939 [debug] [Thread-1 (]: On model.bde.stg_property: Close
[0m12:15:35.568589 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107154bb0>]}
[0m12:15:35.569025 [info ] [Thread-1 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.18s]
[0m12:15:35.569443 [debug] [Thread-1 (]: Finished running node model.bde.stg_property
[0m12:15:35.569738 [debug] [Thread-1 (]: Began running node model.bde.stg_suburb
[0m12:15:35.570150 [info ] [Thread-1 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:15:35.570605 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_suburb)
[0m12:15:35.570852 [debug] [Thread-1 (]: Began compiling node model.bde.stg_suburb
[0m12:15:35.572955 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:15:35.573565 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (compile): 12:15:35.571020 => 12:15:35.573445
[0m12:15:35.573829 [debug] [Thread-1 (]: Began executing node model.bde.stg_suburb
[0m12:15:35.576600 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:15:35.577178 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:15:35.577453 [debug] [Thread-1 (]: On model.bde.stg_suburb: BEGIN
[0m12:15:35.577694 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:15:35.690599 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:35.691210 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:15:35.691551 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:15:35.705576 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:15:35.708725 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:15:35.709096 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:15:35.722317 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.726212 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:15:35.726717 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:15:35.749809 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.751418 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:15:35.751783 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:15:35.752069 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:15:35.763022 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:35.765357 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:15:35.765688 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:15:35.780201 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:15:35.787970 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (execute): 12:15:35.574010 => 12:15:35.787149
[0m12:15:35.789456 [debug] [Thread-1 (]: On model.bde.stg_suburb: Close
[0m12:15:35.791041 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bb0d90>]}
[0m12:15:35.791638 [info ] [Thread-1 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.22s]
[0m12:15:35.792297 [debug] [Thread-1 (]: Finished running node model.bde.stg_suburb
[0m12:15:35.792656 [debug] [Thread-1 (]: Began running node model.bde.dim_LGA
[0m12:15:35.792977 [info ] [Thread-1 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:15:35.793707 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.dim_LGA)
[0m12:15:35.794359 [debug] [Thread-1 (]: Began compiling node model.bde.dim_LGA
[0m12:15:35.797877 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:15:35.798558 [debug] [Thread-1 (]: Timing info for model.bde.dim_LGA (compile): 12:15:35.794591 => 12:15:35.798430
[0m12:15:35.798814 [debug] [Thread-1 (]: Began executing node model.bde.dim_LGA
[0m12:15:35.802280 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:15:35.803290 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:15:35.803845 [debug] [Thread-1 (]: On model.bde.dim_LGA: BEGIN
[0m12:15:35.804231 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:15:35.815917 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:35.816565 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:15:35.816936 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:15:35.829330 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:15:35.833743 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:15:35.834063 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:15:35.845092 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.847122 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:15:35.847368 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:15:35.858866 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.859935 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:15:35.860187 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:15:35.860412 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:15:35.872510 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:35.874245 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:15:35.874490 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:15:35.889759 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:15:35.890694 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 12:15:35.470859 => 12:15:35.890571
[0m12:15:35.890960 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m12:15:35.891576 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107027d30>]}
[0m12:15:35.892013 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.42s]
[0m12:15:35.892451 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m12:15:35.892739 [debug] [Thread-4 (]: Began running node model.bde.fact_G01
[0m12:15:35.893157 [info ] [Thread-4 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:15:35.893625 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.fact_G01)
[0m12:15:35.893880 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G01
[0m12:15:35.896346 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:15:35.896969 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (compile): 12:15:35.894058 => 12:15:35.896839
[0m12:15:35.897239 [debug] [Thread-4 (]: Began executing node model.bde.fact_G01
[0m12:15:35.901446 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:15:35.902050 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:15:35.902312 [debug] [Thread-4 (]: On model.bde.fact_G01: BEGIN
[0m12:15:35.902555 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:15:35.949809 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:35.950246 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:15:35.950541 [debug] [Thread-1 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:15:35.968369 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:15:35.971521 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:15:35.971863 [debug] [Thread-1 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:15:35.981331 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:35.983676 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:15:35.983984 [debug] [Thread-1 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:15:35.996151 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:36.000542 [debug] [Thread-1 (]: On model.bde.dim_LGA: COMMIT
[0m12:15:36.000874 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:15:36.001148 [debug] [Thread-1 (]: On model.bde.dim_LGA: COMMIT
[0m12:15:36.012410 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:36.016066 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:15:36.016432 [debug] [Thread-1 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:15:36.033016 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:15:36.034116 [debug] [Thread-1 (]: Timing info for model.bde.dim_LGA (execute): 12:15:35.798985 => 12:15:36.033973
[0m12:15:36.034424 [debug] [Thread-1 (]: On model.bde.dim_LGA: Close
[0m12:15:36.035088 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107211600>]}
[0m12:15:36.035572 [info ] [Thread-1 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.24s]
[0m12:15:36.036043 [debug] [Thread-1 (]: Finished running node model.bde.dim_LGA
[0m12:15:36.036379 [debug] [Thread-1 (]: Began running node model.bde.fact_G02
[0m12:15:36.036716 [info ] [Thread-1 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:15:36.037309 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G02)
[0m12:15:36.037626 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G02
[0m12:15:36.040232 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:15:36.040531 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:36.040909 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:15:36.041241 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:15:36.041757 [debug] [Thread-1 (]: Timing info for model.bde.fact_G02 (compile): 12:15:36.037840 => 12:15:36.041566
[0m12:15:36.042051 [debug] [Thread-1 (]: Began executing node model.bde.fact_G02
[0m12:15:36.045072 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:15:36.045542 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:15:36.045789 [debug] [Thread-1 (]: On model.bde.fact_G02: BEGIN
[0m12:15:36.046022 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:15:36.069810 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:15:36.072321 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:15:36.072593 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:15:36.082805 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:36.085148 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:15:36.085471 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:15:36.094773 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:36.096208 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m12:15:36.096506 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:15:36.096760 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m12:15:36.108818 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:36.112428 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:15:36.112755 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:15:36.129521 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:15:36.130605 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (execute): 12:15:35.897419 => 12:15:36.130463
[0m12:15:36.130896 [debug] [Thread-4 (]: On model.bde.fact_G01: Close
[0m12:15:36.131539 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108133010>]}
[0m12:15:36.131988 [info ] [Thread-4 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.24s]
[0m12:15:36.132444 [debug] [Thread-4 (]: Finished running node model.bde.fact_G01
[0m12:15:36.132770 [debug] [Thread-4 (]: Began running node model.bde.fact_listing
[0m12:15:36.133185 [info ] [Thread-4 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:15:36.133739 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_listing)
[0m12:15:36.134025 [debug] [Thread-4 (]: Began compiling node model.bde.fact_listing
[0m12:15:36.136341 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:15:36.137004 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (compile): 12:15:36.134222 => 12:15:36.136864
[0m12:15:36.137277 [debug] [Thread-4 (]: Began executing node model.bde.fact_listing
[0m12:15:36.140005 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:15:36.140485 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:15:36.140742 [debug] [Thread-4 (]: On model.bde.fact_listing: BEGIN
[0m12:15:36.140972 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:15:36.158576 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:36.158839 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:15:36.159094 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:15:36.187756 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:15:36.190331 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:15:36.190670 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:15:36.216115 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:36.218651 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:15:36.218941 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:15:36.232211 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:36.233902 [debug] [Thread-1 (]: On model.bde.fact_G02: COMMIT
[0m12:15:36.234248 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:15:36.234552 [debug] [Thread-1 (]: On model.bde.fact_G02: COMMIT
[0m12:15:36.248282 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:36.250517 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:15:36.250898 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:15:36.267141 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:15:36.268511 [debug] [Thread-1 (]: Timing info for model.bde.fact_G02 (execute): 12:15:36.042250 => 12:15:36.268335
[0m12:15:36.268900 [debug] [Thread-1 (]: On model.bde.fact_G02: Close
[0m12:15:36.269255 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:36.269691 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:15:36.270376 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10779c340>]}
[0m12:15:36.270830 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:15:36.271472 [info ] [Thread-1 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.23s]
[0m12:15:36.272238 [debug] [Thread-1 (]: Finished running node model.bde.fact_G02
[0m12:15:36.272620 [debug] [Thread-1 (]: Began running node model.bde.dim_host
[0m12:15:36.273039 [info ] [Thread-1 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:15:36.273608 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m12:15:36.273951 [debug] [Thread-1 (]: Began compiling node model.bde.dim_host
[0m12:15:36.276878 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:15:36.277551 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (compile): 12:15:36.274177 => 12:15:36.277394
[0m12:15:36.277872 [debug] [Thread-1 (]: Began executing node model.bde.dim_host
[0m12:15:36.280991 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:15:36.281548 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:15:36.281850 [debug] [Thread-1 (]: On model.bde.dim_host: BEGIN
[0m12:15:36.282131 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:15:36.392841 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:36.393906 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:15:36.394436 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:15:37.136571 [debug] [Thread-1 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m12:15:37.147921 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:15:37.148648 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:15:38.515312 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m12:15:38.523412 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:15:38.524481 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:15:38.534250 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:38.538301 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:15:38.538806 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:15:38.548043 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:38.550273 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:15:38.550738 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:15:38.551164 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:15:38.642712 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:38.652346 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:15:38.653364 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:15:38.675519 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:15:38.680610 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:15:34.812368 => 12:15:38.680263
[0m12:15:38.681444 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:15:38.683321 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10720ac50>]}
[0m12:15:38.684450 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 3.91s]
[0m12:15:38.685282 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:15:38.685892 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m12:15:38.686834 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:15:38.688079 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m12:15:38.688632 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m12:15:38.692771 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:15:38.693878 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 12:15:38.688983 => 12:15:38.693672
[0m12:15:38.694290 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m12:15:38.698481 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:15:38.699106 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:15:38.699433 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m12:15:38.699754 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:15:38.813510 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:38.814028 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:15:38.814363 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:15:39.287779 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:15:39.295104 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:15:39.296225 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:15:39.896847 [debug] [Thread-4 (]: SQL status: SELECT 340945 in 4.0 seconds
[0m12:15:39.905901 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:15:39.906738 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:15:39.947401 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 5.0 seconds
[0m12:15:39.954431 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:15:39.956745 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m12:15:39.967098 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:39.970202 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:15:39.970581 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m12:15:39.979826 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:39.981567 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:15:39.981935 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:15:39.982236 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:15:40.057225 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:40.058586 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:40.059682 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 1.0 seconds
[0m12:15:40.060630 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 3.0 seconds
[0m12:15:40.065411 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:15:40.068852 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:15:40.071678 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:15:40.074465 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:15:40.074873 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m12:15:40.075292 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:15:40.075623 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:15:40.075940 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:15:40.088265 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:40.088672 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:40.089096 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:40.090954 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m12:15:40.092461 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:15:40.093963 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m12:15:40.094333 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:15:40.094725 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:15:40.095068 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:15:40.095384 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:15:40.096675 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:15:34.814745 => 12:15:40.096509
[0m12:15:40.097008 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m12:15:40.097315 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:15:40.097616 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m12:15:40.097938 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:15:40.098904 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074ec070>]}
[0m12:15:40.099432 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 5.33s]
[0m12:15:40.099934 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:15:40.100267 [debug] [Thread-3 (]: Began running node model.bde.dim_suburb
[0m12:15:40.100694 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:15:40.101303 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_suburb)
[0m12:15:40.101604 [debug] [Thread-3 (]: Began compiling node model.bde.dim_suburb
[0m12:15:40.104364 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:15:40.105100 [debug] [Thread-3 (]: Timing info for model.bde.dim_suburb (compile): 12:15:40.101812 => 12:15:40.104959
[0m12:15:40.105410 [debug] [Thread-3 (]: Began executing node model.bde.dim_suburb
[0m12:15:40.108400 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:15:40.108673 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:40.110451 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:15:40.110726 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:40.110964 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:40.111192 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:15:40.114027 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:15:40.114293 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:15:40.115942 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:15:40.116312 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:15:40.116563 [debug] [Thread-3 (]: On model.bde.dim_suburb: BEGIN
[0m12:15:40.116795 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:15:40.117060 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:15:40.154889 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:15:40.156261 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (execute): 12:15:36.278093 => 12:15:40.156118
[0m12:15:40.156547 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:15:40.156888 [debug] [Thread-1 (]: On model.bde.dim_host: Close
[0m12:15:40.157935 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 12:15:38.694567 => 12:15:40.157808
[0m12:15:40.158269 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m12:15:40.158786 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10814f730>]}
[0m12:15:40.159234 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081a7880>]}
[0m12:15:40.159647 [info ] [Thread-1 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 3.89s]
[0m12:15:40.160055 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 1.47s]
[0m12:15:40.160470 [debug] [Thread-1 (]: Finished running node model.bde.dim_host
[0m12:15:40.160810 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m12:15:40.161092 [debug] [Thread-1 (]: Began running node model.bde.dim_room
[0m12:15:40.161495 [info ] [Thread-1 (]: 19 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:15:40.161943 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dim_host, now model.bde.dim_room)
[0m12:15:40.162185 [debug] [Thread-1 (]: Began compiling node model.bde.dim_room
[0m12:15:40.164455 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:15:40.165001 [debug] [Thread-1 (]: Timing info for model.bde.dim_room (compile): 12:15:40.162353 => 12:15:40.164878
[0m12:15:40.165254 [debug] [Thread-1 (]: Began executing node model.bde.dim_room
[0m12:15:40.167870 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:15:40.168303 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_room"
[0m12:15:40.168529 [debug] [Thread-1 (]: On model.bde.dim_room: BEGIN
[0m12:15:40.168738 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:15:40.176925 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:15:40.177988 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (execute): 12:15:36.137457 => 12:15:40.177872
[0m12:15:40.178258 [debug] [Thread-4 (]: On model.bde.fact_listing: Close
[0m12:15:40.178830 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077c8700>]}
[0m12:15:40.179223 [info ] [Thread-4 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 4.05s]
[0m12:15:40.179605 [debug] [Thread-4 (]: Finished running node model.bde.fact_listing
[0m12:15:40.239782 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:40.240233 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:15:40.240573 [debug] [Thread-3 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:15:40.260150 [debug] [Thread-3 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:15:40.263214 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:15:40.263522 [debug] [Thread-3 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:15:40.273360 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:40.275808 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:15:40.276147 [debug] [Thread-3 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:15:40.283033 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:15:40.283359 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_room"
[0m12:15:40.283693 [debug] [Thread-1 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:15:40.284613 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:40.286195 [debug] [Thread-3 (]: On model.bde.dim_suburb: COMMIT
[0m12:15:40.286532 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:15:40.286846 [debug] [Thread-3 (]: On model.bde.dim_suburb: COMMIT
[0m12:15:40.297481 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:40.299692 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:15:40.300036 [debug] [Thread-3 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:15:40.318211 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:15:40.319655 [debug] [Thread-3 (]: Timing info for model.bde.dim_suburb (execute): 12:15:40.105617 => 12:15:40.319468
[0m12:15:40.320053 [debug] [Thread-3 (]: On model.bde.dim_suburb: Close
[0m12:15:40.320927 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081adbd0>]}
[0m12:15:40.321543 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.22s]
[0m12:15:40.322092 [debug] [Thread-3 (]: Finished running node model.bde.dim_suburb
[0m12:15:40.416300 [debug] [Thread-1 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:15:40.424990 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_room"
[0m12:15:40.425569 [debug] [Thread-1 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:15:40.435608 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:40.441743 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_room"
[0m12:15:40.442182 [debug] [Thread-1 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:15:40.452434 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:15:40.454301 [debug] [Thread-1 (]: On model.bde.dim_room: COMMIT
[0m12:15:40.454715 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_room"
[0m12:15:40.455059 [debug] [Thread-1 (]: On model.bde.dim_room: COMMIT
[0m12:15:40.476751 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:15:40.479841 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_room"
[0m12:15:40.480324 [debug] [Thread-1 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:15:40.495850 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:15:40.497616 [debug] [Thread-1 (]: Timing info for model.bde.dim_room (execute): 12:15:40.165428 => 12:15:40.497373
[0m12:15:40.498096 [debug] [Thread-1 (]: On model.bde.dim_room: Close
[0m12:15:40.499216 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1bb283f-e7c6-4a3e-b3cb-ed099289a59f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108427ee0>]}
[0m12:15:40.499994 [info ] [Thread-1 (]: 19 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.34s]
[0m12:15:40.500730 [debug] [Thread-1 (]: Finished running node model.bde.dim_room
[0m12:15:40.502821 [debug] [MainThread]: Using postgres connection "master"
[0m12:15:40.503281 [debug] [MainThread]: On master: BEGIN
[0m12:15:40.503622 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:15:40.602384 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:15:40.604354 [debug] [MainThread]: On master: COMMIT
[0m12:15:40.605395 [debug] [MainThread]: Using postgres connection "master"
[0m12:15:40.605918 [debug] [MainThread]: On master: COMMIT
[0m12:15:40.614386 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:15:40.614925 [debug] [MainThread]: On master: Close
[0m12:15:40.616605 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:15:40.617094 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:15:40.617570 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m12:15:40.617994 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:15:40.618409 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:15:40.619155 [info ] [MainThread]: 
[0m12:15:40.619684 [info ] [MainThread]: Finished running 11 table models, 8 view models in 0 hours 0 minutes and 6.34 seconds (6.34s).
[0m12:15:40.624141 [debug] [MainThread]: Command end result
[0m12:15:40.635617 [info ] [MainThread]: 
[0m12:15:40.636078 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m12:15:40.636395 [info ] [MainThread]: 
[0m12:15:40.636689 [error] [MainThread]:   Database Error in model dm_host_neighbourhod (models/datamart/dm_host_neighbourhod.sql)
  column suburb.lga_name does not exist
  LINE 17:         suburb.lga_name AS host_neighbourhood_lga,
                   ^
  compiled Code at target/run/bde/models/datamart/dm_host_neighbourhod.sql
[0m12:15:40.637007 [info ] [MainThread]: 
[0m12:15:40.637305 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m12:15:40.637923 [debug] [MainThread]: Command `dbt run` failed at 12:15:40.637840 after 6.51 seconds
[0m12:15:40.638311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103511810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108416860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070265c0>]}
[0m12:15:40.638659 [debug] [MainThread]: Flushing usage events
[0m12:16:22.477021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ad9810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11284db10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11284d450>]}


============================== 12:16:22.479717 | e6a0af34-2747-4716-90ec-0e27edbba032 ==============================
[0m12:16:22.479717 [info ] [MainThread]: Running with dbt=1.6.6
[0m12:16:22.480052 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:16:22.535818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11284d660>]}
[0m12:16:22.543750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d391b0>]}
[0m12:16:22.544378 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m12:16:22.553805 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m12:16:22.580652 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:16:22.581114 [debug] [MainThread]: Partial parsing: updated file: bde://models/datamart/dm_host_neighbourhod.sql
[0m12:16:22.600973 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.raw
- models.bde.median
[0m12:16:22.603769 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134ecc70>]}
[0m12:16:22.609609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11317ed40>]}
[0m12:16:22.609868 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m12:16:22.610058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11317ef20>]}
[0m12:16:22.611255 [info ] [MainThread]: 
[0m12:16:22.611643 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:16:22.612470 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:16:22.612916 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:16:22.613265 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:16:22.617859 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:16:22.618755 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:16:22.619582 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:16:22.619746 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:16:22.619921 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:16:22.620082 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:16:22.620229 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:16:22.620364 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:16:22.620495 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:16:22.779258 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:16:22.780728 [debug] [ThreadPool]: On list_postgres: Close
[0m12:16:22.782931 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:16:22.783740 [debug] [ThreadPool]: On list_postgres: Close
[0m12:16:22.792310 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:16:22.793041 [debug] [ThreadPool]: On list_postgres: Close
[0m12:16:22.794732 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m12:16:22.799621 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:16:22.800076 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_staging)
[0m12:16:22.800568 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m12:16:22.800775 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m12:16:22.801254 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_warehouse'
[0m12:16:22.802604 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:16:22.803774 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:16:22.803997 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:16:22.805184 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:16:22.805405 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m12:16:22.805598 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m12:16:22.805906 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m12:16:22.806121 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:16:22.806323 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:16:22.806520 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:16:22.907173 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:16:22.907653 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:16:22.907951 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m12:16:22.909475 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:16:22.909716 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:16:22.909982 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m12:16:22.910409 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:16:22.910641 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:16:22.910910 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m12:16:22.911254 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:16:22.911493 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:16:22.911743 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m12:16:22.923796 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:16:22.925087 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m12:16:22.927516 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:16:22.928560 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m12:16:22.930066 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:16:22.931067 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m12:16:22.931398 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:16:22.932444 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m12:16:22.936157 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m12:16:22.936404 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m12:16:22.940657 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m12:16:22.942342 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m12:16:22.947940 [debug] [MainThread]: Using postgres connection "master"
[0m12:16:22.948243 [debug] [MainThread]: On master: BEGIN
[0m12:16:22.948470 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:16:23.048864 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:16:23.049939 [debug] [MainThread]: Using postgres connection "master"
[0m12:16:23.050579 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:16:23.076132 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:16:23.082481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112cbf9d0>]}
[0m12:16:23.083236 [debug] [MainThread]: On master: ROLLBACK
[0m12:16:23.092995 [debug] [MainThread]: Using postgres connection "master"
[0m12:16:23.093327 [debug] [MainThread]: On master: BEGIN
[0m12:16:23.111873 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:16:23.112231 [debug] [MainThread]: On master: COMMIT
[0m12:16:23.112546 [debug] [MainThread]: Using postgres connection "master"
[0m12:16:23.112844 [debug] [MainThread]: On master: COMMIT
[0m12:16:23.124116 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:16:23.124528 [debug] [MainThread]: On master: Close
[0m12:16:23.125607 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:16:23.126079 [info ] [MainThread]: 
[0m12:16:23.130724 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m12:16:23.131204 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m12:16:23.131655 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m12:16:23.132009 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m12:16:23.132556 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m12:16:23.133161 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m12:16:23.133752 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m12:16:23.134232 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m12:16:23.135021 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_host_neighbourhod)
[0m12:16:23.135687 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.dm_listing_neighbourhood)
[0m12:16:23.136280 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_property_type)
[0m12:16:23.136811 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.stg_G01)
[0m12:16:23.137204 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m12:16:23.137538 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m12:16:23.137865 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m12:16:23.138200 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m12:16:23.145618 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m12:16:23.148093 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m12:16:23.151656 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m12:16:23.153953 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m12:16:23.154846 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 12:16:23.145894 => 12:16:23.154651
[0m12:16:23.155276 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 12:16:23.148363 => 12:16:23.155136
[0m12:16:23.155555 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 12:16:23.138442 => 12:16:23.155439
[0m12:16:23.155809 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m12:16:23.156121 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m12:16:23.156415 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 12:16:23.151894 => 12:16:23.156298
[0m12:16:23.156671 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m12:16:23.181036 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m12:16:23.183258 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m12:16:23.183519 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m12:16:23.185564 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m12:16:23.192290 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:16:23.195770 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m12:16:23.195983 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:16:23.196252 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m12:16:23.196657 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:16:23.196994 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m12:16:23.197265 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:16:23.197482 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:16:23.197706 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m12:16:23.197914 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:16:23.198193 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m12:16:23.198400 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:16:23.198684 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:16:23.318343 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:23.318752 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:16:23.319295 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m12:16:23.320513 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:23.320804 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:16:23.321294 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:16:23.329681 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:23.330028 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:16:23.330598 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type



WITH sorted_listing AS (
    SELECT 
        prop.property_type,
        room.room_type,
        list.accommodates,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
SELECT 
    property_type,
    room_type,
    accommodates,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,



    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:16:23.347985 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:16:23.354650 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:16:23.354988 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:16:23.366871 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:23.369238 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:16:23.369545 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:16:23.441131 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:23.441693 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:16:23.442354 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM 
        warehouse.dim_host host
    LEFT JOIN 
        warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
distinct_host_count AS (
    SELECT
        TO_CHAR(h.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        COUNT(DISTINCT h.host_id) AS num_distinct_hosts
    FROM
        host_neighbourhood_lga_transform h
    GROUP BY
        TO_CHAR(h.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
),
estimated_revenue AS (
    SELECT
        TO_CHAR(l.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        SUM((30 - l.availability_30) * l.price) AS total_estimated_revenue
    FROM
        warehouse.fact_listing l
    LEFT JOIN
        host_neighbourhood_lga_transform h ON l.surrogate_key_host = h.surrogate_key_host
    WHERE
        l.has_availability = 't'
    GROUP BY
        TO_CHAR(l.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
)
SELECT
    dhct.month_year,
    dhct.host_neighbourhood_lga,
    dhct.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dhct.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dhct.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM
    distinct_host_count dhct
LEFT JOIN
    estimated_revenue er ON dhct.month_year = er.month_year AND dhct.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY
    dhct.month_year, dhct.host_neighbourhood_lga
  );
  
[0m12:16:23.464487 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column host.scraped_date does not exist
LINE 18:         TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
                         ^

[0m12:16:23.465592 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: ROLLBACK
[0m12:16:23.474922 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:16:23.183676 => 12:16:23.474563
[0m12:16:23.475649 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:16:23.484110 [debug] [Thread-1 (]: Database Error in model dm_host_neighbourhod (models/datamart/dm_host_neighbourhod.sql)
  column host.scraped_date does not exist
  LINE 18:         TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
                           ^
  compiled Code at target/run/bde/models/datamart/dm_host_neighbourhod.sql
[0m12:16:23.484843 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11354ddb0>]}
[0m12:16:23.485529 [error] [Thread-1 (]: 1 of 19 ERROR creating sql table model datamart.dm_host_neighbourhod ........... [[31mERROR[0m in 0.35s]
[0m12:16:23.486199 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:16:23.486657 [debug] [Thread-1 (]: Began running node model.bde.stg_G02
[0m12:16:23.487239 [info ] [Thread-1 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:16:23.487986 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.stg_G02)
[0m12:16:23.488367 [debug] [Thread-1 (]: Began compiling node model.bde.stg_G02
[0m12:16:23.492163 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:16:23.492949 [debug] [Thread-1 (]: Timing info for model.bde.stg_G02 (compile): 12:16:23.488634 => 12:16:23.492782
[0m12:16:23.493288 [debug] [Thread-1 (]: Began executing node model.bde.stg_G02
[0m12:16:23.497038 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:16:23.497599 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:16:23.497919 [debug] [Thread-1 (]: On model.bde.stg_G02: BEGIN
[0m12:16:23.498216 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:16:23.508254 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:23.521689 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:16:23.522020 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:16:23.522287 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:16:23.532794 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:23.538916 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:16:23.539206 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:16:23.554394 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:16:23.555567 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:16:23.185925 => 12:16:23.555426
[0m12:16:23.555881 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:16:23.556517 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135c2ad0>]}
[0m12:16:23.556996 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.42s]
[0m12:16:23.557461 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:16:23.557792 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m12:16:23.558212 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:16:23.558764 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_LGA)
[0m12:16:23.559041 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m12:16:23.561256 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:16:23.561779 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 12:16:23.559224 => 12:16:23.561661
[0m12:16:23.562043 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m12:16:23.564801 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:16:23.565232 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:16:23.565477 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m12:16:23.565703 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:16:23.613881 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:23.614249 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:16:23.614631 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:16:23.629704 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:16:23.632594 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:16:23.632959 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:16:23.647796 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:23.651633 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:16:23.652070 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:16:23.661171 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:23.662593 [debug] [Thread-1 (]: On model.bde.stg_G02: COMMIT
[0m12:16:23.662937 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:16:23.663240 [debug] [Thread-1 (]: On model.bde.stg_G02: COMMIT
[0m12:16:23.672859 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:23.675079 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:16:23.675408 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:16:23.687052 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:16:23.688286 [debug] [Thread-1 (]: Timing info for model.bde.stg_G02 (execute): 12:16:23.493526 => 12:16:23.688137
[0m12:16:23.688653 [debug] [Thread-1 (]: On model.bde.stg_G02: Close
[0m12:16:23.689403 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114ac4850>]}
[0m12:16:23.689925 [info ] [Thread-1 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.20s]
[0m12:16:23.690444 [debug] [Thread-1 (]: Finished running node model.bde.stg_G02
[0m12:16:23.690829 [debug] [Thread-1 (]: Began running node model.bde.stg_fact
[0m12:16:23.691302 [info ] [Thread-1 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:16:23.691963 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_fact)
[0m12:16:23.692308 [debug] [Thread-1 (]: Began compiling node model.bde.stg_fact
[0m12:16:23.695218 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:16:23.695991 [debug] [Thread-1 (]: Timing info for model.bde.stg_fact (compile): 12:16:23.692544 => 12:16:23.695802
[0m12:16:23.696343 [debug] [Thread-1 (]: Began executing node model.bde.stg_fact
[0m12:16:23.699441 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:16:23.699730 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:23.700093 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:16:23.700463 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:16:23.700793 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:16:23.701104 [debug] [Thread-1 (]: On model.bde.stg_fact: BEGIN
[0m12:16:23.701362 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:16:23.712749 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:16:23.715289 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:16:23.715588 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:16:23.724911 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:23.727236 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:16:23.727526 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:16:23.738718 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:23.740097 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:16:23.740382 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:16:23.740640 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:16:23.750479 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:23.752506 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:16:23.752799 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:16:23.763607 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:16:23.764789 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 12:16:23.562218 => 12:16:23.764629
[0m12:16:23.765124 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m12:16:23.765848 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134b3430>]}
[0m12:16:23.766382 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.21s]
[0m12:16:23.766905 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m12:16:23.767252 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m12:16:23.767725 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:16:23.768266 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_host)
[0m12:16:23.768566 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m12:16:23.771160 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:16:23.771743 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 12:16:23.768768 => 12:16:23.771607
[0m12:16:23.772026 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m12:16:23.776332 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:16:23.776857 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:16:23.777136 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m12:16:23.777375 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:16:23.821113 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:23.821545 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:16:23.821972 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:16:23.845244 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:16:23.876212 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:16:23.876584 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:16:23.886450 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:23.888448 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:16:23.888716 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:16:23.898568 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:23.899717 [debug] [Thread-1 (]: On model.bde.stg_fact: COMMIT
[0m12:16:23.899977 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:16:23.900220 [debug] [Thread-1 (]: On model.bde.stg_fact: COMMIT
[0m12:16:23.907047 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:23.907312 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:16:23.907630 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:16:23.909872 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:23.911623 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:16:23.911875 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:16:23.926930 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:16:23.927180 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:16:23.929355 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:16:23.930269 [debug] [Thread-1 (]: Timing info for model.bde.stg_fact (execute): 12:16:23.696561 => 12:16:23.930142
[0m12:16:23.930544 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:16:23.930806 [debug] [Thread-1 (]: On model.bde.stg_fact: Close
[0m12:16:23.931489 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134eee90>]}
[0m12:16:23.931920 [info ] [Thread-1 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.24s]
[0m12:16:23.932326 [debug] [Thread-1 (]: Finished running node model.bde.stg_fact
[0m12:16:23.932623 [debug] [Thread-1 (]: Began running node model.bde.stg_property
[0m12:16:23.933042 [info ] [Thread-1 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:16:23.933504 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_property)
[0m12:16:23.933751 [debug] [Thread-1 (]: Began compiling node model.bde.stg_property
[0m12:16:23.936060 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:16:23.936678 [debug] [Thread-1 (]: Timing info for model.bde.stg_property (compile): 12:16:23.933920 => 12:16:23.936562
[0m12:16:23.936920 [debug] [Thread-1 (]: Began executing node model.bde.stg_property
[0m12:16:23.939511 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:16:23.939966 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:16:23.940198 [debug] [Thread-1 (]: On model.bde.stg_property: BEGIN
[0m12:16:23.940434 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:23.940689 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:16:23.942585 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:16:23.942993 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:16:23.953950 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:23.955063 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:16:23.955296 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:16:23.955515 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:16:23.965655 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:23.967488 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:16:23.967785 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:16:23.978744 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:16:23.979643 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 12:16:23.772220 => 12:16:23.979538
[0m12:16:23.979881 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m12:16:23.980438 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134edf60>]}
[0m12:16:23.980808 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.21s]
[0m12:16:23.981156 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m12:16:23.981433 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m12:16:23.981843 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:16:23.982475 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_room)
[0m12:16:23.982802 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m12:16:23.985809 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:16:23.986342 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 12:16:23.982969 => 12:16:23.986236
[0m12:16:23.986561 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m12:16:23.988849 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:16:23.989236 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:16:23.989433 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m12:16:23.989612 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:16:24.051547 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:24.051997 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:16:24.052317 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:16:24.067981 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:16:24.070455 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:16:24.070728 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:16:24.081655 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:24.083633 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:16:24.083906 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:16:24.092652 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:24.093748 [debug] [Thread-1 (]: On model.bde.stg_property: COMMIT
[0m12:16:24.094005 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:16:24.094229 [debug] [Thread-1 (]: On model.bde.stg_property: COMMIT
[0m12:16:24.099950 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:24.100188 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:16:24.100455 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:16:24.103204 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:24.105039 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:16:24.105311 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:16:24.114599 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:16:24.116701 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:16:24.116961 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:16:24.117221 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:16:24.118168 [debug] [Thread-1 (]: Timing info for model.bde.stg_property (execute): 12:16:23.937087 => 12:16:24.118036
[0m12:16:24.118479 [debug] [Thread-1 (]: On model.bde.stg_property: Close
[0m12:16:24.119084 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135172e0>]}
[0m12:16:24.119514 [info ] [Thread-1 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.19s]
[0m12:16:24.119944 [debug] [Thread-1 (]: Finished running node model.bde.stg_property
[0m12:16:24.120242 [debug] [Thread-1 (]: Began running node model.bde.stg_suburb
[0m12:16:24.120624 [info ] [Thread-1 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:16:24.121179 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_suburb)
[0m12:16:24.121454 [debug] [Thread-1 (]: Began compiling node model.bde.stg_suburb
[0m12:16:24.123446 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:16:24.123988 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (compile): 12:16:24.121621 => 12:16:24.123879
[0m12:16:24.124222 [debug] [Thread-1 (]: Began executing node model.bde.stg_suburb
[0m12:16:24.126863 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:16:24.127361 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:16:24.127600 [debug] [Thread-1 (]: On model.bde.stg_suburb: BEGIN
[0m12:16:24.127819 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:24.128083 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:16:24.130821 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:16:24.131168 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:16:24.140070 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:24.141166 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:16:24.141404 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:16:24.141614 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:16:24.151965 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:24.153546 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:16:24.153794 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:16:24.168191 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:16:24.169161 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 12:16:23.986715 => 12:16:24.169040
[0m12:16:24.169430 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m12:16:24.170077 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135c2ad0>]}
[0m12:16:24.170504 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.19s]
[0m12:16:24.170917 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m12:16:24.171199 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m12:16:24.171620 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:16:24.172070 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.dim_LGA)
[0m12:16:24.172306 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m12:16:24.174399 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:16:24.174908 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 12:16:24.172478 => 12:16:24.174798
[0m12:16:24.175146 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m12:16:24.177737 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:16:24.178185 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:16:24.178412 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m12:16:24.178625 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:16:24.236397 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:24.236817 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:16:24.237090 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:16:24.250488 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:16:24.252997 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:16:24.253239 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:16:24.263493 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:24.265338 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:16:24.265585 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:16:24.276931 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:24.278008 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:16:24.278239 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:16:24.278457 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:16:24.288249 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:24.289946 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:16:24.290209 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:16:24.300775 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:16:24.301686 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (execute): 12:16:24.124380 => 12:16:24.301568
[0m12:16:24.301947 [debug] [Thread-1 (]: On model.bde.stg_suburb: Close
[0m12:16:24.302528 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114aedd80>]}
[0m12:16:24.302944 [info ] [Thread-1 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.18s]
[0m12:16:24.303362 [debug] [Thread-1 (]: Finished running node model.bde.stg_suburb
[0m12:16:24.303655 [debug] [Thread-1 (]: Began running node model.bde.fact_G01
[0m12:16:24.304096 [info ] [Thread-1 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:16:24.304628 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.fact_G01)
[0m12:16:24.304896 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G01
[0m12:16:24.307299 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:16:24.308666 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (compile): 12:16:24.305078 => 12:16:24.308538
[0m12:16:24.308921 [debug] [Thread-1 (]: Began executing node model.bde.fact_G01
[0m12:16:24.312575 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:16:24.313017 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:16:24.313255 [debug] [Thread-1 (]: On model.bde.fact_G01: BEGIN
[0m12:16:24.313472 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:16:24.450967 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:24.451564 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:16:24.452072 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:16:24.476365 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:16:24.481867 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:16:24.482424 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:16:24.493237 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:24.496842 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:16:24.497364 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:16:24.507691 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:24.514021 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:16:24.514424 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:24.514819 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:16:24.515188 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:16:24.515543 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:16:24.515917 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:16:24.527785 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:24.532196 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:16:24.532486 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:16:24.532776 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:16:24.535143 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:16:24.535514 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:16:24.546286 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:24.548569 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:16:24.548872 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:16:24.551660 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:24.552808 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (execute): 12:16:24.309094 => 12:16:24.552658
[0m12:16:24.553148 [debug] [Thread-1 (]: On model.bde.fact_G01: Close
[0m12:16:24.553931 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11352f6a0>]}
[0m12:16:24.554473 [info ] [Thread-1 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.25s]
[0m12:16:24.554989 [debug] [Thread-1 (]: Finished running node model.bde.fact_G01
[0m12:16:24.555356 [debug] [Thread-1 (]: Began running node model.bde.fact_G02
[0m12:16:24.555798 [info ] [Thread-1 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:16:24.556362 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_G02)
[0m12:16:24.556627 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G02
[0m12:16:24.558903 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:16:24.559158 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:24.560498 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:16:24.560868 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:16:24.561177 [debug] [Thread-1 (]: Timing info for model.bde.fact_G02 (compile): 12:16:24.556802 => 12:16:24.561048
[0m12:16:24.561525 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:16:24.561806 [debug] [Thread-1 (]: Began executing node model.bde.fact_G02
[0m12:16:24.564818 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:16:24.565293 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:16:24.565526 [debug] [Thread-1 (]: On model.bde.fact_G02: BEGIN
[0m12:16:24.565735 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:16:24.584674 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:24.587734 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:16:24.588028 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:16:24.606947 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:24.607979 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 12:16:24.175314 => 12:16:24.607845
[0m12:16:24.608271 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m12:16:24.608903 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135c2ad0>]}
[0m12:16:24.609343 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.44s]
[0m12:16:24.609770 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m12:16:24.610058 [debug] [Thread-4 (]: Began running node model.bde.fact_listing
[0m12:16:24.610405 [info ] [Thread-4 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:16:24.610878 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_listing)
[0m12:16:24.611131 [debug] [Thread-4 (]: Began compiling node model.bde.fact_listing
[0m12:16:24.613258 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:16:24.613845 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (compile): 12:16:24.611307 => 12:16:24.613723
[0m12:16:24.614114 [debug] [Thread-4 (]: Began executing node model.bde.fact_listing
[0m12:16:24.616780 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:16:24.617331 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:16:24.617716 [debug] [Thread-4 (]: On model.bde.fact_listing: BEGIN
[0m12:16:24.617957 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:16:24.679785 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:24.680239 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:16:24.680607 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:16:24.704984 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:16:24.708073 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:16:24.708452 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:16:24.718783 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:24.721614 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:16:24.721950 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:16:24.736719 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:24.738609 [debug] [Thread-1 (]: On model.bde.fact_G02: COMMIT
[0m12:16:24.739008 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:16:24.739370 [debug] [Thread-1 (]: On model.bde.fact_G02: COMMIT
[0m12:16:24.749184 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:24.751820 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:16:24.752215 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:16:24.752575 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:24.753017 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:16:24.753444 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:16:24.770536 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:24.772134 [debug] [Thread-1 (]: Timing info for model.bde.fact_G02 (execute): 12:16:24.562048 => 12:16:24.771943
[0m12:16:24.772548 [debug] [Thread-1 (]: On model.bde.fact_G02: Close
[0m12:16:24.773507 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114ac6410>]}
[0m12:16:24.774139 [info ] [Thread-1 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.22s]
[0m12:16:24.774760 [debug] [Thread-1 (]: Finished running node model.bde.fact_G02
[0m12:16:24.775195 [debug] [Thread-1 (]: Began running node model.bde.dim_host
[0m12:16:24.775637 [info ] [Thread-1 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:16:24.776385 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m12:16:24.776745 [debug] [Thread-1 (]: Began compiling node model.bde.dim_host
[0m12:16:24.779689 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:16:24.780423 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (compile): 12:16:24.776980 => 12:16:24.780271
[0m12:16:24.780749 [debug] [Thread-1 (]: Began executing node model.bde.dim_host
[0m12:16:24.784342 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:16:24.784871 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:16:24.785143 [debug] [Thread-1 (]: On model.bde.dim_host: BEGIN
[0m12:16:24.785402 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:16:24.959568 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:24.961004 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:16:24.961637 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:16:26.490393 [debug] [Thread-1 (]: SQL status: SELECT 28839 in 2.0 seconds
[0m12:16:26.502804 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:16:26.503573 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:16:31.970049 [debug] [Thread-4 (]: SQL status: SELECT 340945 in 7.0 seconds
[0m12:16:31.977852 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:16:31.978580 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:16:33.145324 [debug] [Thread-2 (]: SQL status: SELECT 296 in 10.0 seconds
[0m12:16:33.155279 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:16:33.155974 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:16:33.168431 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:33.173110 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:16:33.173907 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:16:33.183581 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:33.186932 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:16:33.187591 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:16:33.188125 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:16:33.199231 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:33.204381 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:16:33.204917 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:16:33.222404 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:33.225312 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:16:23.156856 => 12:16:33.225064
[0m12:16:33.225837 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:16:33.226996 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134b2740>]}
[0m12:16:33.227801 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 10.09s]
[0m12:16:33.229296 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:16:33.229885 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m12:16:33.230406 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:16:33.231295 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m12:16:33.231925 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m12:16:33.235863 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:16:33.236974 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 12:16:33.232359 => 12:16:33.236735
[0m12:16:33.237433 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m12:16:33.241677 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:16:33.242330 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:16:33.242669 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m12:16:33.242984 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:16:33.350783 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:33.351636 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:16:33.352052 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:16:33.643905 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 10.0 seconds
[0m12:16:33.651137 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:16:33.651842 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m12:16:33.667588 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:33.675257 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:16:33.675912 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m12:16:33.689050 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:33.691522 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:16:33.692009 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:16:33.692440 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:16:33.716946 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:33.718161 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 2.0 seconds
[0m12:16:33.718999 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 7.0 seconds
[0m12:16:33.723577 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:16:33.726816 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:16:33.729722 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:16:33.730151 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m12:16:33.730544 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:16:33.730922 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:16:33.743797 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:33.744197 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:33.746207 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m12:16:33.748018 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m12:16:33.748441 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:16:33.748816 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:16:33.749190 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m12:16:33.749560 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m12:16:33.759460 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:33.760919 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:16:23.181225 => 12:16:33.760702
[0m12:16:33.761324 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:16:33.762315 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134b2800>]}
[0m12:16:33.762985 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 10.63s]
[0m12:16:33.763475 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:33.764068 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:16:33.766583 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:16:33.767003 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:33.767387 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m12:16:33.767812 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:16:33.770040 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:16:33.770498 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:16:33.770998 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:16:33.771593 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m12:16:33.771940 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m12:16:33.774560 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:16:33.775251 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 12:16:33.772150 => 12:16:33.775114
[0m12:16:33.775547 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m12:16:33.778909 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:16:33.779596 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:16:33.779878 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m12:16:33.780131 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:16:33.793872 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:33.795192 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (execute): 12:16:24.780976 => 12:16:33.795055
[0m12:16:33.795521 [debug] [Thread-1 (]: On model.bde.dim_host: Close
[0m12:16:33.796298 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114ade200>]}
[0m12:16:33.796814 [info ] [Thread-1 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 9.02s]
[0m12:16:33.797277 [debug] [Thread-1 (]: Finished running node model.bde.dim_host
[0m12:16:33.797616 [debug] [Thread-1 (]: Began running node model.bde.dim_suburb
[0m12:16:33.798024 [info ] [Thread-1 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:16:33.798562 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dim_host, now model.bde.dim_suburb)
[0m12:16:33.798840 [debug] [Thread-1 (]: Began compiling node model.bde.dim_suburb
[0m12:16:33.801184 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:16:33.801739 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (compile): 12:16:33.799026 => 12:16:33.801618
[0m12:16:33.801997 [debug] [Thread-1 (]: Began executing node model.bde.dim_suburb
[0m12:16:33.806329 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:16:33.806842 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:16:33.807084 [debug] [Thread-1 (]: On model.bde.dim_suburb: BEGIN
[0m12:16:33.807304 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:16:33.843362 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:33.844780 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (execute): 12:16:24.614303 => 12:16:33.844639
[0m12:16:33.845100 [debug] [Thread-4 (]: On model.bde.fact_listing: Close
[0m12:16:33.845743 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135fc4f0>]}
[0m12:16:33.846188 [info ] [Thread-4 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 9.24s]
[0m12:16:33.846607 [debug] [Thread-4 (]: Finished running node model.bde.fact_listing
[0m12:16:33.870946 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m12:16:33.873738 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:16:33.874045 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:16:33.886093 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:33.888535 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:16:33.888815 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:16:33.898009 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:33.899464 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:16:33.899770 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:16:33.900028 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:16:33.903517 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:33.903769 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:16:33.904027 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:16:33.915818 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:33.917862 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:16:33.918160 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:16:33.920405 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:16:33.920666 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:16:33.920934 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:16:33.937701 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:33.938695 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 12:16:33.237674 => 12:16:33.938568
[0m12:16:33.938978 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m12:16:33.939576 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114bd59f0>]}
[0m12:16:33.940021 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 0.71s]
[0m12:16:33.940470 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m12:16:33.940755 [debug] [Thread-1 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:16:33.943244 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:16:33.943553 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:16:33.953136 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:33.955416 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:16:33.955720 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:16:33.965419 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:33.966818 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m12:16:33.967119 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:16:33.967385 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m12:16:33.983363 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:33.985374 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:16:33.985675 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:16:34.006254 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:34.007480 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (execute): 12:16:33.802169 => 12:16:34.007327
[0m12:16:34.007855 [debug] [Thread-1 (]: On model.bde.dim_suburb: Close
[0m12:16:34.008589 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135fa2c0>]}
[0m12:16:34.009103 [info ] [Thread-1 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.21s]
[0m12:16:34.009605 [debug] [Thread-1 (]: Finished running node model.bde.dim_suburb
[0m12:16:34.043360 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:16:34.046896 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:16:34.047356 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:16:34.057267 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:34.062264 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:16:34.062696 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:16:34.073180 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:34.074981 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:16:34.075360 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:16:34.075706 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:16:34.091685 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:16:34.094403 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:16:34.094826 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:16:34.108893 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:34.110643 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 12:16:33.775761 => 12:16:34.110423
[0m12:16:34.111154 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m12:16:34.112228 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6a0af34-2747-4716-90ec-0e27edbba032', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c009d0>]}
[0m12:16:34.112978 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.34s]
[0m12:16:34.113683 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m12:16:34.115456 [debug] [MainThread]: Using postgres connection "master"
[0m12:16:34.115814 [debug] [MainThread]: On master: BEGIN
[0m12:16:34.116127 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:16:34.227971 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:16:34.229962 [debug] [MainThread]: On master: COMMIT
[0m12:16:34.231052 [debug] [MainThread]: Using postgres connection "master"
[0m12:16:34.232016 [debug] [MainThread]: On master: COMMIT
[0m12:16:34.242205 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:16:34.242831 [debug] [MainThread]: On master: Close
[0m12:16:34.243827 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:16:34.244159 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:16:34.244455 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m12:16:34.244738 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:16:34.245021 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:16:34.245441 [info ] [MainThread]: 
[0m12:16:34.245810 [info ] [MainThread]: Finished running 11 table models, 8 view models in 0 hours 0 minutes and 11.63 seconds (11.63s).
[0m12:16:34.248451 [debug] [MainThread]: Command end result
[0m12:16:34.256782 [info ] [MainThread]: 
[0m12:16:34.257175 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m12:16:34.257434 [info ] [MainThread]: 
[0m12:16:34.257700 [error] [MainThread]:   Database Error in model dm_host_neighbourhod (models/datamart/dm_host_neighbourhod.sql)
  column host.scraped_date does not exist
  LINE 18:         TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
                           ^
  compiled Code at target/run/bde/models/datamart/dm_host_neighbourhod.sql
[0m12:16:34.257970 [info ] [MainThread]: 
[0m12:16:34.258223 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m12:16:34.258715 [debug] [MainThread]: Command `dbt run` failed at 12:16:34.258643 after 11.79 seconds
[0m12:16:34.259032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ad9810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114bbe0e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b983d0>]}
[0m12:16:34.259337 [debug] [MainThread]: Flushing usage events
[0m12:18:48.265638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b58f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11154da50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11154d390>]}


============================== 12:18:48.268137 | 6ac5da07-111c-48d7-8cf7-68b79b79d551 ==============================
[0m12:18:48.268137 [info ] [MainThread]: Running with dbt=1.6.6
[0m12:18:48.268448 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:18:48.324260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11154d5a0>]}
[0m12:18:48.331900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119010f0>]}
[0m12:18:48.332259 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m12:18:48.341327 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m12:18:48.366810 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:18:48.367179 [debug] [MainThread]: Partial parsing: updated file: bde://models/warehouse/dim_host.sql
[0m12:18:48.387969 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.raw
- models.bde.median
[0m12:18:48.390876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121ecbb0>]}
[0m12:18:48.397387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f26c50>]}
[0m12:18:48.397625 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m12:18:48.397804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f26e60>]}
[0m12:18:48.398942 [info ] [MainThread]: 
[0m12:18:48.399298 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:18:48.400129 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:18:48.400535 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:18:48.400861 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:18:48.405440 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:18:48.406356 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:18:48.407167 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:18:48.407326 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:18:48.407495 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:18:48.407675 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:18:48.407830 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:18:48.407967 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:18:48.408095 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:18:48.582850 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:18:48.584383 [debug] [ThreadPool]: On list_postgres: Close
[0m12:18:48.584661 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:18:48.585540 [debug] [ThreadPool]: On list_postgres: Close
[0m12:18:48.592268 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:18:48.593132 [debug] [ThreadPool]: On list_postgres: Close
[0m12:18:48.594934 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m12:18:48.595437 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m12:18:48.600157 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:18:48.600639 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_staging)
[0m12:18:48.601065 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_warehouse'
[0m12:18:48.602406 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:18:48.602637 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m12:18:48.603705 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:18:48.604820 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:18:48.605025 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m12:18:48.605205 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:18:48.605384 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m12:18:48.605558 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m12:18:48.605725 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:18:48.606004 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:18:48.606198 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:18:48.702754 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:18:48.703087 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:18:48.703404 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:18:48.703636 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:18:48.703873 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m12:18:48.704130 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m12:18:48.712649 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:18:48.712878 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:18:48.713101 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m12:18:48.718502 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:18:48.718706 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:18:48.718923 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m12:18:48.720251 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:18:48.721216 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m12:18:48.729885 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:18:48.730136 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:18:48.731093 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m12:18:48.731328 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m12:18:48.732178 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m12:18:48.734374 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:18:48.735158 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m12:18:48.740874 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m12:18:48.742147 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m12:18:48.745472 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m12:18:48.750698 [debug] [MainThread]: Using postgres connection "master"
[0m12:18:48.751074 [debug] [MainThread]: On master: BEGIN
[0m12:18:48.751296 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:18:48.844160 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:18:48.844605 [debug] [MainThread]: Using postgres connection "master"
[0m12:18:48.845040 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:18:48.875439 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:18:48.878194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112308520>]}
[0m12:18:48.878743 [debug] [MainThread]: On master: ROLLBACK
[0m12:18:48.887545 [debug] [MainThread]: Using postgres connection "master"
[0m12:18:48.887856 [debug] [MainThread]: On master: BEGIN
[0m12:18:48.905318 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:18:48.905717 [debug] [MainThread]: On master: COMMIT
[0m12:18:48.906014 [debug] [MainThread]: Using postgres connection "master"
[0m12:18:48.906298 [debug] [MainThread]: On master: COMMIT
[0m12:18:48.915645 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:18:48.915978 [debug] [MainThread]: On master: Close
[0m12:18:48.916890 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:18:48.917247 [info ] [MainThread]: 
[0m12:18:48.921478 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m12:18:48.921884 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m12:18:48.922260 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m12:18:48.922536 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m12:18:48.922965 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m12:18:48.923344 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m12:18:48.923711 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m12:18:48.924065 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m12:18:48.924624 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_host_neighbourhod)
[0m12:18:48.925089 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_listing_neighbourhood)
[0m12:18:48.925533 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.dm_property_type)
[0m12:18:48.925963 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.stg_G01)
[0m12:18:48.926254 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m12:18:48.926520 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m12:18:48.926803 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m12:18:48.927067 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m12:18:48.933643 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m12:18:48.936162 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m12:18:48.939427 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m12:18:48.941612 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m12:18:48.942466 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 12:18:48.927309 => 12:18:48.942293
[0m12:18:48.943023 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m12:18:48.943378 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 12:18:48.939630 => 12:18:48.943204
[0m12:18:48.943674 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 12:18:48.933877 => 12:18:48.943559
[0m12:18:48.949262 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 12:18:48.936373 => 12:18:48.949109
[0m12:18:48.967116 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m12:18:48.967444 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m12:18:48.967701 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m12:18:48.967950 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m12:18:48.978360 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m12:18:48.980641 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m12:18:48.980885 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:18:48.982862 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m12:18:48.983205 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m12:18:48.983538 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:18:48.983742 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:18:48.984044 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m12:18:48.984225 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:18:48.984394 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:18:48.984660 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:18:48.984851 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m12:18:48.985047 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m12:18:48.985289 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:18:48.985480 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:18:49.073924 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:49.074377 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:18:49.074725 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM 
        warehouse.dim_host host
    LEFT JOIN 
        warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
distinct_host_count AS (
    SELECT
        TO_CHAR(h.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        COUNT(DISTINCT h.host_id) AS num_distinct_hosts
    FROM
        host_neighbourhood_lga_transform h
    GROUP BY
        TO_CHAR(h.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
),
estimated_revenue AS (
    SELECT
        TO_CHAR(l.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        SUM((30 - l.availability_30) * l.price) AS total_estimated_revenue
    FROM
        warehouse.fact_listing l
    LEFT JOIN
        host_neighbourhood_lga_transform h ON l.surrogate_key_host = h.surrogate_key_host
    WHERE
        l.has_availability = 't'
    GROUP BY
        TO_CHAR(l.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
)
SELECT
    dhct.month_year,
    dhct.host_neighbourhood_lga,
    dhct.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dhct.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dhct.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM
    distinct_host_count dhct
LEFT JOIN
    estimated_revenue er ON dhct.month_year = er.month_year AND dhct.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY
    dhct.month_year, dhct.host_neighbourhood_lga
  );
  
[0m12:18:49.089871 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:49.090165 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:18:49.090435 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:49.090946 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type



WITH sorted_listing AS (
    SELECT 
        prop.property_type,
        room.room_type,
        list.accommodates,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
SELECT 
    property_type,
    room_type,
    accommodates,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,



    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:18:49.091441 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:18:49.091774 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column host.scraped_date does not exist
LINE 18:         TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
                         ^

[0m12:18:49.092346 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m12:18:49.092842 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: ROLLBACK
[0m12:18:49.113794 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:18:48.943857 => 12:18:49.113614
[0m12:18:49.114113 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:18:49.118794 [debug] [Thread-1 (]: Database Error in model dm_host_neighbourhod (models/datamart/dm_host_neighbourhod.sql)
  column host.scraped_date does not exist
  LINE 18:         TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
                           ^
  compiled Code at target/run/bde/models/datamart/dm_host_neighbourhod.sql
[0m12:18:49.119200 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f24a30>]}
[0m12:18:49.119686 [error] [Thread-1 (]: 1 of 19 ERROR creating sql table model datamart.dm_host_neighbourhod ........... [[31mERROR[0m in 0.19s]
[0m12:18:49.120136 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:18:49.120447 [debug] [Thread-1 (]: Began running node model.bde.stg_G02
[0m12:18:49.120818 [info ] [Thread-1 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:18:49.121258 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.stg_G02)
[0m12:18:49.121501 [debug] [Thread-1 (]: Began compiling node model.bde.stg_G02
[0m12:18:49.124787 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:18:49.125340 [debug] [Thread-1 (]: Timing info for model.bde.stg_G02 (compile): 12:18:49.121665 => 12:18:49.125224
[0m12:18:49.125587 [debug] [Thread-1 (]: Began executing node model.bde.stg_G02
[0m12:18:49.128294 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:18:49.128795 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:18:49.129034 [debug] [Thread-1 (]: On model.bde.stg_G02: BEGIN
[0m12:18:49.129248 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:18:49.236672 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:49.237229 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:18:49.237725 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:18:49.254049 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:18:49.261202 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:18:49.261608 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:18:49.271875 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:49.274628 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:18:49.274965 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:18:49.285601 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:49.299294 [debug] [Thread-1 (]: On model.bde.stg_G02: COMMIT
[0m12:18:49.299619 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:49.299943 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:18:49.300213 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:18:49.300465 [debug] [Thread-1 (]: On model.bde.stg_G02: COMMIT
[0m12:18:49.300879 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:18:49.312232 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:49.317905 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:18:49.318190 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:18:49.326552 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:18:49.328800 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:18:49.329072 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:18:49.330455 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:18:49.331366 [debug] [Thread-1 (]: Timing info for model.bde.stg_G02 (execute): 12:18:49.125748 => 12:18:49.331242
[0m12:18:49.331626 [debug] [Thread-1 (]: On model.bde.stg_G02: Close
[0m12:18:49.332233 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123cb490>]}
[0m12:18:49.332643 [info ] [Thread-1 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.21s]
[0m12:18:49.333031 [debug] [Thread-1 (]: Finished running node model.bde.stg_G02
[0m12:18:49.333323 [debug] [Thread-1 (]: Began running node model.bde.stg_LGA
[0m12:18:49.333681 [info ] [Thread-1 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:18:49.334135 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m12:18:49.334367 [debug] [Thread-1 (]: Began compiling node model.bde.stg_LGA
[0m12:18:49.336347 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:18:49.336963 [debug] [Thread-1 (]: Timing info for model.bde.stg_LGA (compile): 12:18:49.334522 => 12:18:49.336850
[0m12:18:49.337205 [debug] [Thread-1 (]: Began executing node model.bde.stg_LGA
[0m12:18:49.340555 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:18:49.340802 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:49.342562 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:18:49.342804 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:18:49.343077 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:18:49.343281 [debug] [Thread-1 (]: On model.bde.stg_LGA: BEGIN
[0m12:18:49.343494 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:18:49.353509 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:49.354597 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:18:49.354818 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:18:49.355030 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:18:49.370455 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:49.372169 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:18:49.372403 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:18:49.387039 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:18:49.388052 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:18:48.968179 => 12:18:49.387934
[0m12:18:49.388341 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:18:49.388936 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121af880>]}
[0m12:18:49.389354 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.46s]
[0m12:18:49.389741 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:18:49.390022 [debug] [Thread-4 (]: Began running node model.bde.stg_fact
[0m12:18:49.390358 [info ] [Thread-4 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:18:49.390795 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_fact)
[0m12:18:49.391030 [debug] [Thread-4 (]: Began compiling node model.bde.stg_fact
[0m12:18:49.393275 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:18:49.394235 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (compile): 12:18:49.391192 => 12:18:49.394105
[0m12:18:49.394479 [debug] [Thread-4 (]: Began executing node model.bde.stg_fact
[0m12:18:49.397017 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:18:49.397435 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:18:49.397647 [debug] [Thread-4 (]: On model.bde.stg_fact: BEGIN
[0m12:18:49.397851 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:18:49.456568 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:49.456934 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:18:49.457239 [debug] [Thread-1 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:18:49.476027 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:18:49.478982 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:18:49.479321 [debug] [Thread-1 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:18:49.489148 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:49.491437 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:18:49.491731 [debug] [Thread-1 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:18:49.501779 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:49.503027 [debug] [Thread-1 (]: On model.bde.stg_LGA: COMMIT
[0m12:18:49.503315 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:18:49.503585 [debug] [Thread-1 (]: On model.bde.stg_LGA: COMMIT
[0m12:18:49.519400 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:49.519727 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:49.520096 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:18:49.522348 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:18:49.522823 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:18:49.523263 [debug] [Thread-1 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:18:49.541743 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:18:49.542055 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:18:49.543383 [debug] [Thread-1 (]: Timing info for model.bde.stg_LGA (execute): 12:18:49.337372 => 12:18:49.543218
[0m12:18:49.546356 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:18:49.546735 [debug] [Thread-1 (]: On model.bde.stg_LGA: Close
[0m12:18:49.547020 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:18:49.547707 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113697df0>]}
[0m12:18:49.548186 [info ] [Thread-1 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.21s]
[0m12:18:49.548635 [debug] [Thread-1 (]: Finished running node model.bde.stg_LGA
[0m12:18:49.548989 [debug] [Thread-1 (]: Began running node model.bde.stg_host
[0m12:18:49.549401 [info ] [Thread-1 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:18:49.550115 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_host)
[0m12:18:49.550462 [debug] [Thread-1 (]: Began compiling node model.bde.stg_host
[0m12:18:49.579904 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:49.581801 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:18:49.583894 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:18:49.584275 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:18:49.584735 [debug] [Thread-1 (]: Timing info for model.bde.stg_host (compile): 12:18:49.550682 => 12:18:49.584618
[0m12:18:49.584992 [debug] [Thread-1 (]: Began executing node model.bde.stg_host
[0m12:18:49.587415 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:18:49.587866 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_host"
[0m12:18:49.588076 [debug] [Thread-1 (]: On model.bde.stg_host: BEGIN
[0m12:18:49.588273 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:18:49.594311 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:49.595436 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:18:49.595650 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:18:49.595835 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:18:49.606627 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:49.608318 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:18:49.608550 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:18:49.620260 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:18:49.621090 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (execute): 12:18:49.394632 => 12:18:49.620982
[0m12:18:49.621323 [debug] [Thread-4 (]: On model.bde.stg_fact: Close
[0m12:18:49.621873 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112333580>]}
[0m12:18:49.622243 [info ] [Thread-4 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.23s]
[0m12:18:49.622603 [debug] [Thread-4 (]: Finished running node model.bde.stg_fact
[0m12:18:49.622863 [debug] [Thread-4 (]: Began running node model.bde.stg_property
[0m12:18:49.623254 [info ] [Thread-4 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:18:49.623713 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_property)
[0m12:18:49.623953 [debug] [Thread-4 (]: Began compiling node model.bde.stg_property
[0m12:18:49.625960 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:18:49.626432 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (compile): 12:18:49.624114 => 12:18:49.626323
[0m12:18:49.626647 [debug] [Thread-4 (]: Began executing node model.bde.stg_property
[0m12:18:49.629055 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:18:49.629429 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:18:49.629628 [debug] [Thread-4 (]: On model.bde.stg_property: BEGIN
[0m12:18:49.629813 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:18:49.694762 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:49.695179 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_host"
[0m12:18:49.695528 [debug] [Thread-1 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:18:49.711511 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:18:49.714293 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_host"
[0m12:18:49.714600 [debug] [Thread-1 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:18:49.723582 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:49.725625 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_host"
[0m12:18:49.725963 [debug] [Thread-1 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:18:49.735555 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:49.736654 [debug] [Thread-1 (]: On model.bde.stg_host: COMMIT
[0m12:18:49.736915 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_host"
[0m12:18:49.737148 [debug] [Thread-1 (]: On model.bde.stg_host: COMMIT
[0m12:18:49.749222 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:49.752309 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_host"
[0m12:18:49.752582 [debug] [Thread-1 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:18:49.762870 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:18:49.764040 [debug] [Thread-1 (]: Timing info for model.bde.stg_host (execute): 12:18:49.585144 => 12:18:49.763890
[0m12:18:49.764360 [debug] [Thread-1 (]: On model.bde.stg_host: Close
[0m12:18:49.765085 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136f7df0>]}
[0m12:18:49.765580 [info ] [Thread-1 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.22s]
[0m12:18:49.766053 [debug] [Thread-1 (]: Finished running node model.bde.stg_host
[0m12:18:49.766394 [debug] [Thread-1 (]: Began running node model.bde.stg_room
[0m12:18:49.766846 [info ] [Thread-1 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:18:49.767346 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_room)
[0m12:18:49.767603 [debug] [Thread-1 (]: Began compiling node model.bde.stg_room
[0m12:18:49.769846 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:18:49.770422 [debug] [Thread-1 (]: Timing info for model.bde.stg_room (compile): 12:18:49.767779 => 12:18:49.770296
[0m12:18:49.770686 [debug] [Thread-1 (]: Began executing node model.bde.stg_room
[0m12:18:49.773457 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:18:49.773908 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_room"
[0m12:18:49.774155 [debug] [Thread-1 (]: On model.bde.stg_room: BEGIN
[0m12:18:49.774393 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:18:49.899381 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:49.900002 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_room"
[0m12:18:49.900477 [debug] [Thread-1 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:18:49.912350 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:18:49.916305 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_room"
[0m12:18:49.916725 [debug] [Thread-1 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:18:49.926685 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:49.929644 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_room"
[0m12:18:49.929983 [debug] [Thread-1 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:18:49.940672 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:49.942299 [debug] [Thread-1 (]: On model.bde.stg_room: COMMIT
[0m12:18:49.942688 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_room"
[0m12:18:49.943036 [debug] [Thread-1 (]: On model.bde.stg_room: COMMIT
[0m12:18:49.952366 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:49.952754 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:18:49.953197 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:18:49.954424 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:49.957009 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_room"
[0m12:18:49.957391 [debug] [Thread-1 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:18:49.967477 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:18:49.970820 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:18:49.971240 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:18:49.971763 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:18:49.973228 [debug] [Thread-1 (]: Timing info for model.bde.stg_room (execute): 12:18:49.770869 => 12:18:49.973056
[0m12:18:49.973737 [debug] [Thread-1 (]: On model.bde.stg_room: Close
[0m12:18:49.974632 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11236fbe0>]}
[0m12:18:49.975253 [info ] [Thread-1 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.21s]
[0m12:18:49.975800 [debug] [Thread-1 (]: Finished running node model.bde.stg_room
[0m12:18:49.976211 [debug] [Thread-1 (]: Began running node model.bde.stg_suburb
[0m12:18:49.976796 [info ] [Thread-1 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:18:49.977428 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.stg_suburb)
[0m12:18:49.977778 [debug] [Thread-1 (]: Began compiling node model.bde.stg_suburb
[0m12:18:49.980512 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:18:49.981164 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (compile): 12:18:49.978051 => 12:18:49.981028
[0m12:18:49.981454 [debug] [Thread-1 (]: Began executing node model.bde.stg_suburb
[0m12:18:49.985953 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:18:49.986263 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:49.988685 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:18:49.989064 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:18:49.989361 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:18:49.989681 [debug] [Thread-1 (]: On model.bde.stg_suburb: BEGIN
[0m12:18:49.989974 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:18:49.999370 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:50.000603 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:18:50.000875 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:18:50.001124 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:18:50.015553 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:50.017718 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:18:50.018018 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:18:50.034844 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:18:50.035970 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (execute): 12:18:49.626796 => 12:18:50.035827
[0m12:18:50.036280 [debug] [Thread-4 (]: On model.bde.stg_property: Close
[0m12:18:50.036941 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118a5330>]}
[0m12:18:50.037404 [info ] [Thread-4 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.41s]
[0m12:18:50.037811 [debug] [Thread-4 (]: Finished running node model.bde.stg_property
[0m12:18:50.038104 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m12:18:50.038397 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:18:50.038937 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.dim_LGA)
[0m12:18:50.039287 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m12:18:50.041506 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:18:50.042073 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 12:18:50.039465 => 12:18:50.041955
[0m12:18:50.042350 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m12:18:50.045215 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:18:50.045720 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:18:50.045955 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m12:18:50.046169 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:18:50.109974 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:50.110354 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:18:50.110665 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:18:50.121360 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:18:50.124465 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:18:50.124814 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:18:50.134086 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:50.136562 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:18:50.136950 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:18:50.145872 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:50.147370 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:18:50.147689 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:18:50.147987 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:18:50.157446 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:50.157756 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:18:50.158080 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:18:50.158423 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:50.160694 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:18:50.161035 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:18:50.173318 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:18:50.174684 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (execute): 12:18:49.981651 => 12:18:50.174506
[0m12:18:50.175070 [debug] [Thread-1 (]: On model.bde.stg_suburb: Close
[0m12:18:50.175888 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11367ece0>]}
[0m12:18:50.176266 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:18:50.176868 [info ] [Thread-1 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.20s]
[0m12:18:50.179579 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:18:50.180067 [debug] [Thread-1 (]: Finished running node model.bde.stg_suburb
[0m12:18:50.180390 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:18:50.180776 [debug] [Thread-1 (]: Began running node model.bde.fact_G01
[0m12:18:50.181336 [info ] [Thread-1 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:18:50.181937 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.fact_G01)
[0m12:18:50.182287 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G01
[0m12:18:50.186511 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:18:50.187146 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (compile): 12:18:50.182537 => 12:18:50.187003
[0m12:18:50.187436 [debug] [Thread-1 (]: Began executing node model.bde.fact_G01
[0m12:18:50.190481 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:18:50.190998 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:18:50.191282 [debug] [Thread-1 (]: On model.bde.fact_G01: BEGIN
[0m12:18:50.191562 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:18:50.191987 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:50.193983 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:18:50.194341 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:18:50.203128 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:50.206880 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:18:50.207167 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:18:50.207404 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:18:50.216630 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:50.219636 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:18:50.219891 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:18:50.233740 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:18:50.234647 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 12:18:50.042586 => 12:18:50.234546
[0m12:18:50.234861 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m12:18:50.235345 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111900e50>]}
[0m12:18:50.235698 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.20s]
[0m12:18:50.236021 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m12:18:50.236251 [debug] [Thread-4 (]: Began running node model.bde.fact_G02
[0m12:18:50.236550 [info ] [Thread-4 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:18:50.236955 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G02)
[0m12:18:50.237173 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G02
[0m12:18:50.239070 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:18:50.239552 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (compile): 12:18:50.237322 => 12:18:50.239448
[0m12:18:50.239749 [debug] [Thread-4 (]: Began executing node model.bde.fact_G02
[0m12:18:50.241955 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:18:50.242304 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:18:50.242485 [debug] [Thread-4 (]: On model.bde.fact_G02: BEGIN
[0m12:18:50.242656 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:18:50.301046 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:50.301417 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:18:50.301695 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:18:50.330490 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:18:50.332981 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:18:50.333300 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:18:50.343109 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:50.345194 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:18:50.345502 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:18:50.352511 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:50.352782 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:18:50.353061 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:18:50.355258 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:50.358040 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:18:50.358351 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:18:50.358612 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:18:50.368793 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:50.370728 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:18:50.371020 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:18:50.371681 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:18:50.373927 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:18:50.374249 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:18:50.385100 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:50.387578 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:18:50.387882 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:18:50.388228 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:18:50.389280 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (execute): 12:18:50.187630 => 12:18:50.389138
[0m12:18:50.389578 [debug] [Thread-1 (]: On model.bde.fact_G01: Close
[0m12:18:50.390224 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11367ece0>]}
[0m12:18:50.390701 [info ] [Thread-1 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.21s]
[0m12:18:50.391205 [debug] [Thread-1 (]: Finished running node model.bde.fact_G01
[0m12:18:50.391539 [debug] [Thread-1 (]: Began running node model.bde.fact_listing
[0m12:18:50.391965 [info ] [Thread-1 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:18:50.392535 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_listing)
[0m12:18:50.392843 [debug] [Thread-1 (]: Began compiling node model.bde.fact_listing
[0m12:18:50.395310 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:18:50.395851 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (compile): 12:18:50.393046 => 12:18:50.395723
[0m12:18:50.396106 [debug] [Thread-1 (]: Began executing node model.bde.fact_listing
[0m12:18:50.398862 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:18:50.399107 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:50.400391 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:18:50.400659 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:18:50.400891 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:18:50.401130 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:18:50.401414 [debug] [Thread-1 (]: On model.bde.fact_listing: BEGIN
[0m12:18:50.401645 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:18:50.411565 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:50.413466 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:18:50.413732 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:18:50.429553 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:18:50.430524 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (execute): 12:18:50.239892 => 12:18:50.430405
[0m12:18:50.430801 [debug] [Thread-4 (]: On model.bde.fact_G02: Close
[0m12:18:50.431385 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112141540>]}
[0m12:18:50.431786 [info ] [Thread-4 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.19s]
[0m12:18:50.432198 [debug] [Thread-4 (]: Finished running node model.bde.fact_G02
[0m12:18:50.432486 [debug] [Thread-4 (]: Began running node model.bde.dim_host
[0m12:18:50.432857 [info ] [Thread-4 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:18:50.433363 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m12:18:50.433624 [debug] [Thread-4 (]: Began compiling node model.bde.dim_host
[0m12:18:50.435873 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:18:50.436402 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (compile): 12:18:50.433804 => 12:18:50.436267
[0m12:18:50.436653 [debug] [Thread-4 (]: Began executing node model.bde.dim_host
[0m12:18:50.439333 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:18:50.439729 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:18:50.439952 [debug] [Thread-4 (]: On model.bde.dim_host: BEGIN
[0m12:18:50.440160 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:18:50.511181 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:50.511560 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:18:50.511917 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:18:50.565483 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:50.565978 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:18:50.566480 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    scraped_date,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:18:51.265566 [debug] [Thread-4 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m12:18:51.277899 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:18:51.278477 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:18:52.780830 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m12:18:52.788999 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:18:52.789928 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:18:52.799609 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:52.803873 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:18:52.804370 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:18:52.823017 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:52.827207 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:18:52.827774 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:18:52.828224 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:18:52.857181 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:52.863685 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:18:52.864526 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:18:52.885903 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:18:52.889104 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:18:48.978651 => 12:18:52.888834
[0m12:18:52.889678 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:18:52.890922 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123ca8f0>]}
[0m12:18:52.891931 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 3.97s]
[0m12:18:52.892753 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:18:52.893239 [debug] [Thread-2 (]: Began running node model.bde.dim_room
[0m12:18:52.893790 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:18:52.894519 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_room)
[0m12:18:52.894906 [debug] [Thread-2 (]: Began compiling node model.bde.dim_room
[0m12:18:52.898545 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:18:52.899454 [debug] [Thread-2 (]: Timing info for model.bde.dim_room (compile): 12:18:52.895173 => 12:18:52.899261
[0m12:18:52.899795 [debug] [Thread-2 (]: Began executing node model.bde.dim_room
[0m12:18:52.903536 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:18:52.904224 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:18:52.904544 [debug] [Thread-2 (]: On model.bde.dim_room: BEGIN
[0m12:18:52.904851 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:18:53.025138 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:53.026713 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:18:53.027364 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:18:53.536186 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m12:18:53.538926 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:18:53.539237 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:18:53.831411 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 5.0 seconds
[0m12:18:53.839666 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:18:53.840856 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m12:18:53.851737 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:53.859569 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:18:53.860137 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m12:18:53.869304 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:53.871764 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:18:53.872191 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:18:53.872569 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:18:53.899098 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 3.0 seconds
[0m12:18:53.900250 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:53.905254 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:18:53.905764 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:53.909196 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:18:53.909623 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:18:53.912261 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:18:53.912732 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:18:53.913244 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m12:18:53.914978 [debug] [Thread-1 (]: SQL status: SELECT 340945 in 3.0 seconds
[0m12:18:53.918208 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:18:53.918632 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:18:53.922228 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:53.923861 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:18:53.924201 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:53.924558 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:18:53.926268 [debug] [Thread-2 (]: On model.bde.dim_room: COMMIT
[0m12:18:53.926620 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:18:53.926954 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:18:53.927294 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:53.927760 [debug] [Thread-2 (]: On model.bde.dim_room: COMMIT
[0m12:18:53.930333 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:18:53.930705 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:18:53.936145 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:18:53.937346 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:18:48.981060 => 12:18:53.937174
[0m12:18:53.937717 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:18:53.938218 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:53.938877 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11234e260>]}
[0m12:18:53.940898 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:18:53.941162 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:53.941419 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:53.941897 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 5.01s]
[0m12:18:53.942260 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:18:53.944293 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:18:53.945841 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:18:53.946323 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:18:53.946652 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:18:53.946916 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:18:53.947199 [debug] [Thread-3 (]: Began running node model.bde.dim_property
[0m12:18:53.947814 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:18:53.948293 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:18:53.948886 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_property)
[0m12:18:53.949214 [debug] [Thread-3 (]: Began compiling node model.bde.dim_property
[0m12:18:53.952742 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:18:53.953380 [debug] [Thread-3 (]: Timing info for model.bde.dim_property (compile): 12:18:53.949411 => 12:18:53.953244
[0m12:18:53.953660 [debug] [Thread-3 (]: Began executing node model.bde.dim_property
[0m12:18:53.956660 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:18:53.957269 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_property"
[0m12:18:53.957529 [debug] [Thread-3 (]: On model.bde.dim_property: BEGIN
[0m12:18:53.957763 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:18:53.963083 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:18:53.964093 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (execute): 12:18:50.436824 => 12:18:53.963991
[0m12:18:53.964324 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:53.964530 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:18:53.964772 [debug] [Thread-4 (]: On model.bde.dim_host: Close
[0m12:18:53.966532 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:18:53.967387 [debug] [Thread-2 (]: Timing info for model.bde.dim_room (execute): 12:18:52.900025 => 12:18:53.967291
[0m12:18:53.967670 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:18:53.967926 [debug] [Thread-2 (]: On model.bde.dim_room: Close
[0m12:18:53.968326 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137d05e0>]}
[0m12:18:53.969179 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123939d0>]}
[0m12:18:53.968793 [info ] [Thread-4 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 3.54s]
[0m12:18:53.969584 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 1.07s]
[0m12:18:53.969930 [debug] [Thread-4 (]: Finished running node model.bde.dim_host
[0m12:18:53.970225 [debug] [Thread-2 (]: Finished running node model.bde.dim_room
[0m12:18:53.970481 [debug] [Thread-4 (]: Began running node model.bde.dim_suburb
[0m12:18:53.970868 [info ] [Thread-4 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:18:53.971330 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_host, now model.bde.dim_suburb)
[0m12:18:53.971564 [debug] [Thread-4 (]: Began compiling node model.bde.dim_suburb
[0m12:18:53.973480 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:18:53.973938 [debug] [Thread-4 (]: Timing info for model.bde.dim_suburb (compile): 12:18:53.971730 => 12:18:53.973830
[0m12:18:53.974148 [debug] [Thread-4 (]: Began executing node model.bde.dim_suburb
[0m12:18:53.976488 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:18:53.976920 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:18:53.977122 [debug] [Thread-4 (]: On model.bde.dim_suburb: BEGIN
[0m12:18:53.977313 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:18:54.000196 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:18:54.001262 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (execute): 12:18:50.396279 => 12:18:54.001149
[0m12:18:54.001507 [debug] [Thread-1 (]: On model.bde.fact_listing: Close
[0m12:18:54.002045 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11367ece0>]}
[0m12:18:54.002408 [info ] [Thread-1 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 3.61s]
[0m12:18:54.002768 [debug] [Thread-1 (]: Finished running node model.bde.fact_listing
[0m12:18:54.057224 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:54.057651 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_property"
[0m12:18:54.057934 [debug] [Thread-3 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:18:54.065917 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:18:54.066174 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:18:54.066413 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:18:54.091114 [debug] [Thread-4 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:18:54.093800 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:18:54.094129 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:18:54.104031 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:54.106380 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:18:54.106642 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:18:54.116106 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:54.117484 [debug] [Thread-4 (]: On model.bde.dim_suburb: COMMIT
[0m12:18:54.117724 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:18:54.117947 [debug] [Thread-4 (]: On model.bde.dim_suburb: COMMIT
[0m12:18:54.140189 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:54.142178 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:18:54.142434 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:18:54.159537 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:18:54.160716 [debug] [Thread-4 (]: Timing info for model.bde.dim_suburb (execute): 12:18:53.974287 => 12:18:54.160588
[0m12:18:54.161019 [debug] [Thread-4 (]: On model.bde.dim_suburb: Close
[0m12:18:54.161733 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123ca8f0>]}
[0m12:18:54.162188 [info ] [Thread-4 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.19s]
[0m12:18:54.162604 [debug] [Thread-4 (]: Finished running node model.bde.dim_suburb
[0m12:18:54.278057 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:18:54.281518 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_property"
[0m12:18:54.281882 [debug] [Thread-3 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:18:54.290963 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:54.295242 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_property"
[0m12:18:54.295603 [debug] [Thread-3 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:18:54.304466 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:18:54.306151 [debug] [Thread-3 (]: On model.bde.dim_property: COMMIT
[0m12:18:54.306446 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_property"
[0m12:18:54.306714 [debug] [Thread-3 (]: On model.bde.dim_property: COMMIT
[0m12:18:54.324867 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:18:54.327333 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_property"
[0m12:18:54.327838 [debug] [Thread-3 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:18:54.343110 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:18:54.344482 [debug] [Thread-3 (]: Timing info for model.bde.dim_property (execute): 12:18:53.953863 => 12:18:54.344347
[0m12:18:54.344756 [debug] [Thread-3 (]: On model.bde.dim_property: Close
[0m12:18:54.345416 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ac5da07-111c-48d7-8cf7-68b79b79d551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123dae90>]}
[0m12:18:54.345807 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 0.40s]
[0m12:18:54.346177 [debug] [Thread-3 (]: Finished running node model.bde.dim_property
[0m12:18:54.347216 [debug] [MainThread]: Using postgres connection "master"
[0m12:18:54.347449 [debug] [MainThread]: On master: BEGIN
[0m12:18:54.347633 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:18:54.442461 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:18:54.442905 [debug] [MainThread]: On master: COMMIT
[0m12:18:54.443135 [debug] [MainThread]: Using postgres connection "master"
[0m12:18:54.443361 [debug] [MainThread]: On master: COMMIT
[0m12:18:54.453063 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:18:54.453305 [debug] [MainThread]: On master: Close
[0m12:18:54.453888 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:18:54.454090 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:18:54.454270 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:18:54.454452 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m12:18:54.454633 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:18:54.454943 [info ] [MainThread]: 
[0m12:18:54.455226 [info ] [MainThread]: Finished running 11 table models, 8 view models in 0 hours 0 minutes and 6.06 seconds (6.06s).
[0m12:18:54.457097 [debug] [MainThread]: Command end result
[0m12:18:54.463584 [info ] [MainThread]: 
[0m12:18:54.463880 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m12:18:54.464085 [info ] [MainThread]: 
[0m12:18:54.464299 [error] [MainThread]:   Database Error in model dm_host_neighbourhod (models/datamart/dm_host_neighbourhod.sql)
  column host.scraped_date does not exist
  LINE 18:         TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
                           ^
  compiled Code at target/run/bde/models/datamart/dm_host_neighbourhod.sql
[0m12:18:54.464534 [info ] [MainThread]: 
[0m12:18:54.464743 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m12:18:54.465180 [debug] [MainThread]: Command `dbt run` failed at 12:18:54.465124 after 6.21 seconds
[0m12:18:54.465459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b58f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137c3670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123d9330>]}
[0m12:18:54.465698 [debug] [MainThread]: Flushing usage events
[0m12:20:19.098803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d6a500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cc1ab0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cc13f0>]}


============================== 12:20:19.101270 | 5c7e64dd-d660-4c78-a704-1707483e9ad2 ==============================
[0m12:20:19.101270 [info ] [MainThread]: Running with dbt=1.6.6
[0m12:20:19.101572 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --full-refresh', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:20:19.150338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cc1600>]}
[0m12:20:19.158237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105111150>]}
[0m12:20:19.158655 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m12:20:19.167591 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m12:20:19.189662 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:20:19.189883 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:20:19.190535 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.median
- models.bde.raw
[0m12:20:19.193760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056940d0>]}
[0m12:20:19.199490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105526cb0>]}
[0m12:20:19.199729 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m12:20:19.199907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055240a0>]}
[0m12:20:19.201067 [info ] [MainThread]: 
[0m12:20:19.201440 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:20:19.202268 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:20:19.202674 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:20:19.207456 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:20:19.207744 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:20:19.208684 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:20:19.208881 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:20:19.210089 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:20:19.210289 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:20:19.210465 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:20:19.210628 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:20:19.210796 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:20:19.211542 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:20:19.370838 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:20:19.372290 [debug] [ThreadPool]: On list_postgres: Close
[0m12:20:19.372575 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:20:19.372834 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:20:19.373796 [debug] [ThreadPool]: On list_postgres: Close
[0m12:20:19.375084 [debug] [ThreadPool]: On list_postgres: Close
[0m12:20:19.377205 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m12:20:19.377758 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_staging)
[0m12:20:19.382140 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:20:19.382631 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m12:20:19.383232 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_warehouse'
[0m12:20:19.384550 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:20:19.384802 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m12:20:19.386035 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:20:19.387199 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:20:19.387421 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m12:20:19.387617 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:20:19.387810 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m12:20:19.387998 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m12:20:19.388178 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:20:19.388469 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:20:19.388726 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:20:19.494812 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:20:19.495217 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:20:19.495587 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:20:19.495857 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:20:19.496141 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m12:20:19.496458 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m12:20:19.498277 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:20:19.498599 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:20:19.498909 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m12:20:19.515522 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:20:19.516784 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m12:20:19.517080 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:20:19.518212 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m12:20:19.519946 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:20:19.520942 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m12:20:19.526287 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m12:20:19.528129 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m12:20:19.530129 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m12:20:19.758196 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:20:19.760197 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:20:19.761337 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m12:20:19.780698 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:20:19.784357 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m12:20:19.794622 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m12:20:19.806151 [debug] [MainThread]: Using postgres connection "master"
[0m12:20:19.806817 [debug] [MainThread]: On master: BEGIN
[0m12:20:19.807169 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:20:19.916523 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:20:19.917865 [debug] [MainThread]: Using postgres connection "master"
[0m12:20:19.918645 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:20:19.944751 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:20:19.952927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056ef4c0>]}
[0m12:20:19.953716 [debug] [MainThread]: On master: ROLLBACK
[0m12:20:19.963563 [debug] [MainThread]: Using postgres connection "master"
[0m12:20:19.963989 [debug] [MainThread]: On master: BEGIN
[0m12:20:19.986499 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:20:19.986731 [debug] [MainThread]: On master: COMMIT
[0m12:20:19.986957 [debug] [MainThread]: Using postgres connection "master"
[0m12:20:19.987157 [debug] [MainThread]: On master: COMMIT
[0m12:20:19.996348 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:20:19.996593 [debug] [MainThread]: On master: Close
[0m12:20:19.997290 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:20:19.997577 [info ] [MainThread]: 
[0m12:20:20.001039 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m12:20:20.001353 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m12:20:20.001653 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m12:20:20.001890 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m12:20:20.002241 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m12:20:20.002608 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m12:20:20.003009 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m12:20:20.003683 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m12:20:20.004444 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_host_neighbourhod)
[0m12:20:20.004930 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.dm_listing_neighbourhood)
[0m12:20:20.005358 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_property_type)
[0m12:20:20.005765 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.stg_G01)
[0m12:20:20.006045 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m12:20:20.006303 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m12:20:20.006566 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m12:20:20.006805 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m12:20:20.012527 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m12:20:20.014624 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m12:20:20.017376 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m12:20:20.019436 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m12:20:20.020186 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 12:20:20.006989 => 12:20:20.019978
[0m12:20:20.020642 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m12:20:20.021027 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 12:20:20.012773 => 12:20:20.020879
[0m12:20:20.021302 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 12:20:20.014843 => 12:20:20.021189
[0m12:20:20.028104 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 12:20:20.017578 => 12:20:20.027957
[0m12:20:20.043942 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m12:20:20.044195 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m12:20:20.044438 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m12:20:20.044645 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m12:20:20.046867 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m12:20:20.048906 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m12:20:20.049148 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:20:20.058914 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m12:20:20.059287 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m12:20:20.059610 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:20:20.059841 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:20:20.060028 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:20:20.060232 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m12:20:20.060501 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:20:20.060698 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m12:20:20.060900 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:20:20.061083 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m12:20:20.061253 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:20:20.061476 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:20:20.168189 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:20.168554 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:20.168897 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:20:20.169189 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:20:20.169567 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM 
        warehouse.dim_host host
    LEFT JOIN 
        warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
distinct_host_count AS (
    SELECT
        TO_CHAR(h.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        COUNT(DISTINCT h.host_id) AS num_distinct_hosts
    FROM
        host_neighbourhood_lga_transform h
    GROUP BY
        TO_CHAR(h.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
),
estimated_revenue AS (
    SELECT
        TO_CHAR(l.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        SUM((30 - l.availability_30) * l.price) AS total_estimated_revenue
    FROM
        warehouse.fact_listing l
    LEFT JOIN
        host_neighbourhood_lga_transform h ON l.surrogate_key_host = h.surrogate_key_host
    WHERE
        l.has_availability = 't'
    GROUP BY
        TO_CHAR(l.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
)
SELECT
    dhct.month_year,
    dhct.host_neighbourhood_lga,
    dhct.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dhct.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dhct.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM
    distinct_host_count dhct
LEFT JOIN
    estimated_revenue er ON dhct.month_year = er.month_year AND dhct.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY
    dhct.month_year, dhct.host_neighbourhood_lga
  );
  
[0m12:20:20.170189 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type



WITH sorted_listing AS (
    SELECT 
        prop.property_type,
        room.room_type,
        list.accommodates,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
SELECT 
    property_type,
    room_type,
    accommodates,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,



    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:20:20.295788 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:20.297099 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:20:20.298027 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m12:20:20.431363 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:20.432660 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:20:20.433416 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:20:20.465564 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:20:20.478073 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:20:20.478823 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:20:20.489352 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:20.492605 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:20:20.493017 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:20:20.507342 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:20.523490 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:20:20.523824 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:20:20.524106 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:20:20.534459 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:20.541495 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:20:20.541839 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:20:20.553223 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:20:20.554587 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:20:20.049291 => 12:20:20.554413
[0m12:20:20.554981 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:20:20.555852 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057bb970>]}
[0m12:20:20.556450 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.55s]
[0m12:20:20.556962 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:20:20.557304 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m12:20:20.557783 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:20:20.558421 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m12:20:20.558738 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m12:20:20.561446 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:20:20.562360 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 12:20:20.558953 => 12:20:20.562218
[0m12:20:20.562650 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m12:20:20.565637 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:20:20.566117 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:20:20.566369 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m12:20:20.566603 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:20:20.678042 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:20.678792 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:20:20.679443 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:20:20.695107 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:20:20.699486 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:20:20.699936 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:20:20.712131 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:20.715647 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:20:20.716056 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:20:20.725982 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:20.728027 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:20:20.728532 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:20:20.728985 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:20:20.739741 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:20.744838 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:20:20.745306 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:20:20.756667 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:20:20.758312 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 12:20:20.562893 => 12:20:20.758092
[0m12:20:20.758783 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m12:20:20.759811 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10585f340>]}
[0m12:20:20.760563 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.20s]
[0m12:20:20.761251 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m12:20:20.761681 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m12:20:20.762280 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:20:20.763068 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m12:20:20.763480 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m12:20:20.767051 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:20:20.767846 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 12:20:20.763759 => 12:20:20.767683
[0m12:20:20.768182 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m12:20:20.771836 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:20:20.772611 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:20:20.773126 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m12:20:20.773464 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:20:21.167161 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:21.167761 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:20:21.168186 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:20:21.180322 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:20:21.183943 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:20:21.184323 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:20:21.193624 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:21.196304 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:20:21.196652 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:20:21.205577 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:21.207010 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:20:21.207334 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:20:21.207630 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:20:21.217305 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:21.219945 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:20:21.220295 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:20:21.231610 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:20:21.233027 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 12:20:20.768407 => 12:20:21.232836
[0m12:20:21.233425 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m12:20:21.234366 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105716470>]}
[0m12:20:21.235017 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.47s]
[0m12:20:21.235596 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m12:20:21.235994 [debug] [Thread-4 (]: Began running node model.bde.stg_fact
[0m12:20:21.236381 [info ] [Thread-4 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:20:21.237293 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_fact)
[0m12:20:21.237730 [debug] [Thread-4 (]: Began compiling node model.bde.stg_fact
[0m12:20:21.241091 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:20:21.241960 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (compile): 12:20:21.237994 => 12:20:21.241787
[0m12:20:21.242307 [debug] [Thread-4 (]: Began executing node model.bde.stg_fact
[0m12:20:21.245593 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:20:21.246136 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:20:21.246415 [debug] [Thread-4 (]: On model.bde.stg_fact: BEGIN
[0m12:20:21.246685 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:20:21.369778 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:21.371211 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:20:21.371998 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:20:21.388965 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:20:21.399064 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:20:21.399753 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:20:21.410313 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:21.414396 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:20:21.414916 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:20:21.427494 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:21.429649 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:20:21.430141 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:20:21.430595 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:20:21.439930 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:21.443072 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:20:21.443549 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:20:21.455074 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:20:21.456631 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (execute): 12:20:21.242550 => 12:20:21.456441
[0m12:20:21.457036 [debug] [Thread-4 (]: On model.bde.stg_fact: Close
[0m12:20:21.457979 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105888730>]}
[0m12:20:21.458638 [info ] [Thread-4 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.22s]
[0m12:20:21.459261 [debug] [Thread-4 (]: Finished running node model.bde.stg_fact
[0m12:20:21.459715 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m12:20:21.460403 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:20:21.461095 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_host)
[0m12:20:21.461461 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m12:20:21.464925 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:20:21.465750 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 12:20:21.461726 => 12:20:21.465560
[0m12:20:21.466173 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m12:20:21.469576 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:20:21.470093 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:20:21.470364 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m12:20:21.470624 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:20:21.605310 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:21.607134 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:20:21.608040 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:20:21.625965 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:20:21.634086 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:20:21.634816 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:20:21.644604 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:21.648404 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:20:21.648906 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:20:21.658712 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:21.660763 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:20:21.661240 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:20:21.661672 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:20:21.680343 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:21.683556 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:20:21.683996 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:20:21.694738 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:20:21.696330 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 12:20:21.466417 => 12:20:21.696143
[0m12:20:21.696706 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m12:20:21.697703 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10587f970>]}
[0m12:20:21.698325 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.24s]
[0m12:20:21.698885 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m12:20:21.699295 [debug] [Thread-4 (]: Began running node model.bde.stg_property
[0m12:20:21.699906 [info ] [Thread-4 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:20:21.700617 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_property)
[0m12:20:21.700976 [debug] [Thread-4 (]: Began compiling node model.bde.stg_property
[0m12:20:21.703931 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:20:21.704756 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (compile): 12:20:21.701236 => 12:20:21.704602
[0m12:20:21.705039 [debug] [Thread-4 (]: Began executing node model.bde.stg_property
[0m12:20:21.741075 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:20:21.741708 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:20:21.741938 [debug] [Thread-4 (]: On model.bde.stg_property: BEGIN
[0m12:20:21.742134 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:20:21.986595 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:21.988315 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:20:21.989336 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:20:22.004644 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:20:22.012318 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:20:22.012840 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:20:22.024630 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:22.029145 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:20:22.029650 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:20:22.042937 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:22.045038 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:20:22.046097 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:20:22.046569 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:20:22.058793 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:22.061937 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:20:22.062407 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:20:22.073494 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:20:22.075386 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (execute): 12:20:21.705237 => 12:20:22.075154
[0m12:20:22.075877 [debug] [Thread-4 (]: On model.bde.stg_property: Close
[0m12:20:22.077071 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056e3b20>]}
[0m12:20:22.077866 [info ] [Thread-4 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.38s]
[0m12:20:22.078705 [debug] [Thread-4 (]: Finished running node model.bde.stg_property
[0m12:20:22.079236 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m12:20:22.080113 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:20:22.081127 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_room)
[0m12:20:22.081656 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m12:20:22.085373 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:20:22.086390 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 12:20:22.082009 => 12:20:22.086195
[0m12:20:22.086784 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m12:20:22.090706 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:20:22.091367 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:20:22.091692 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m12:20:22.092000 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:20:22.210787 [debug] [Thread-1 (]: SQL status: SELECT 217 in 2.0 seconds
[0m12:20:22.218723 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:20:22.219490 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m12:20:22.229582 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:22.230104 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:22.234135 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:20:22.234597 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:20:22.235013 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m12:20:22.235441 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:20:22.250941 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:22.257077 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:20:22.257488 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:20:22.257886 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:20:22.262518 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:20:22.262878 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:20:22.263208 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:20:22.272785 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:22.275246 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:20:22.275571 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:22.275879 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:20:22.279948 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:20:22.280346 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m12:20:22.289584 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:22.290948 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:20:22.291275 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:20:22.291571 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:20:22.295905 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:22.297195 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:20:20.021451 => 12:20:22.297041
[0m12:20:22.297526 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:20:22.298277 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10572bb50>]}
[0m12:20:22.298740 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 217[0m in 2.29s]
[0m12:20:22.299197 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:20:22.299518 [debug] [Thread-1 (]: Began running node model.bde.stg_suburb
[0m12:20:22.299907 [info ] [Thread-1 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:20:22.300445 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.stg_suburb)
[0m12:20:22.300736 [debug] [Thread-1 (]: Began compiling node model.bde.stg_suburb
[0m12:20:22.302826 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:20:22.303086 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:22.304910 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:20:22.305271 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:20:22.305644 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (compile): 12:20:22.300957 => 12:20:22.305467
[0m12:20:22.306014 [debug] [Thread-1 (]: Began executing node model.bde.stg_suburb
[0m12:20:22.308648 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:20:22.309107 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:20:22.309352 [debug] [Thread-1 (]: On model.bde.stg_suburb: BEGIN
[0m12:20:22.309595 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:20:22.320087 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:20:22.321209 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 12:20:22.087046 => 12:20:22.321075
[0m12:20:22.321476 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m12:20:22.322083 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056950f0>]}
[0m12:20:22.322514 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.24s]
[0m12:20:22.322920 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m12:20:22.323217 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m12:20:22.323623 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:20:22.324083 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.dim_LGA)
[0m12:20:22.324313 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m12:20:22.326412 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:20:22.326952 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 12:20:22.324471 => 12:20:22.326838
[0m12:20:22.327194 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m12:20:22.329889 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:20:22.330363 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:20:22.330592 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m12:20:22.330795 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:20:22.420647 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:22.421115 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:20:22.421516 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:20:22.433727 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:20:22.438362 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:20:22.438742 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:20:22.444708 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:22.445060 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:20:22.445380 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:20:22.451632 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:22.454153 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:20:22.454514 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:20:22.461815 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:20:22.464429 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:20:22.464768 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:22.465178 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:20:22.466786 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:20:22.467262 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:20:22.467572 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:20:22.476111 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:22.478598 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:20:22.478914 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:22.479249 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:20:22.481236 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:20:22.481585 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:20:22.489874 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:22.491301 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:20:22.491571 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:20:22.491822 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:20:22.492949 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:20:22.493931 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (execute): 12:20:22.306193 => 12:20:22.493797
[0m12:20:22.494222 [debug] [Thread-1 (]: On model.bde.stg_suburb: Close
[0m12:20:22.494877 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105696620>]}
[0m12:20:22.495349 [info ] [Thread-1 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.19s]
[0m12:20:22.495804 [debug] [Thread-1 (]: Finished running node model.bde.stg_suburb
[0m12:20:22.496126 [debug] [Thread-1 (]: Began running node model.bde.fact_G01
[0m12:20:22.496579 [info ] [Thread-1 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:20:22.497112 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.fact_G01)
[0m12:20:22.497404 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G01
[0m12:20:22.500037 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:20:22.500690 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (compile): 12:20:22.497603 => 12:20:22.500557
[0m12:20:22.500988 [debug] [Thread-1 (]: Began executing node model.bde.fact_G01
[0m12:20:22.503837 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:20:22.504087 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:22.505826 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:20:22.506114 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:20:22.506505 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:20:22.506736 [debug] [Thread-1 (]: On model.bde.fact_G01: BEGIN
[0m12:20:22.506956 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:20:22.520746 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:22.521782 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 12:20:22.327357 => 12:20:22.521661
[0m12:20:22.522063 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m12:20:22.522648 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10585f310>]}
[0m12:20:22.523042 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.20s]
[0m12:20:22.523458 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m12:20:22.523747 [debug] [Thread-4 (]: Began running node model.bde.fact_G02
[0m12:20:22.524085 [info ] [Thread-4 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:20:22.524548 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G02)
[0m12:20:22.524800 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G02
[0m12:20:22.527063 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:20:22.527557 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (compile): 12:20:22.524970 => 12:20:22.527433
[0m12:20:22.527797 [debug] [Thread-4 (]: Began executing node model.bde.fact_G02
[0m12:20:22.532267 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:20:22.533017 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:20:22.533257 [debug] [Thread-4 (]: On model.bde.fact_G02: BEGIN
[0m12:20:22.533473 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:20:22.630127 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:22.630603 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:20:22.630995 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:20:22.656958 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:20:22.660869 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:20:22.661299 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:20:22.670818 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:22.674141 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:20:22.674616 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:20:22.686956 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:22.688899 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:20:22.689294 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:20:22.689639 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:20:22.699235 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:22.702458 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:20:22.702944 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:20:22.720877 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:22.722711 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (execute): 12:20:22.501183 => 12:20:22.722474
[0m12:20:22.723141 [debug] [Thread-1 (]: On model.bde.fact_G01: Close
[0m12:20:22.724050 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583c6a0>]}
[0m12:20:22.724760 [info ] [Thread-1 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.23s]
[0m12:20:22.725395 [debug] [Thread-1 (]: Finished running node model.bde.fact_G01
[0m12:20:22.725858 [debug] [Thread-1 (]: Began running node model.bde.fact_listing
[0m12:20:22.726420 [info ] [Thread-1 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:20:22.727158 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_listing)
[0m12:20:22.727558 [debug] [Thread-1 (]: Began compiling node model.bde.fact_listing
[0m12:20:22.730937 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:20:22.731754 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (compile): 12:20:22.727825 => 12:20:22.731588
[0m12:20:22.732086 [debug] [Thread-1 (]: Began executing node model.bde.fact_listing
[0m12:20:22.735968 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:20:22.736702 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:20:22.736981 [debug] [Thread-1 (]: On model.bde.fact_listing: BEGIN
[0m12:20:22.737245 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:20:22.737522 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:22.737968 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:20:22.738245 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:20:22.756891 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:20:22.759510 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:20:22.759833 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:20:22.768134 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:22.770348 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:20:22.770653 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:20:22.909874 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:22.914540 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:20:22.915253 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:20:22.915819 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:20:22.925393 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:22.933036 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:20:22.933671 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:20:22.936017 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:22.936476 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:20:22.937007 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:20:22.956665 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:22.958554 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (execute): 12:20:22.527964 => 12:20:22.958356
[0m12:20:22.958971 [debug] [Thread-4 (]: On model.bde.fact_G02: Close
[0m12:20:22.959978 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057569b0>]}
[0m12:20:22.960708 [info ] [Thread-4 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.44s]
[0m12:20:22.961356 [debug] [Thread-4 (]: Finished running node model.bde.fact_G02
[0m12:20:22.961864 [debug] [Thread-4 (]: Began running node model.bde.dim_host
[0m12:20:22.962791 [info ] [Thread-4 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:20:22.963852 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m12:20:22.964286 [debug] [Thread-4 (]: Began compiling node model.bde.dim_host
[0m12:20:22.967519 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:20:22.968530 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (compile): 12:20:22.964574 => 12:20:22.968346
[0m12:20:22.968867 [debug] [Thread-4 (]: Began executing node model.bde.dim_host
[0m12:20:22.973050 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:20:22.973830 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:20:22.974105 [debug] [Thread-4 (]: On model.bde.dim_host: BEGIN
[0m12:20:22.974370 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:20:23.161553 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:23.161942 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:20:23.162236 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    scraped_date,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:20:23.826076 [debug] [Thread-4 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m12:20:23.832905 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:20:23.833505 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:20:24.063337 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m12:20:24.071963 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:20:24.073155 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:20:24.084785 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:24.089811 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:20:24.090446 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:20:24.099857 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:24.102668 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:20:24.103200 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:20:24.103659 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:20:24.120990 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:24.124692 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:20:24.125180 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:20:24.145952 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:24.147291 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:20:20.044895 => 12:20:24.147139
[0m12:20:24.147627 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:20:24.148339 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105755e40>]}
[0m12:20:24.148776 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 4.14s]
[0m12:20:24.149201 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:20:24.149503 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m12:20:24.149898 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:20:24.150435 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m12:20:24.150723 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m12:20:24.153128 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:20:24.153723 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 12:20:24.150911 => 12:20:24.153588
[0m12:20:24.153986 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m12:20:24.158066 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:20:24.158654 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:20:24.158905 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m12:20:24.159144 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:20:24.258730 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:24.259257 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:20:24.259608 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:20:24.775965 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m12:20:24.782268 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:20:24.782933 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:20:24.851516 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 5.0 seconds
[0m12:20:24.859740 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:20:24.860323 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m12:20:24.870481 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:24.874288 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:20:24.874648 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m12:20:24.885254 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:24.888382 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:20:24.888963 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:20:24.889248 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:20:24.926342 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:24.927018 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:24.927557 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 1.0 seconds
[0m12:20:24.932147 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:20:24.935975 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:20:24.937763 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:20:24.938144 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:20:24.938459 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m12:20:24.938803 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:20:24.949249 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:24.949564 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:24.951419 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:20:24.953453 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:20:24.953830 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:20:24.954270 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:20:24.954773 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:20:24.955380 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:20:24.960371 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:24.962029 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:20:20.047077 => 12:20:24.961906
[0m12:20:24.962312 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:20:24.962885 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056fc7f0>]}
[0m12:20:24.963261 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 4.96s]
[0m12:20:24.963574 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:20:24.963805 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m12:20:24.964336 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:20:24.964852 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m12:20:24.965081 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m12:20:24.967095 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:20:24.967495 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:24.970451 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:20:24.970918 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 12:20:24.965229 => 12:20:24.970772
[0m12:20:24.971177 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:20:24.971740 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m12:20:24.974310 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:20:24.974759 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:20:24.974944 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m12:20:24.975114 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:20:24.978884 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:24.980488 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:20:24.980716 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:20:25.014642 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:25.015730 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (execute): 12:20:22.969096 => 12:20:25.015625
[0m12:20:25.015968 [debug] [Thread-4 (]: On model.bde.dim_host: Close
[0m12:20:25.016530 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058e9db0>]}
[0m12:20:25.016868 [info ] [Thread-4 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 2.05s]
[0m12:20:25.017174 [debug] [Thread-4 (]: Finished running node model.bde.dim_host
[0m12:20:25.017396 [debug] [Thread-4 (]: Began running node model.bde.dim_suburb
[0m12:20:25.018086 [info ] [Thread-4 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:20:25.018608 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_host, now model.bde.dim_suburb)
[0m12:20:25.018837 [debug] [Thread-4 (]: Began compiling node model.bde.dim_suburb
[0m12:20:25.020710 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:20:25.021214 [debug] [Thread-4 (]: Timing info for model.bde.dim_suburb (compile): 12:20:25.018986 => 12:20:25.021115
[0m12:20:25.021407 [debug] [Thread-4 (]: Began executing node model.bde.dim_suburb
[0m12:20:25.021758 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:25.024086 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:20:25.025033 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 12:20:24.154162 => 12:20:25.024940
[0m12:20:25.025549 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m12:20:25.026566 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057981c0>]}
[0m12:20:25.026801 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:20:25.027691 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 0.88s]
[0m12:20:25.028271 [debug] [Thread-4 (]: On model.bde.dim_suburb: BEGIN
[0m12:20:25.028748 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m12:20:25.029031 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:20:25.180077 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:25.180480 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:20:25.180709 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:20:25.188677 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:20:25.189018 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:20:25.189236 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:20:25.213252 [debug] [Thread-4 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:20:25.215369 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:20:25.215616 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:20:25.224578 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:25.226437 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:20:25.226671 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:20:25.236027 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:25.237115 [debug] [Thread-4 (]: On model.bde.dim_suburb: COMMIT
[0m12:20:25.237319 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:20:25.237501 [debug] [Thread-4 (]: On model.bde.dim_suburb: COMMIT
[0m12:20:25.261271 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:25.262676 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:20:25.262871 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:20:25.282816 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:25.283773 [debug] [Thread-4 (]: Timing info for model.bde.dim_suburb (execute): 12:20:25.021933 => 12:20:25.283682
[0m12:20:25.283996 [debug] [Thread-4 (]: On model.bde.dim_suburb: Close
[0m12:20:25.284511 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105756860>]}
[0m12:20:25.284836 [info ] [Thread-4 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.27s]
[0m12:20:25.285129 [debug] [Thread-4 (]: Finished running node model.bde.dim_suburb
[0m12:20:25.456211 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:20:25.462655 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:20:25.463148 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:20:25.472219 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:25.477084 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:20:25.477428 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:20:25.486804 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:25.489862 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:20:25.490426 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:20:25.490873 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:20:25.517594 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:25.519291 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:20:25.519520 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:20:25.544530 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:25.547059 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 12:20:24.972177 => 12:20:25.546796
[0m12:20:25.547609 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m12:20:25.548729 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105756020>]}
[0m12:20:25.549436 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.58s]
[0m12:20:25.549912 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m12:20:25.902753 [debug] [Thread-1 (]: SQL status: SELECT 340945 in 3.0 seconds
[0m12:20:25.911818 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:20:25.912511 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:20:25.926963 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:25.931920 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:20:25.932554 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:20:25.942334 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:25.945188 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:20:25.945730 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:20:25.946180 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:20:26.094023 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:20:26.102233 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:20:26.102849 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:20:26.130555 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:26.132230 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (execute): 12:20:22.732321 => 12:20:26.132018
[0m12:20:26.132655 [debug] [Thread-1 (]: On model.bde.fact_listing: Close
[0m12:20:26.133634 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c7e64dd-d660-4c78-a704-1707483e9ad2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058173a0>]}
[0m12:20:26.134362 [info ] [Thread-1 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 3.41s]
[0m12:20:26.135011 [debug] [Thread-1 (]: Finished running node model.bde.fact_listing
[0m12:20:26.136990 [debug] [MainThread]: Using postgres connection "master"
[0m12:20:26.137467 [debug] [MainThread]: On master: BEGIN
[0m12:20:26.137812 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:20:26.504809 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:20:26.506878 [debug] [MainThread]: On master: COMMIT
[0m12:20:26.507905 [debug] [MainThread]: Using postgres connection "master"
[0m12:20:26.508876 [debug] [MainThread]: On master: COMMIT
[0m12:20:26.518377 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:20:26.519786 [debug] [MainThread]: On master: Close
[0m12:20:26.521741 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:20:26.522231 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:20:26.522593 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m12:20:26.522938 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:20:26.523268 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:20:26.523907 [info ] [MainThread]: 
[0m12:20:26.524888 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 7.32 seconds (7.32s).
[0m12:20:26.528529 [debug] [MainThread]: Command end result
[0m12:20:26.538831 [info ] [MainThread]: 
[0m12:20:26.539256 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:20:26.539586 [info ] [MainThread]: 
[0m12:20:26.539912 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m12:20:26.540600 [debug] [MainThread]: Command `dbt run` succeeded at 12:20:26.540515 after 7.45 seconds
[0m12:20:26.541008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d6a500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058d76a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056ef1f0>]}
[0m12:20:26.541395 [debug] [MainThread]: Flushing usage events
[0m12:26:04.131470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bf0190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b4da80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b4d360>]}


============================== 12:26:04.134123 | 6756c9d8-81c0-4548-9f94-dbb02c2ed70b ==============================
[0m12:26:04.134123 [info ] [MainThread]: Running with dbt=1.6.6
[0m12:26:04.134471 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --full-refresh', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:26:04.204797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b4d5d0>]}
[0m12:26:04.212937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f95120>]}
[0m12:26:04.213492 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m12:26:04.223100 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m12:26:04.249387 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:26:04.249815 [debug] [MainThread]: Partial parsing: updated file: bde://models/datamart/dm_listing_neighbourhood.sql
[0m12:26:04.270918 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.median
- models.bde.raw
[0m12:26:04.274041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075089a0>]}
[0m12:26:04.281160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074e6c80>]}
[0m12:26:04.281436 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m12:26:04.281645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074e6e90>]}
[0m12:26:04.282818 [info ] [MainThread]: 
[0m12:26:04.283224 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:26:04.284066 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:26:04.284485 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:26:04.289602 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:26:04.289960 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:26:04.291023 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:26:04.291264 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:26:04.292109 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:26:04.292287 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:26:04.292493 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:04.292647 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:26:04.292797 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:04.293728 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:04.451454 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:26:04.452723 [debug] [ThreadPool]: On list_postgres: Close
[0m12:26:04.577340 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:26:04.578890 [debug] [ThreadPool]: On list_postgres: Close
[0m12:26:04.590991 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:26:04.591900 [debug] [ThreadPool]: On list_postgres: Close
[0m12:26:04.594185 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m12:26:04.594774 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_warehouse)
[0m12:26:04.600680 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:26:04.601244 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m12:26:04.601872 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_staging'
[0m12:26:04.603445 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:26:04.603794 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m12:26:04.605400 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:26:04.607012 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:26:04.607277 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m12:26:04.607513 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:26:04.607748 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m12:26:04.607968 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m12:26:04.608182 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:26:04.608535 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:26:04.608819 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:04.878393 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:26:04.879021 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:26:04.879486 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:26:04.879744 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:26:04.879999 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m12:26:04.880266 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m12:26:04.881242 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:26:04.881512 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:26:04.881738 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m12:26:04.895821 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:26:04.897012 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m12:26:04.898566 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:26:04.899399 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m12:26:04.899629 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:26:04.900616 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m12:26:04.906473 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m12:26:04.908675 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m12:26:04.910365 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m12:26:05.087821 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:26:05.088544 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:26:05.089188 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m12:26:05.102982 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:26:05.104401 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m12:26:05.113045 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m12:26:05.118406 [debug] [MainThread]: Using postgres connection "master"
[0m12:26:05.118733 [debug] [MainThread]: On master: BEGIN
[0m12:26:05.118972 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:26:05.224272 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:26:05.224679 [debug] [MainThread]: Using postgres connection "master"
[0m12:26:05.224972 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:26:05.252074 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:26:05.253947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074e3e50>]}
[0m12:26:05.254340 [debug] [MainThread]: On master: ROLLBACK
[0m12:26:05.263844 [debug] [MainThread]: Using postgres connection "master"
[0m12:26:05.264107 [debug] [MainThread]: On master: BEGIN
[0m12:26:05.285643 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:26:05.286012 [debug] [MainThread]: On master: COMMIT
[0m12:26:05.286241 [debug] [MainThread]: Using postgres connection "master"
[0m12:26:05.286437 [debug] [MainThread]: On master: COMMIT
[0m12:26:05.298235 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:26:05.298455 [debug] [MainThread]: On master: Close
[0m12:26:05.299037 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:26:05.299287 [info ] [MainThread]: 
[0m12:26:05.301919 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m12:26:05.302303 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m12:26:05.302702 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m12:26:05.303027 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m12:26:05.303433 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m12:26:05.303827 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m12:26:05.304210 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m12:26:05.304523 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m12:26:05.305001 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_host_neighbourhod)
[0m12:26:05.305413 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.dm_listing_neighbourhood)
[0m12:26:05.305800 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_property_type)
[0m12:26:05.306181 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.stg_G01)
[0m12:26:05.306425 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m12:26:05.306650 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m12:26:05.306864 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m12:26:05.307080 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m12:26:05.312343 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m12:26:05.314186 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m12:26:05.316910 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m12:26:05.318925 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m12:26:05.320650 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 12:26:05.314369 => 12:26:05.320507
[0m12:26:05.321099 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 12:26:05.307243 => 12:26:05.320864
[0m12:26:05.321396 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m12:26:05.321648 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 12:26:05.312562 => 12:26:05.321547
[0m12:26:05.321899 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 12:26:05.317112 => 12:26:05.321778
[0m12:26:05.322188 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m12:26:05.343902 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m12:26:05.344232 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m12:26:05.344455 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m12:26:05.346570 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m12:26:05.348747 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m12:26:05.358087 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m12:26:05.358339 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:26:05.358754 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:26:05.359031 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m12:26:05.359230 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:26:05.359420 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m12:26:05.359592 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:26:05.359764 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:26:05.359936 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m12:26:05.360098 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:26:05.360260 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m12:26:05.360508 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:26:05.360847 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:26:05.461063 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:05.461495 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:26:05.461880 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type



WITH sorted_listing AS (
    SELECT 
        prop.property_type,
        room.room_type,
        list.accommodates,
        DATE_TRUNC('month', list.scraped_date) AS month_year,
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
SELECT 
    property_type,
    room_type,
    accommodates,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,



    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:26:05.462258 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:05.462537 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:26:05.462801 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM 
        warehouse.dim_host host
    LEFT JOIN 
        warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
distinct_host_count AS (
    SELECT
        TO_CHAR(h.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        COUNT(DISTINCT h.host_id) AS num_distinct_hosts
    FROM
        host_neighbourhood_lga_transform h
    GROUP BY
        TO_CHAR(h.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
),
estimated_revenue AS (
    SELECT
        TO_CHAR(l.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        SUM((30 - l.availability_30) * l.price) AS total_estimated_revenue
    FROM
        warehouse.fact_listing l
    LEFT JOIN
        host_neighbourhood_lga_transform h ON l.surrogate_key_host = h.surrogate_key_host
    WHERE
        l.has_availability = 't'
    GROUP BY
        TO_CHAR(l.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
)
SELECT
    dhct.month_year,
    dhct.host_neighbourhood_lga,
    dhct.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dhct.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dhct.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM
    distinct_host_count dhct
LEFT JOIN
    estimated_revenue er ON dhct.month_year = er.month_year AND dhct.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY
    dhct.month_year, dhct.host_neighbourhood_lga
  );
  
[0m12:26:05.486373 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:05.486701 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:26:05.487083 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:26:05.488578 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:05.488803 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:26:05.489195 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,     
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m12:26:05.523386 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:26:05.528506 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:26:05.528807 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:26:05.539428 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:05.541255 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:26:05.541505 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:26:05.555056 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:05.565025 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:26:05.565288 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:26:05.565498 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:26:05.577856 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:05.582616 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:26:05.582872 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:26:05.595799 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:26:05.596828 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:26:05.348946 => 12:26:05.596705
[0m12:26:05.597071 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:26:05.597682 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107672ad0>]}
[0m12:26:05.598086 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.29s]
[0m12:26:05.598477 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:26:05.598744 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m12:26:05.599023 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:26:05.599633 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m12:26:05.599964 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m12:26:05.602171 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:26:05.603742 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 12:26:05.600147 => 12:26:05.603592
[0m12:26:05.604012 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m12:26:05.606723 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:26:05.607238 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:26:05.607459 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m12:26:05.607665 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:26:05.711591 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:05.712105 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:26:05.712422 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:26:05.727278 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:26:05.729893 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:26:05.730175 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:26:05.739267 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:05.741145 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:26:05.741416 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:26:05.750533 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:05.752122 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:26:05.752456 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:26:05.752727 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:26:05.762890 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:05.764924 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:26:05.765234 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:26:05.776003 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:26:05.777060 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 12:26:05.604175 => 12:26:05.776931
[0m12:26:05.777360 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m12:26:05.778038 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10771e590>]}
[0m12:26:05.778474 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.18s]
[0m12:26:05.778888 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m12:26:05.779186 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m12:26:05.779491 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:26:05.780100 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m12:26:05.780435 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m12:26:05.784098 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:26:05.785088 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 12:26:05.780641 => 12:26:05.784974
[0m12:26:05.785328 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m12:26:05.787911 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:26:05.788346 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:26:05.788581 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m12:26:05.788794 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:26:05.896469 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:05.897073 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:26:05.897545 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:26:05.910426 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:26:05.914231 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:26:05.914596 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:26:05.924572 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:05.927645 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:26:05.928051 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:26:05.937333 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:05.939079 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:26:05.939481 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:26:05.939857 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:26:05.950522 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:05.953360 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:26:05.953796 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:26:05.964118 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:26:05.965511 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 12:26:05.785486 => 12:26:05.965325
[0m12:26:05.965904 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m12:26:05.966858 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076ea830>]}
[0m12:26:05.967555 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.19s]
[0m12:26:05.968253 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m12:26:05.968778 [debug] [Thread-4 (]: Began running node model.bde.stg_fact
[0m12:26:05.969363 [info ] [Thread-4 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:26:05.970162 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_fact)
[0m12:26:05.970509 [debug] [Thread-4 (]: Began compiling node model.bde.stg_fact
[0m12:26:05.973880 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:26:05.975542 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (compile): 12:26:05.970753 => 12:26:05.975369
[0m12:26:05.975896 [debug] [Thread-4 (]: Began executing node model.bde.stg_fact
[0m12:26:05.979272 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:26:05.979807 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:26:05.980088 [debug] [Thread-4 (]: On model.bde.stg_fact: BEGIN
[0m12:26:05.980369 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:26:06.094716 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:06.095510 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:26:06.096113 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:26:06.112827 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:26:06.117436 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:26:06.117869 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:26:06.128005 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:06.132678 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:26:06.133094 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:26:06.142871 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:06.144716 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:26:06.145123 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:26:06.145550 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:26:06.156452 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:06.195279 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:26:06.195641 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:26:06.208043 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:26:06.209058 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (execute): 12:26:05.976126 => 12:26:06.208944
[0m12:26:06.209326 [debug] [Thread-4 (]: On model.bde.stg_fact: Close
[0m12:26:06.209938 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f5b310>]}
[0m12:26:06.210335 [info ] [Thread-4 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.24s]
[0m12:26:06.210725 [debug] [Thread-4 (]: Finished running node model.bde.stg_fact
[0m12:26:06.211005 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m12:26:06.211412 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:26:06.211910 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_host)
[0m12:26:06.212226 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m12:26:06.214465 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:26:06.216212 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 12:26:06.212413 => 12:26:06.216110
[0m12:26:06.216440 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m12:26:06.218913 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:26:06.219368 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:26:06.219587 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m12:26:06.219790 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:26:06.634057 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:06.634798 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:26:06.635279 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:26:06.657625 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:26:06.660639 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:26:06.660995 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:26:06.672314 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:06.674886 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:26:06.675237 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:26:06.688274 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:06.689644 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:26:06.689944 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:26:06.690228 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:26:06.916480 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:06.923695 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:26:06.924426 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:26:06.946982 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:26:06.950560 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 12:26:06.216602 => 12:26:06.950250
[0m12:26:06.951319 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m12:26:06.953369 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075f5990>]}
[0m12:26:06.954425 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.74s]
[0m12:26:06.955270 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m12:26:06.955871 [debug] [Thread-4 (]: Began running node model.bde.stg_property
[0m12:26:06.956698 [info ] [Thread-4 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:26:06.957549 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_property)
[0m12:26:06.957986 [debug] [Thread-4 (]: Began compiling node model.bde.stg_property
[0m12:26:06.961668 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:26:06.963665 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (compile): 12:26:06.958270 => 12:26:06.963469
[0m12:26:06.964067 [debug] [Thread-4 (]: Began executing node model.bde.stg_property
[0m12:26:06.967937 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:26:06.968606 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:26:06.968939 [debug] [Thread-4 (]: On model.bde.stg_property: BEGIN
[0m12:26:06.969240 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:26:07.076506 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:07.077348 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:26:07.077896 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:26:07.095218 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:26:07.102090 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:26:07.102649 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:26:07.115777 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:07.118734 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:26:07.119166 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:26:07.128421 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:07.130089 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:26:07.130491 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:26:07.130854 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:26:07.143410 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:07.146542 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:26:07.146954 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:26:07.157967 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:26:07.159913 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (execute): 12:26:06.964325 => 12:26:07.159679
[0m12:26:07.160353 [debug] [Thread-4 (]: On model.bde.stg_property: Close
[0m12:26:07.161335 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076d9d80>]}
[0m12:26:07.162023 [info ] [Thread-4 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.20s]
[0m12:26:07.162651 [debug] [Thread-4 (]: Finished running node model.bde.stg_property
[0m12:26:07.163129 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m12:26:07.163889 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:26:07.164781 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_room)
[0m12:26:07.165677 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m12:26:07.169270 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:26:07.170551 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 12:26:07.166019 => 12:26:07.170289
[0m12:26:07.171031 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m12:26:07.175172 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:26:07.176306 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:26:07.176729 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m12:26:07.177014 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:26:07.209957 [debug] [Thread-1 (]: SQL status: SELECT 217 in 2.0 seconds
[0m12:26:07.213497 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:26:07.213948 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m12:26:07.227193 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:07.229886 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:26:07.230190 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m12:26:07.239435 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:07.244220 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:26:07.244679 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:26:07.245002 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:26:07.255929 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:07.259909 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:26:07.260269 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m12:26:07.281419 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:26:07.282996 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:26:05.344611 => 12:26:07.282812
[0m12:26:07.283388 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:26:07.284187 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075fddb0>]}
[0m12:26:07.284795 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 217[0m in 1.98s]
[0m12:26:07.285315 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:26:07.285675 [debug] [Thread-1 (]: Began running node model.bde.stg_suburb
[0m12:26:07.286122 [info ] [Thread-1 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:26:07.286659 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.stg_suburb)
[0m12:26:07.286953 [debug] [Thread-1 (]: Began compiling node model.bde.stg_suburb
[0m12:26:07.290857 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:26:07.291499 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (compile): 12:26:07.287140 => 12:26:07.291367
[0m12:26:07.291770 [debug] [Thread-1 (]: Began executing node model.bde.stg_suburb
[0m12:26:07.294730 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:26:07.295179 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:26:07.295415 [debug] [Thread-1 (]: On model.bde.stg_suburb: BEGIN
[0m12:26:07.295630 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:26:07.297293 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:07.297600 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:26:07.297864 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:26:07.310109 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:26:07.312830 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:26:07.313102 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:26:07.326360 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:07.328373 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:26:07.328644 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:26:07.340241 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:07.341404 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:26:07.341680 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:26:07.341907 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:26:07.352839 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:07.354709 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:26:07.354970 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:26:07.365682 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:26:07.366678 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 12:26:07.171286 => 12:26:07.366541
[0m12:26:07.366959 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m12:26:07.367598 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076d2f20>]}
[0m12:26:07.368042 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.20s]
[0m12:26:07.368470 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m12:26:07.368780 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m12:26:07.369230 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:26:07.369728 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.dim_LGA)
[0m12:26:07.370006 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m12:26:07.372444 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:26:07.373536 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 12:26:07.370199 => 12:26:07.373418
[0m12:26:07.373799 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m12:26:07.376435 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:26:07.376876 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:26:07.377110 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m12:26:07.377329 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:26:07.421486 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:07.422017 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:26:07.422341 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:26:07.433883 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:26:07.436867 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:26:07.437153 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:26:07.448104 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:07.451793 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:26:07.452084 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:26:07.461115 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:07.462569 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:26:07.462923 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:26:07.463176 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:26:07.477716 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:07.480016 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:26:07.480287 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:07.480567 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:26:07.480827 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:26:07.481172 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:26:07.492118 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:26:07.493437 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (execute): 12:26:07.291945 => 12:26:07.493288
[0m12:26:07.493747 [debug] [Thread-1 (]: On model.bde.stg_suburb: Close
[0m12:26:07.494541 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107518790>]}
[0m12:26:07.495052 [info ] [Thread-1 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.21s]
[0m12:26:07.495600 [debug] [Thread-1 (]: Finished running node model.bde.stg_suburb
[0m12:26:07.496045 [debug] [Thread-1 (]: Began running node model.bde.fact_G01
[0m12:26:07.496587 [info ] [Thread-1 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:26:07.497212 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.fact_G01)
[0m12:26:07.497543 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G01
[0m12:26:07.500434 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:26:07.502270 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (compile): 12:26:07.497800 => 12:26:07.502115
[0m12:26:07.502567 [debug] [Thread-1 (]: Began executing node model.bde.fact_G01
[0m12:26:07.502843 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:26:07.505914 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:26:07.508228 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:26:07.508669 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:26:07.509200 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:26:07.509476 [debug] [Thread-1 (]: On model.bde.fact_G01: BEGIN
[0m12:26:07.509701 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:26:07.523596 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:07.526205 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:26:07.526471 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:26:07.537558 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:07.539007 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:26:07.539261 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:26:07.539484 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:26:07.557666 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:07.559742 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:26:07.560017 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:26:07.574273 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:26:07.575426 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 12:26:07.373967 => 12:26:07.575284
[0m12:26:07.575725 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m12:26:07.576441 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076e22f0>]}
[0m12:26:07.576942 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.21s]
[0m12:26:07.577376 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m12:26:07.577697 [debug] [Thread-4 (]: Began running node model.bde.fact_G02
[0m12:26:07.578111 [info ] [Thread-4 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:26:07.578673 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G02)
[0m12:26:07.578971 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G02
[0m12:26:07.581745 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:26:07.582324 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (compile): 12:26:07.579155 => 12:26:07.582195
[0m12:26:07.582581 [debug] [Thread-4 (]: Began executing node model.bde.fact_G02
[0m12:26:07.586825 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:26:07.587307 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:26:07.587544 [debug] [Thread-4 (]: On model.bde.fact_G02: BEGIN
[0m12:26:07.587759 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:26:07.705619 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:07.706078 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:26:07.706305 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:26:07.862699 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:07.863117 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:26:07.863363 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:26:07.889199 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:26:07.891728 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:26:07.891994 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:26:07.902075 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:07.904112 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:26:07.904387 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:26:07.917361 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:07.918714 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:26:07.918991 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:26:07.919244 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:26:07.933122 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:07.935093 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:26:07.935393 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:26:07.939563 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:26:07.942191 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:26:07.942521 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:26:07.964735 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:26:07.965795 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (execute): 12:26:07.503080 => 12:26:07.965649
[0m12:26:07.966074 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:07.966387 [debug] [Thread-1 (]: On model.bde.fact_G01: Close
[0m12:26:07.968529 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:26:07.968894 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:26:07.969479 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10750aa70>]}
[0m12:26:07.970018 [info ] [Thread-1 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.47s]
[0m12:26:07.970482 [debug] [Thread-1 (]: Finished running node model.bde.fact_G01
[0m12:26:07.970805 [debug] [Thread-1 (]: Began running node model.bde.fact_listing
[0m12:26:07.971198 [info ] [Thread-1 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:26:07.971708 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_listing)
[0m12:26:07.971991 [debug] [Thread-1 (]: Began compiling node model.bde.fact_listing
[0m12:26:07.974299 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:26:07.975695 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (compile): 12:26:07.972188 => 12:26:07.975565
[0m12:26:07.975953 [debug] [Thread-1 (]: Began executing node model.bde.fact_listing
[0m12:26:07.978796 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:26:07.979277 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:26:07.979519 [debug] [Thread-1 (]: On model.bde.fact_listing: BEGIN
[0m12:26:07.979747 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:26:07.981193 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:07.982405 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:26:07.982662 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:26:07.982884 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:26:07.992708 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:07.995773 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:26:07.996048 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:26:08.011573 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:26:08.012601 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (execute): 12:26:07.582749 => 12:26:08.012477
[0m12:26:08.012872 [debug] [Thread-4 (]: On model.bde.fact_G02: Close
[0m12:26:08.013475 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076e22f0>]}
[0m12:26:08.013901 [info ] [Thread-4 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.43s]
[0m12:26:08.014305 [debug] [Thread-4 (]: Finished running node model.bde.fact_G02
[0m12:26:08.014588 [debug] [Thread-4 (]: Began running node model.bde.dim_host
[0m12:26:08.014933 [info ] [Thread-4 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:26:08.015397 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m12:26:08.015653 [debug] [Thread-4 (]: Began compiling node model.bde.dim_host
[0m12:26:08.017867 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:26:08.018595 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (compile): 12:26:08.015828 => 12:26:08.018479
[0m12:26:08.018830 [debug] [Thread-4 (]: Began executing node model.bde.dim_host
[0m12:26:08.021591 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:26:08.022235 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:26:08.022472 [debug] [Thread-4 (]: On model.bde.dim_host: BEGIN
[0m12:26:08.022689 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:26:08.114005 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:08.114414 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:26:08.114810 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:26:08.148120 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:08.148533 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:26:08.148929 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    scraped_date,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:26:08.790307 [debug] [Thread-4 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m12:26:08.798626 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:26:08.799400 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:26:09.410521 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m12:26:09.418874 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:26:09.419740 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:26:09.430231 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:09.433919 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:26:09.434431 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:26:09.446199 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:09.448484 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:26:09.448992 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:26:09.449440 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:26:09.469643 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:09.475448 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:26:09.476005 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:26:09.497535 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:26:09.500741 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:26:05.346824 => 12:26:09.500467
[0m12:26:09.501364 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:26:09.502898 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c803730>]}
[0m12:26:09.503847 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 4.20s]
[0m12:26:09.504637 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:26:09.505218 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m12:26:09.505981 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:26:09.506953 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m12:26:09.507385 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m12:26:09.511153 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:26:09.513008 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 12:26:09.507668 => 12:26:09.512840
[0m12:26:09.513353 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m12:26:09.518693 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:26:09.519429 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:26:09.519754 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m12:26:09.520065 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:26:09.625921 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:09.626551 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:26:09.627077 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:26:10.124968 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:26:10.134113 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:26:10.134955 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:26:10.470876 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 5.0 seconds
[0m12:26:10.473269 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:26:10.473544 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m12:26:10.483461 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:10.485349 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:26:10.485615 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m12:26:10.500470 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:10.501599 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:26:10.501835 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:26:10.502051 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:26:10.525259 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:10.527079 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:26:10.527359 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 2.0 seconds
[0m12:26:10.527660 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:10.527913 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m12:26:10.529897 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:26:10.531756 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:26:10.532123 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:26:10.532426 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:26:10.544290 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:10.544543 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:10.545731 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:26:10.546884 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:26:10.547147 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:26:10.547390 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:26:10.547623 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:26:10.547865 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:26:10.554096 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:26:10.555218 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:26:05.322350 => 12:26:10.555093
[0m12:26:10.555504 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:26:10.556237 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074e5720>]}
[0m12:26:10.556663 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 5.25s]
[0m12:26:10.557046 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:26:10.557314 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m12:26:10.557727 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:26:10.558312 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m12:26:10.558586 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m12:26:10.560931 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:26:10.562313 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 12:26:10.558766 => 12:26:10.562178
[0m12:26:10.562543 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:10.562858 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m12:26:10.563078 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:10.564720 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:26:10.568370 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:26:10.569862 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:26:10.570119 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:26:10.570480 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:26:10.570954 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:26:10.571192 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m12:26:10.571416 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:26:10.603119 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:26:10.603430 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:26:10.604573 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (execute): 12:26:08.018995 => 12:26:10.604444
[0m12:26:10.605421 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 12:26:09.513586 => 12:26:10.605318
[0m12:26:10.605676 [debug] [Thread-4 (]: On model.bde.dim_host: Close
[0m12:26:10.605902 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m12:26:10.606505 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c83ba00>]}
[0m12:26:10.606927 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076af130>]}
[0m12:26:10.607326 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 1.10s]
[0m12:26:10.607701 [info ] [Thread-4 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 2.59s]
[0m12:26:10.608092 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m12:26:10.608398 [debug] [Thread-4 (]: Finished running node model.bde.dim_host
[0m12:26:10.608664 [debug] [Thread-2 (]: Began running node model.bde.dim_suburb
[0m12:26:10.609057 [info ] [Thread-2 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:26:10.609464 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dim_property, now model.bde.dim_suburb)
[0m12:26:10.609684 [debug] [Thread-2 (]: Began compiling node model.bde.dim_suburb
[0m12:26:10.611716 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:26:10.612334 [debug] [Thread-2 (]: Timing info for model.bde.dim_suburb (compile): 12:26:10.609834 => 12:26:10.612228
[0m12:26:10.612554 [debug] [Thread-2 (]: Began executing node model.bde.dim_suburb
[0m12:26:10.614937 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:26:10.615347 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:26:10.615553 [debug] [Thread-2 (]: On model.bde.dim_suburb: BEGIN
[0m12:26:10.615750 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:26:10.687900 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:10.688325 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:26:10.688630 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:26:10.715310 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:26:10.715594 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:26:10.715877 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:26:10.736259 [debug] [Thread-2 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:26:10.739113 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:26:10.739439 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:26:10.758728 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:10.761178 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:26:10.761485 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:26:10.775458 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:10.777281 [debug] [Thread-2 (]: On model.bde.dim_suburb: COMMIT
[0m12:26:10.777638 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:26:10.777952 [debug] [Thread-2 (]: On model.bde.dim_suburb: COMMIT
[0m12:26:10.807961 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:10.810537 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:26:10.810935 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:26:10.830958 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:26:10.832323 [debug] [Thread-2 (]: Timing info for model.bde.dim_suburb (execute): 12:26:10.612713 => 12:26:10.832161
[0m12:26:10.832696 [debug] [Thread-2 (]: On model.bde.dim_suburb: Close
[0m12:26:10.833567 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10766ff40>]}
[0m12:26:10.834168 [info ] [Thread-2 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.22s]
[0m12:26:10.834711 [debug] [Thread-2 (]: Finished running node model.bde.dim_suburb
[0m12:26:10.958683 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:26:10.966884 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:26:10.967663 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:26:10.983028 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:10.987116 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:26:10.987633 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:26:10.997438 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:11.001779 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:26:11.002225 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:26:11.002606 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:26:11.038038 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:11.041202 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:26:11.041636 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:26:11.063299 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:26:11.064884 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 12:26:10.564931 => 12:26:11.064710
[0m12:26:11.065278 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m12:26:11.066209 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075183d0>]}
[0m12:26:11.066806 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.51s]
[0m12:26:11.067302 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m12:26:11.192052 [debug] [Thread-1 (]: SQL status: SELECT 340945 in 3.0 seconds
[0m12:26:11.200263 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:26:11.200916 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:26:11.211314 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:11.215339 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:26:11.215871 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:26:11.225400 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:26:11.227723 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:26:11.228218 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:26:11.228658 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:26:11.247318 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:26:11.252934 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:26:11.253506 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:26:11.283180 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:26:11.286486 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (execute): 12:26:07.976156 => 12:26:11.286217
[0m12:26:11.287057 [debug] [Thread-1 (]: On model.bde.fact_listing: Close
[0m12:26:11.288305 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6756c9d8-81c0-4548-9f94-dbb02c2ed70b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107631420>]}
[0m12:26:11.289188 [info ] [Thread-1 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 3.32s]
[0m12:26:11.289953 [debug] [Thread-1 (]: Finished running node model.bde.fact_listing
[0m12:26:11.292052 [debug] [MainThread]: Using postgres connection "master"
[0m12:26:11.292437 [debug] [MainThread]: On master: BEGIN
[0m12:26:11.292756 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:26:11.389977 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:26:11.390647 [debug] [MainThread]: On master: COMMIT
[0m12:26:11.391086 [debug] [MainThread]: Using postgres connection "master"
[0m12:26:11.391487 [debug] [MainThread]: On master: COMMIT
[0m12:26:11.401170 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:26:11.402449 [debug] [MainThread]: On master: Close
[0m12:26:11.404143 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:26:11.404680 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:26:11.405037 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:26:11.405384 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:26:11.405736 [debug] [MainThread]: Connection 'model.bde.dim_host' was properly closed.
[0m12:26:11.406272 [info ] [MainThread]: 
[0m12:26:11.406739 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 7.12 seconds (7.12s).
[0m12:26:11.410284 [debug] [MainThread]: Command end result
[0m12:26:11.421338 [info ] [MainThread]: 
[0m12:26:11.421819 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:26:11.422151 [info ] [MainThread]: 
[0m12:26:11.422460 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m12:26:11.423063 [debug] [MainThread]: Command `dbt run` succeeded at 12:26:11.422979 after 7.31 seconds
[0m12:26:11.423441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bf0190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075e3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10759f760>]}
[0m12:26:11.423809 [debug] [MainThread]: Flushing usage events
[0m12:28:03.422834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e61750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11194dae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11194d3c0>]}


============================== 12:28:03.425275 | 6df98b0c-9118-4346-a086-363d3704681e ==============================
[0m12:28:03.425275 [info ] [MainThread]: Running with dbt=1.6.6
[0m12:28:03.425575 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m12:28:03.480503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11194d630>]}
[0m12:28:03.488124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d01180>]}
[0m12:28:03.488486 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m12:28:03.497798 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m12:28:03.526788 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:28:03.527232 [debug] [MainThread]: Partial parsing: updated file: bde://models/datamart/dm_property_type.sql
[0m12:28:03.548793 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.raw
- models.bde.median
[0m12:28:03.551781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11230cc40>]}
[0m12:28:03.558489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112126d10>]}
[0m12:28:03.558724 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m12:28:03.558903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112126ef0>]}
[0m12:28:03.560044 [info ] [MainThread]: 
[0m12:28:03.560406 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:28:03.561255 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:28:03.561679 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:28:03.566449 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:28:03.566786 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:28:03.567737 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:28:03.567925 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:28:03.568753 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:28:03.568912 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:28:03.569108 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:28:03.569256 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:28:03.569388 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:28:03.570337 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:28:03.716748 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:28:03.717996 [debug] [ThreadPool]: On list_postgres: Close
[0m12:28:03.718238 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:28:03.718473 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:28:03.719325 [debug] [ThreadPool]: On list_postgres: Close
[0m12:28:03.720339 [debug] [ThreadPool]: On list_postgres: Close
[0m12:28:03.722299 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_warehouse)
[0m12:28:03.722806 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m12:28:03.723258 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_staging)
[0m12:28:03.727574 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:28:03.728022 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_datamart'
[0m12:28:03.729257 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:28:03.730352 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:28:03.730561 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m12:28:03.731651 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:28:03.731855 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m12:28:03.732035 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m12:28:03.732212 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:28:03.732394 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m12:28:03.732561 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:28:03.732739 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:28:03.733055 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:28:03.835163 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:28:03.835712 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:28:03.835999 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m12:28:03.839317 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:28:03.839605 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:28:03.839861 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m12:28:03.840980 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:28:03.841204 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:28:03.841447 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m12:28:03.849997 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:28:03.850238 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:28:03.850472 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m12:28:03.851368 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:28:03.852387 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m12:28:03.855384 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:28:03.856317 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m12:28:03.856560 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:28:03.857432 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m12:28:03.861298 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m12:28:03.865159 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:28:03.865390 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m12:28:03.866325 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m12:28:03.866562 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m12:28:03.877848 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m12:28:03.882908 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:03.883198 [debug] [MainThread]: On master: BEGIN
[0m12:28:03.883413 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:28:03.983705 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:28:03.984154 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:03.984484 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:28:04.010411 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:28:04.012471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11230c8b0>]}
[0m12:28:04.012851 [debug] [MainThread]: On master: ROLLBACK
[0m12:28:04.021715 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:04.021993 [debug] [MainThread]: On master: BEGIN
[0m12:28:04.045199 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:28:04.045505 [debug] [MainThread]: On master: COMMIT
[0m12:28:04.045723 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:04.045916 [debug] [MainThread]: On master: COMMIT
[0m12:28:04.055294 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:28:04.055576 [debug] [MainThread]: On master: Close
[0m12:28:04.056240 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:28:04.056501 [info ] [MainThread]: 
[0m12:28:04.059620 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m12:28:04.059909 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m12:28:04.060202 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m12:28:04.060454 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m12:28:04.060789 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m12:28:04.061144 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m12:28:04.061476 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m12:28:04.061784 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m12:28:04.062257 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.dm_host_neighbourhod)
[0m12:28:04.062667 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_listing_neighbourhood)
[0m12:28:04.063053 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.dm_property_type)
[0m12:28:04.063431 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.stg_G01)
[0m12:28:04.063675 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m12:28:04.063901 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m12:28:04.064119 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m12:28:04.064332 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m12:28:04.069941 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m12:28:04.072091 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m12:28:04.075093 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m12:28:04.077119 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m12:28:04.079769 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 12:28:04.072349 => 12:28:04.079498
[0m12:28:04.080191 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 12:28:04.064504 => 12:28:04.080041
[0m12:28:04.080516 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m12:28:04.080781 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 12:28:04.070320 => 12:28:04.080669
[0m12:28:04.081023 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 12:28:04.075315 => 12:28:04.080919
[0m12:28:04.081264 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m12:28:04.103070 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m12:28:04.103375 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m12:28:04.103607 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m12:28:04.105780 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m12:28:04.107927 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m12:28:04.117454 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m12:28:04.117836 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:28:04.118335 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m12:28:04.118548 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:28:04.118748 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:28:04.118979 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:28:04.119197 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m12:28:04.119385 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:28:04.119569 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m12:28:04.119844 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:28:04.120024 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m12:28:04.120205 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:28:04.120442 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:28:04.223532 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:04.223962 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:28:04.224411 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:28:04.227238 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:04.227583 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:28:04.227969 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM 
        warehouse.dim_host host
    LEFT JOIN 
        warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
distinct_host_count AS (
    SELECT
        TO_CHAR(h.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        COUNT(DISTINCT h.host_id) AS num_distinct_hosts
    FROM
        host_neighbourhood_lga_transform h
    GROUP BY
        TO_CHAR(h.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
),
estimated_revenue AS (
    SELECT
        TO_CHAR(l.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        SUM((30 - l.availability_30) * l.price) AS total_estimated_revenue
    FROM
        warehouse.fact_listing l
    LEFT JOIN
        host_neighbourhood_lga_transform h ON l.surrogate_key_host = h.surrogate_key_host
    WHERE
        l.has_availability = 't'
    GROUP BY
        TO_CHAR(l.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
)
SELECT
    dhct.month_year,
    dhct.host_neighbourhood_lga,
    dhct.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dhct.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dhct.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM
    distinct_host_count dhct
LEFT JOIN
    estimated_revenue er ON dhct.month_year = er.month_year AND dhct.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY
    dhct.month_year, dhct.host_neighbourhood_lga
  );
  
[0m12:28:04.229047 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:04.229330 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:28:04.229803 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,     
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m12:28:04.248106 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:04.254600 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:28:04.254925 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:28:04.267743 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:04.269877 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:28:04.270142 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:28:04.280380 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:04.291302 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:28:04.291590 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:28:04.291810 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:28:04.302785 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:04.307942 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:28:04.308213 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:28:04.308845 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:04.309074 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:28:04.309494 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type

-- Set the configuration for the materialized view



-- Create a Common Table Expression (CTE) called sorted_listing
-- This CTE retrieves data from multiple tables and calculates various metrics
-- It includes property_type, room_type, accommodates, and more.


WITH sorted_listing AS (
    SELECT 
        prop.property_type,-- Property type
        room.room_type,-- Room type
        list.accommodates,-- Accommodates
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year, -- Truncate the date to the month
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id, -- Host ID
        host.host_is_superhost,-- Host is superhost flag
        review_scores_rating,-- Review scores rating
        availability_30-- Availability for the next 30 days
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
-- Select the aggregated metrics for the property_type, room_type, accommodates, and month_year
SELECT 
    property_type,-- Property type
    room_type,-- Room type
    accommodates,-- Number of accommodates
    month_year,-- Truncated month and year
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,-- Calculate the minimum price for active listings
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,-- Calculate the maximum price for active listings
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing, -- Calculate the median price for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts, -- Count the number of distinct hosts
     -- Calculate the superhost rate
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
     -- Calculate the average review scores rating for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


     -- Calculate the percentage change for active listing
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
ROUND(
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:28:04.320251 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:04.321262 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:28:04.108124 => 12:28:04.321141
[0m12:28:04.321515 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:28:04.322159 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123e2b30>]}
[0m12:28:04.322553 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.26s]
[0m12:28:04.322916 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:28:04.323174 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m12:28:04.323523 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:28:04.323987 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m12:28:04.324228 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m12:28:04.326373 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:28:04.327802 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 12:28:04.324395 => 12:28:04.327704
[0m12:28:04.328008 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m12:28:04.330419 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:28:04.330679 [debug] [Thread-3 (]: Postgres adapter: Postgres error: syntax error at or near "AS"
LINE 96:     ) AS avg_estimated_revenue_per_active_listing
               ^

[0m12:28:04.330986 [debug] [Thread-3 (]: On model.bde.dm_property_type: ROLLBACK
[0m12:28:04.331339 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:28:04.331603 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m12:28:04.331825 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:28:04.344221 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:28:04.081421 => 12:28:04.344102
[0m12:28:04.344473 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:28:04.348784 [debug] [Thread-3 (]: Database Error in model dm_property_type (models/datamart/dm_property_type.sql)
  syntax error at or near "AS"
  LINE 96:     ) AS avg_estimated_revenue_per_active_listing
                 ^
  compiled Code at target/run/bde/models/datamart/dm_property_type.sql
[0m12:28:04.349083 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112124910>]}
[0m12:28:04.349479 [error] [Thread-3 (]: 3 of 19 ERROR creating sql table model datamart.dm_property_type ............... [[31mERROR[0m in 0.29s]
[0m12:28:04.349854 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:28:04.350122 [debug] [Thread-3 (]: Began running node model.bde.stg_LGA
[0m12:28:04.350447 [info ] [Thread-3 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:28:04.350831 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.stg_LGA)
[0m12:28:04.351040 [debug] [Thread-3 (]: Began compiling node model.bde.stg_LGA
[0m12:28:04.353095 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:28:04.353872 [debug] [Thread-3 (]: Timing info for model.bde.stg_LGA (compile): 12:28:04.351187 => 12:28:04.353753
[0m12:28:04.354103 [debug] [Thread-3 (]: Began executing node model.bde.stg_LGA
[0m12:28:04.356347 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:28:04.356716 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:28:04.356907 [debug] [Thread-3 (]: On model.bde.stg_LGA: BEGIN
[0m12:28:04.357089 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:28:04.444704 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:04.445161 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:28:04.445557 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:28:04.458488 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:04.458778 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:28:04.459110 [debug] [Thread-3 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:28:04.460239 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:04.463070 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:28:04.463385 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:28:04.481080 [debug] [Thread-3 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:04.481367 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:04.485107 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:28:04.487262 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:28:04.487597 [debug] [Thread-3 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:28:04.487905 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:28:04.502512 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:04.504686 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:28:04.504966 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:04.505254 [debug] [Thread-3 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:28:04.506478 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:28:04.506823 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:28:04.507094 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:28:04.515265 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:04.516503 [debug] [Thread-3 (]: On model.bde.stg_LGA: COMMIT
[0m12:28:04.516782 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:28:04.517043 [debug] [Thread-3 (]: On model.bde.stg_LGA: COMMIT
[0m12:28:04.517817 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:04.519752 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:28:04.520046 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:28:04.527078 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:04.529139 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:28:04.529428 [debug] [Thread-3 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:28:04.533438 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:04.534458 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 12:28:04.328173 => 12:28:04.534322
[0m12:28:04.534753 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m12:28:04.535438 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112345390>]}
[0m12:28:04.535921 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.21s]
[0m12:28:04.536395 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m12:28:04.536729 [debug] [Thread-4 (]: Began running node model.bde.stg_fact
[0m12:28:04.537129 [info ] [Thread-4 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:28:04.537645 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_fact)
[0m12:28:04.537925 [debug] [Thread-4 (]: Began compiling node model.bde.stg_fact
[0m12:28:04.540589 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:28:04.541919 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (compile): 12:28:04.538128 => 12:28:04.541803
[0m12:28:04.542155 [debug] [Thread-3 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:04.542434 [debug] [Thread-4 (]: Began executing node model.bde.stg_fact
[0m12:28:04.543491 [debug] [Thread-3 (]: Timing info for model.bde.stg_LGA (execute): 12:28:04.354251 => 12:28:04.543367
[0m12:28:04.546404 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:28:04.546703 [debug] [Thread-3 (]: On model.bde.stg_LGA: Close
[0m12:28:04.547341 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11236d840>]}
[0m12:28:04.547605 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:28:04.547982 [info ] [Thread-3 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.20s]
[0m12:28:04.548276 [debug] [Thread-4 (]: On model.bde.stg_fact: BEGIN
[0m12:28:04.548643 [debug] [Thread-3 (]: Finished running node model.bde.stg_LGA
[0m12:28:04.548895 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:28:04.549198 [debug] [Thread-3 (]: Began running node model.bde.stg_host
[0m12:28:04.549746 [info ] [Thread-3 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:28:04.550197 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_host)
[0m12:28:04.550435 [debug] [Thread-3 (]: Began compiling node model.bde.stg_host
[0m12:28:04.552532 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:28:04.553408 [debug] [Thread-3 (]: Timing info for model.bde.stg_host (compile): 12:28:04.550595 => 12:28:04.553296
[0m12:28:04.553642 [debug] [Thread-3 (]: Began executing node model.bde.stg_host
[0m12:28:04.580618 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:28:04.581235 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_host"
[0m12:28:04.581459 [debug] [Thread-3 (]: On model.bde.stg_host: BEGIN
[0m12:28:04.581652 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:28:04.648008 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:04.648391 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:28:04.648767 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:28:04.673727 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:04.676271 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:28:04.676565 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:28:04.685605 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:04.687640 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:28:04.688034 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:28:04.697685 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:04.698933 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:28:04.699227 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:28:04.699484 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:28:04.705514 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:04.705801 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_host"
[0m12:28:04.706160 [debug] [Thread-3 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:28:04.710024 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:04.711918 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:28:04.712231 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:28:04.724552 [debug] [Thread-3 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:04.727018 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_host"
[0m12:28:04.727320 [debug] [Thread-3 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:28:04.727661 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:04.728642 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (execute): 12:28:04.543718 => 12:28:04.728510
[0m12:28:04.728951 [debug] [Thread-4 (]: On model.bde.stg_fact: Close
[0m12:28:04.729667 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112356590>]}
[0m12:28:04.730161 [info ] [Thread-4 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.19s]
[0m12:28:04.730626 [debug] [Thread-4 (]: Finished running node model.bde.stg_fact
[0m12:28:04.730965 [debug] [Thread-4 (]: Began running node model.bde.stg_property
[0m12:28:04.731414 [info ] [Thread-4 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:28:04.732042 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_property)
[0m12:28:04.732338 [debug] [Thread-4 (]: Began compiling node model.bde.stg_property
[0m12:28:04.734808 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:28:04.735651 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (compile): 12:28:04.732531 => 12:28:04.735506
[0m12:28:04.735949 [debug] [Thread-4 (]: Began executing node model.bde.stg_property
[0m12:28:04.738715 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:28:04.738960 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:04.740953 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_host"
[0m12:28:04.741257 [debug] [Thread-3 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:28:04.741511 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:28:04.741795 [debug] [Thread-4 (]: On model.bde.stg_property: BEGIN
[0m12:28:04.742027 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:28:04.750344 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:04.751435 [debug] [Thread-3 (]: On model.bde.stg_host: COMMIT
[0m12:28:04.751690 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_host"
[0m12:28:04.751921 [debug] [Thread-3 (]: On model.bde.stg_host: COMMIT
[0m12:28:04.762589 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:04.765526 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_host"
[0m12:28:04.765809 [debug] [Thread-3 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:28:04.780626 [debug] [Thread-3 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:04.781606 [debug] [Thread-3 (]: Timing info for model.bde.stg_host (execute): 12:28:04.553799 => 12:28:04.781488
[0m12:28:04.781869 [debug] [Thread-3 (]: On model.bde.stg_host: Close
[0m12:28:04.782433 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127d45b0>]}
[0m12:28:04.782864 [info ] [Thread-3 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.23s]
[0m12:28:04.783292 [debug] [Thread-3 (]: Finished running node model.bde.stg_host
[0m12:28:04.783584 [debug] [Thread-3 (]: Began running node model.bde.stg_room
[0m12:28:04.783970 [info ] [Thread-3 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:28:04.784515 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_room)
[0m12:28:04.784768 [debug] [Thread-3 (]: Began compiling node model.bde.stg_room
[0m12:28:04.786951 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:28:04.787769 [debug] [Thread-3 (]: Timing info for model.bde.stg_room (compile): 12:28:04.784950 => 12:28:04.787626
[0m12:28:04.788028 [debug] [Thread-3 (]: Began executing node model.bde.stg_room
[0m12:28:04.790637 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:28:04.791246 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_room"
[0m12:28:04.791488 [debug] [Thread-3 (]: On model.bde.stg_room: BEGIN
[0m12:28:04.791701 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:28:04.856750 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:04.857177 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:28:04.857557 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:28:04.873743 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:04.876798 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:28:04.877150 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:28:04.887217 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:04.889721 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:28:04.890077 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:28:04.901478 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:04.902869 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:28:04.903201 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:28:04.903758 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:28:04.910367 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:04.910671 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_room"
[0m12:28:04.911002 [debug] [Thread-3 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:28:04.912795 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:04.915050 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:28:04.915402 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:28:04.925719 [debug] [Thread-3 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:04.928380 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_room"
[0m12:28:04.928698 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:04.929056 [debug] [Thread-3 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:28:04.930251 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (execute): 12:28:04.736136 => 12:28:04.930096
[0m12:28:04.930686 [debug] [Thread-4 (]: On model.bde.stg_property: Close
[0m12:28:04.931405 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113027640>]}
[0m12:28:04.931959 [info ] [Thread-4 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.20s]
[0m12:28:04.932477 [debug] [Thread-4 (]: Finished running node model.bde.stg_property
[0m12:28:04.932844 [debug] [Thread-4 (]: Began running node model.bde.stg_suburb
[0m12:28:04.933349 [info ] [Thread-4 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:28:04.933872 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_suburb)
[0m12:28:04.934150 [debug] [Thread-4 (]: Began compiling node model.bde.stg_suburb
[0m12:28:04.936512 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:28:04.937112 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (compile): 12:28:04.934348 => 12:28:04.936972
[0m12:28:04.937403 [debug] [Thread-4 (]: Began executing node model.bde.stg_suburb
[0m12:28:04.941591 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:28:04.941860 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:04.943861 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_room"
[0m12:28:04.944149 [debug] [Thread-3 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:28:04.944476 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:28:04.944741 [debug] [Thread-4 (]: On model.bde.stg_suburb: BEGIN
[0m12:28:04.944985 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:28:04.958177 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:04.959298 [debug] [Thread-3 (]: On model.bde.stg_room: COMMIT
[0m12:28:04.959545 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_room"
[0m12:28:04.959774 [debug] [Thread-3 (]: On model.bde.stg_room: COMMIT
[0m12:28:05.067685 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:05.068189 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:28:05.068612 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:28:05.081291 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:05.085318 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:28:05.085750 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:28:05.187304 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:05.190822 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_room"
[0m12:28:05.191214 [debug] [Thread-3 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:28:05.218216 [debug] [Thread-3 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:05.219869 [debug] [Thread-3 (]: Timing info for model.bde.stg_room (execute): 12:28:04.788202 => 12:28:05.219671
[0m12:28:05.220305 [debug] [Thread-3 (]: On model.bde.stg_room: Close
[0m12:28:05.221296 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d5300>]}
[0m12:28:05.222323 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:05.221963 [info ] [Thread-3 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.44s]
[0m12:28:05.225578 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:28:05.226100 [debug] [Thread-3 (]: Finished running node model.bde.stg_room
[0m12:28:05.226499 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:28:05.226956 [debug] [Thread-3 (]: Began running node model.bde.dim_LGA
[0m12:28:05.227623 [info ] [Thread-3 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:28:05.228290 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.dim_LGA)
[0m12:28:05.228659 [debug] [Thread-3 (]: Began compiling node model.bde.dim_LGA
[0m12:28:05.231758 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:28:05.234231 [debug] [Thread-3 (]: Timing info for model.bde.dim_LGA (compile): 12:28:05.228893 => 12:28:05.234077
[0m12:28:05.234566 [debug] [Thread-3 (]: Began executing node model.bde.dim_LGA
[0m12:28:05.237929 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:28:05.238222 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:05.239942 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m12:28:05.240363 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:28:05.240685 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:28:05.241007 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m12:28:05.241309 [debug] [Thread-3 (]: On model.bde.dim_LGA: BEGIN
[0m12:28:05.241631 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:28:05.253182 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:05.255622 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:28:05.255912 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:28:05.268533 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:05.269675 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (execute): 12:28:04.937601 => 12:28:05.269536
[0m12:28:05.269970 [debug] [Thread-4 (]: On model.bde.stg_suburb: Close
[0m12:28:05.270571 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113034ee0>]}
[0m12:28:05.271049 [info ] [Thread-4 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.34s]
[0m12:28:05.271477 [debug] [Thread-4 (]: Finished running node model.bde.stg_suburb
[0m12:28:05.271795 [debug] [Thread-4 (]: Began running node model.bde.fact_G01
[0m12:28:05.272223 [info ] [Thread-4 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:28:05.272760 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.fact_G01)
[0m12:28:05.273060 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G01
[0m12:28:05.275561 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:28:05.276430 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (compile): 12:28:05.273261 => 12:28:05.276306
[0m12:28:05.276677 [debug] [Thread-4 (]: Began executing node model.bde.fact_G01
[0m12:28:05.280460 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:28:05.280891 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:28:05.281124 [debug] [Thread-4 (]: On model.bde.fact_G01: BEGIN
[0m12:28:05.281344 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:28:05.349892 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:05.350334 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:28:05.350639 [debug] [Thread-3 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:28:05.367547 [debug] [Thread-3 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:28:05.370535 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:28:05.370856 [debug] [Thread-3 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:28:05.379780 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:05.382215 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:28:05.382508 [debug] [Thread-3 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:28:05.386477 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:05.386801 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:28:05.387118 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:28:05.394876 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:05.399974 [debug] [Thread-3 (]: On model.bde.dim_LGA: COMMIT
[0m12:28:05.400370 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:28:05.400640 [debug] [Thread-3 (]: On model.bde.dim_LGA: COMMIT
[0m12:28:05.409579 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:28:05.412231 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:28:05.412578 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:05.412893 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:28:05.416612 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:28:05.417032 [debug] [Thread-3 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:28:05.426286 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:05.428347 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:28:05.428636 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:28:05.432631 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:05.433641 [debug] [Thread-3 (]: Timing info for model.bde.dim_LGA (execute): 12:28:05.234775 => 12:28:05.433513
[0m12:28:05.433953 [debug] [Thread-3 (]: On model.bde.dim_LGA: Close
[0m12:28:05.434612 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112376bc0>]}
[0m12:28:05.435085 [info ] [Thread-3 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.21s]
[0m12:28:05.435534 [debug] [Thread-3 (]: Finished running node model.bde.dim_LGA
[0m12:28:05.435863 [debug] [Thread-3 (]: Began running node model.bde.fact_G02
[0m12:28:05.436280 [info ] [Thread-3 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:28:05.436849 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G02)
[0m12:28:05.437153 [debug] [Thread-3 (]: Began compiling node model.bde.fact_G02
[0m12:28:05.439738 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:28:05.440362 [debug] [Thread-3 (]: Timing info for model.bde.fact_G02 (compile): 12:28:05.437358 => 12:28:05.440212
[0m12:28:05.440651 [debug] [Thread-3 (]: Began executing node model.bde.fact_G02
[0m12:28:05.443566 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:28:05.443814 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:05.445076 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m12:28:05.445360 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:28:05.445603 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_G02"
[0m12:28:05.445842 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m12:28:05.446077 [debug] [Thread-3 (]: On model.bde.fact_G02: BEGIN
[0m12:28:05.446356 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:28:05.456209 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:05.459472 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m12:28:05.459758 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:28:05.488647 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:05.489772 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (execute): 12:28:05.276839 => 12:28:05.489639
[0m12:28:05.490082 [debug] [Thread-4 (]: On model.bde.fact_G01: Close
[0m12:28:05.490745 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11241a440>]}
[0m12:28:05.491193 [info ] [Thread-4 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.22s]
[0m12:28:05.491656 [debug] [Thread-4 (]: Finished running node model.bde.fact_G01
[0m12:28:05.491989 [debug] [Thread-4 (]: Began running node model.bde.fact_listing
[0m12:28:05.492400 [info ] [Thread-4 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:28:05.492933 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_listing)
[0m12:28:05.493202 [debug] [Thread-4 (]: Began compiling node model.bde.fact_listing
[0m12:28:05.495465 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:28:05.496225 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (compile): 12:28:05.493390 => 12:28:05.496108
[0m12:28:05.496488 [debug] [Thread-4 (]: Began executing node model.bde.fact_listing
[0m12:28:05.499308 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:28:05.499771 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:28:05.500023 [debug] [Thread-4 (]: On model.bde.fact_listing: BEGIN
[0m12:28:05.500263 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:28:05.579530 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:05.579953 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_G02"
[0m12:28:05.580160 [debug] [Thread-3 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:28:05.598413 [debug] [Thread-3 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:28:05.600568 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_G02"
[0m12:28:05.600809 [debug] [Thread-3 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:28:05.611253 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:05.612920 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_G02"
[0m12:28:05.613159 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:05.613447 [debug] [Thread-3 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:28:05.613701 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:28:05.614012 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:28:05.622704 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:05.623907 [debug] [Thread-3 (]: On model.bde.fact_G02: COMMIT
[0m12:28:05.624144 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_G02"
[0m12:28:05.624355 [debug] [Thread-3 (]: On model.bde.fact_G02: COMMIT
[0m12:28:05.635271 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:05.636879 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_G02"
[0m12:28:05.637116 [debug] [Thread-3 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:28:05.655656 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:05.656601 [debug] [Thread-3 (]: Timing info for model.bde.fact_G02 (execute): 12:28:05.440846 => 12:28:05.656470
[0m12:28:05.656878 [debug] [Thread-3 (]: On model.bde.fact_G02: Close
[0m12:28:05.657515 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11228fb20>]}
[0m12:28:05.657930 [info ] [Thread-3 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.22s]
[0m12:28:05.658346 [debug] [Thread-3 (]: Finished running node model.bde.fact_G02
[0m12:28:05.658643 [debug] [Thread-3 (]: Began running node model.bde.dim_host
[0m12:28:05.658949 [info ] [Thread-3 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:28:05.659474 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m12:28:05.659753 [debug] [Thread-3 (]: Began compiling node model.bde.dim_host
[0m12:28:05.662052 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:28:05.662764 [debug] [Thread-3 (]: Timing info for model.bde.dim_host (compile): 12:28:05.659938 => 12:28:05.662644
[0m12:28:05.663015 [debug] [Thread-3 (]: Began executing node model.bde.dim_host
[0m12:28:05.665657 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:28:05.666186 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_host"
[0m12:28:05.666426 [debug] [Thread-3 (]: On model.bde.dim_host: BEGIN
[0m12:28:05.666644 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:28:05.697839 [debug] [Thread-1 (]: SQL status: SELECT 217 in 1.0 seconds
[0m12:28:05.701384 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:28:05.701688 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m12:28:05.713395 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:05.715447 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:28:05.715718 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m12:28:05.725601 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:05.726917 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:28:05.727212 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:28:05.727476 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:28:05.744312 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:05.746347 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:28:05.746648 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m12:28:05.765042 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:05.765356 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_host"
[0m12:28:05.765709 [debug] [Thread-3 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    scraped_date,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:28:05.774592 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:05.775818 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:28:04.103768 => 12:28:05.775641
[0m12:28:05.776181 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:28:05.776894 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122ccf70>]}
[0m12:28:05.777428 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 217[0m in 1.71s]
[0m12:28:05.777966 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:28:05.778364 [debug] [Thread-1 (]: Began running node model.bde.dim_property
[0m12:28:05.778800 [info ] [Thread-1 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:28:05.779401 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.dim_property)
[0m12:28:05.779744 [debug] [Thread-1 (]: Began compiling node model.bde.dim_property
[0m12:28:05.782315 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:28:05.783766 [debug] [Thread-1 (]: Timing info for model.bde.dim_property (compile): 12:28:05.779978 => 12:28:05.783633
[0m12:28:05.784046 [debug] [Thread-1 (]: Began executing node model.bde.dim_property
[0m12:28:05.787062 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:28:05.787548 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_property"
[0m12:28:05.787818 [debug] [Thread-1 (]: On model.bde.dim_property: BEGIN
[0m12:28:05.788072 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:28:05.898420 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:05.899095 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_property"
[0m12:28:05.899644 [debug] [Thread-1 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:28:06.494053 [debug] [Thread-1 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m12:28:06.495564 [debug] [Thread-3 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m12:28:06.502317 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_property"
[0m12:28:06.506288 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_host"
[0m12:28:06.506751 [debug] [Thread-1 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:28:06.507173 [debug] [Thread-3 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:28:08.128296 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m12:28:08.137221 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:28:08.138075 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:28:08.150793 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:08.158102 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:28:08.159216 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:28:08.169151 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:08.172351 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:28:08.172916 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:28:08.173397 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:28:08.214382 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:08.215557 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 2.0 seconds
[0m12:28:08.216769 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 2.0 seconds
[0m12:28:08.222472 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:28:08.226430 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_host"
[0m12:28:08.229274 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_property"
[0m12:28:08.229699 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:28:08.230098 [debug] [Thread-3 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:28:08.230484 [debug] [Thread-1 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:28:08.239423 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:08.241282 [debug] [Thread-3 (]: On model.bde.dim_host: COMMIT
[0m12:28:08.241663 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_host"
[0m12:28:08.242008 [debug] [Thread-3 (]: On model.bde.dim_host: COMMIT
[0m12:28:08.242887 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:08.244628 [debug] [Thread-1 (]: On model.bde.dim_property: COMMIT
[0m12:28:08.245012 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_property"
[0m12:28:08.245361 [debug] [Thread-1 (]: On model.bde.dim_property: COMMIT
[0m12:28:08.252935 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:08.254289 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:28:04.106035 => 12:28:08.254080
[0m12:28:08.254693 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:28:08.255659 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112357190>]}
[0m12:28:08.256089 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:08.256862 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 4.19s]
[0m12:28:08.259695 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_host"
[0m12:28:08.260032 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:08.260530 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:28:08.260864 [debug] [Thread-3 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:28:08.263016 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_property"
[0m12:28:08.263412 [debug] [Thread-2 (]: Began running node model.bde.dim_room
[0m12:28:08.263970 [debug] [Thread-1 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:28:08.264394 [info ] [Thread-2 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:28:08.265001 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_room)
[0m12:28:08.265290 [debug] [Thread-2 (]: Began compiling node model.bde.dim_room
[0m12:28:08.267924 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:28:08.269693 [debug] [Thread-2 (]: Timing info for model.bde.dim_room (compile): 12:28:08.265489 => 12:28:08.269558
[0m12:28:08.269971 [debug] [Thread-2 (]: Began executing node model.bde.dim_room
[0m12:28:08.273056 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:28:08.273556 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:28:08.273798 [debug] [Thread-2 (]: On model.bde.dim_room: BEGIN
[0m12:28:08.274033 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:28:08.312051 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:08.313544 [debug] [Thread-1 (]: Timing info for model.bde.dim_property (execute): 12:28:05.784251 => 12:28:08.313397
[0m12:28:08.313853 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:08.314244 [debug] [Thread-1 (]: On model.bde.dim_property: Close
[0m12:28:08.315375 [debug] [Thread-3 (]: Timing info for model.bde.dim_host (execute): 12:28:05.663185 => 12:28:08.315244
[0m12:28:08.315792 [debug] [Thread-3 (]: On model.bde.dim_host: Close
[0m12:28:08.316393 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122548b0>]}
[0m12:28:08.317442 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112733bb0>]}
[0m12:28:08.316973 [info ] [Thread-1 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 2.54s]
[0m12:28:08.318004 [info ] [Thread-3 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 2.66s]
[0m12:28:08.318543 [debug] [Thread-1 (]: Finished running node model.bde.dim_property
[0m12:28:08.318907 [debug] [Thread-3 (]: Finished running node model.bde.dim_host
[0m12:28:08.319224 [debug] [Thread-1 (]: Began running node model.bde.dim_suburb
[0m12:28:08.319651 [info ] [Thread-1 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:28:08.320122 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dim_property, now model.bde.dim_suburb)
[0m12:28:08.320373 [debug] [Thread-1 (]: Began compiling node model.bde.dim_suburb
[0m12:28:08.322736 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:28:08.323547 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (compile): 12:28:08.320547 => 12:28:08.323417
[0m12:28:08.323816 [debug] [Thread-1 (]: Began executing node model.bde.dim_suburb
[0m12:28:08.327610 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:28:08.328063 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:28:08.328294 [debug] [Thread-1 (]: On model.bde.dim_suburb: BEGIN
[0m12:28:08.328501 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:28:08.384487 [debug] [Thread-4 (]: SQL status: SELECT 340945 in 3.0 seconds
[0m12:28:08.387073 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:28:08.387396 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:08.387748 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:28:08.388065 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:28:08.388435 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:28:08.397447 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:08.399698 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:28:08.399998 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:28:08.409907 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:08.411293 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m12:28:08.411648 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:28:08.411929 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m12:28:08.429916 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:08.430221 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:28:08.430528 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:28:08.432898 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:08.435037 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:28:08.435374 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:28:08.458635 [debug] [Thread-1 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:28:08.461628 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:28:08.461978 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:28:08.476730 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:08.477104 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:08.479913 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:28:08.481118 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (execute): 12:28:05.496664 => 12:28:08.480959
[0m12:28:08.481467 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:28:08.481810 [debug] [Thread-4 (]: On model.bde.fact_listing: Close
[0m12:28:08.482592 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112337550>]}
[0m12:28:08.483124 [info ] [Thread-4 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 2.99s]
[0m12:28:08.483644 [debug] [Thread-4 (]: Finished running node model.bde.fact_listing
[0m12:28:08.492883 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:08.494547 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m12:28:08.494896 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:28:08.495202 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m12:28:08.510437 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:08.512948 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:28:08.513301 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:28:08.532923 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:08.534172 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (execute): 12:28:08.323993 => 12:28:08.534018
[0m12:28:08.534534 [debug] [Thread-1 (]: On model.bde.dim_suburb: Close
[0m12:28:08.535263 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113026bf0>]}
[0m12:28:08.535776 [info ] [Thread-1 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.22s]
[0m12:28:08.536319 [debug] [Thread-1 (]: Finished running node model.bde.dim_suburb
[0m12:28:08.552695 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:28:08.555713 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:28:08.556072 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:28:08.566198 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:08.570559 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:28:08.570911 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:28:08.580489 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:08.582257 [debug] [Thread-2 (]: On model.bde.dim_room: COMMIT
[0m12:28:08.582640 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:28:08.582998 [debug] [Thread-2 (]: On model.bde.dim_room: COMMIT
[0m12:28:08.598738 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:08.601386 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:28:08.601788 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:28:08.616047 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:08.617770 [debug] [Thread-2 (]: Timing info for model.bde.dim_room (execute): 12:28:08.270162 => 12:28:08.617551
[0m12:28:08.618285 [debug] [Thread-2 (]: On model.bde.dim_room: Close
[0m12:28:08.619342 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6df98b0c-9118-4346-a086-363d3704681e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130d7a90>]}
[0m12:28:08.620074 [info ] [Thread-2 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.35s]
[0m12:28:08.620671 [debug] [Thread-2 (]: Finished running node model.bde.dim_room
[0m12:28:08.622334 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:08.622707 [debug] [MainThread]: On master: BEGIN
[0m12:28:08.623042 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:28:08.725685 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:28:08.727209 [debug] [MainThread]: On master: COMMIT
[0m12:28:08.727764 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:08.728274 [debug] [MainThread]: On master: COMMIT
[0m12:28:08.740700 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:28:08.742161 [debug] [MainThread]: On master: Close
[0m12:28:08.744581 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:28:08.745276 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:28:08.745655 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:28:08.746018 [debug] [MainThread]: Connection 'model.bde.dim_host' was properly closed.
[0m12:28:08.746371 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:28:08.747048 [info ] [MainThread]: 
[0m12:28:08.747589 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 5.19 seconds (5.19s).
[0m12:28:08.751570 [debug] [MainThread]: Command end result
[0m12:28:08.763260 [info ] [MainThread]: 
[0m12:28:08.763655 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m12:28:08.763942 [info ] [MainThread]: 
[0m12:28:08.764237 [error] [MainThread]:   Database Error in model dm_property_type (models/datamart/dm_property_type.sql)
  syntax error at or near "AS"
  LINE 96:     ) AS avg_estimated_revenue_per_active_listing
                 ^
  compiled Code at target/run/bde/models/datamart/dm_property_type.sql
[0m12:28:08.764550 [info ] [MainThread]: 
[0m12:28:08.764847 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m12:28:08.765484 [debug] [MainThread]: Command `dbt run` failed at 12:28:08.765401 after 5.36 seconds
[0m12:28:08.765895 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e61750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d01180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122cd720>]}
[0m12:28:08.766269 [debug] [MainThread]: Flushing usage events
[0m12:28:57.794076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1036ac250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105609a20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105609360>]}


============================== 12:28:57.796705 | 1a552448-4c0e-459a-8856-fce5bbeb9a19 ==============================
[0m12:28:57.796705 [info ] [MainThread]: Running with dbt=1.6.6
[0m12:28:57.797020 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'debug': 'False', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --full-refresh', 'send_anonymous_usage_stats': 'True'}
[0m12:28:57.846378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105609570>]}
[0m12:28:57.853919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a550c0>]}
[0m12:28:57.854267 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m12:28:57.863461 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m12:28:57.888021 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:28:57.888293 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:28:57.888977 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.median
- models.bde.raw
[0m12:28:57.892238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061700d0>]}
[0m12:28:57.898654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106132bc0>]}
[0m12:28:57.898932 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m12:28:57.899124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106130130>]}
[0m12:28:57.900295 [info ] [MainThread]: 
[0m12:28:57.900675 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:28:57.901509 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:28:57.901943 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:28:57.906682 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:28:57.906980 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:28:57.907914 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:28:57.908103 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:28:57.909204 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:28:57.909388 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:28:57.909549 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:28:57.909702 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:28:57.909841 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:28:57.910782 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:28:58.055144 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:28:58.056501 [debug] [ThreadPool]: On list_postgres: Close
[0m12:28:58.057649 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:28:58.058438 [debug] [ThreadPool]: On list_postgres: Close
[0m12:28:58.271331 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:28:58.275535 [debug] [ThreadPool]: On list_postgres: Close
[0m12:28:58.280513 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m12:28:58.281620 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_warehouse)
[0m12:28:58.282581 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_staging)
[0m12:28:58.290055 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:28:58.290942 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_datamart'
[0m12:28:58.292858 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:28:58.294587 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:28:58.294939 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m12:28:58.296568 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:28:58.296883 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m12:28:58.297153 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m12:28:58.297432 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:28:58.297676 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m12:28:58.297893 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:28:58.298107 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:28:58.298488 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:28:58.418215 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:28:58.418669 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:28:58.419044 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m12:28:58.419742 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:28:58.420070 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:28:58.420424 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:28:58.420712 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:28:58.421023 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:28:58.421323 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:28:58.421671 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m12:28:58.422073 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m12:28:58.422468 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m12:28:58.432160 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:28:58.433683 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m12:28:58.442479 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:28:58.443984 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m12:28:58.444367 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m12:28:58.444704 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:28:58.445955 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m12:28:58.446640 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:28:58.449066 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m12:28:58.456905 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m12:28:58.457187 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m12:28:58.460317 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m12:28:58.466984 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:58.467335 [debug] [MainThread]: On master: BEGIN
[0m12:28:58.467610 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:28:58.565009 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:28:58.566529 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:58.567615 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:28:58.594633 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:28:58.599640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059d7e80>]}
[0m12:28:58.600556 [debug] [MainThread]: On master: ROLLBACK
[0m12:28:58.609418 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:58.609918 [debug] [MainThread]: On master: BEGIN
[0m12:28:58.627778 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:28:58.629217 [debug] [MainThread]: On master: COMMIT
[0m12:28:58.630256 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:58.631169 [debug] [MainThread]: On master: COMMIT
[0m12:28:58.641526 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:28:58.642900 [debug] [MainThread]: On master: Close
[0m12:28:58.644913 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:28:58.645482 [info ] [MainThread]: 
[0m12:28:58.651120 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m12:28:58.651823 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m12:28:58.652281 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m12:28:58.652772 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m12:28:58.653404 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m12:28:58.654069 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m12:28:58.654648 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m12:28:58.655148 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m12:28:58.655944 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_host_neighbourhod)
[0m12:28:58.656590 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.dm_listing_neighbourhood)
[0m12:28:58.657196 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.dm_property_type)
[0m12:28:58.657812 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.stg_G01)
[0m12:28:58.658222 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m12:28:58.658599 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m12:28:58.658957 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m12:28:58.659318 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m12:28:58.667081 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m12:28:58.669573 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m12:28:58.673186 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m12:28:58.675856 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m12:28:58.676762 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 12:28:58.659622 => 12:28:58.676584
[0m12:28:58.677186 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m12:28:58.677514 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 12:28:58.673464 => 12:28:58.677380
[0m12:28:58.684386 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 12:28:58.667401 => 12:28:58.684199
[0m12:28:58.684713 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 12:28:58.669842 => 12:28:58.684591
[0m12:28:58.697613 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m12:28:58.704478 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m12:28:58.704784 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m12:28:58.705017 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m12:28:58.715159 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m12:28:58.717336 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m12:28:58.719807 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m12:28:58.720120 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:28:58.720469 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m12:28:58.720701 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:28:58.720918 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:28:58.721291 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:28:58.721493 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m12:28:58.721687 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:28:58.721880 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m12:28:58.722071 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:28:58.722253 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m12:28:58.722426 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:28:58.722676 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:28:58.817379 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:58.817740 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:28:58.818259 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type

-- Set the configuration for the materialized view



-- Create a Common Table Expression (CTE) called sorted_listing
-- This CTE retrieves data from multiple tables and calculates various metrics
-- It includes property_type, room_type, accommodates, and more.


WITH sorted_listing AS (
    SELECT 
        prop.property_type,-- Property type
        room.room_type,-- Room type
        list.accommodates,-- Accommodates
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year, -- Truncate the date to the month
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id, -- Host ID
        host.host_is_superhost,-- Host is superhost flag
        review_scores_rating,-- Review scores rating
        availability_30-- Availability for the next 30 days
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
-- Select the aggregated metrics for the property_type, room_type, accommodates, and month_year
SELECT 
    property_type,-- Property type
    room_type,-- Room type
    accommodates,-- Number of accommodates
    month_year,-- Truncated month and year
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,-- Calculate the minimum price for active listings
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,-- Calculate the maximum price for active listings
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing, -- Calculate the median price for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts, -- Count the number of distinct hosts
     -- Calculate the superhost rate
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
     -- Calculate the average review scores rating for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


     -- Calculate the percentage change for active listing
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
ROUND(
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:28:58.838325 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:58.838604 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:28:58.839110 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,     
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m12:28:58.840688 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:58.840974 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:58.841327 [debug] [Thread-3 (]: Postgres adapter: Postgres error: syntax error at or near "AS"
LINE 96:     ) AS avg_estimated_revenue_per_active_listing
               ^

[0m12:28:58.841617 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:28:58.841893 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:28:58.842169 [debug] [Thread-3 (]: On model.bde.dm_property_type: ROLLBACK
[0m12:28:58.842557 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM 
        warehouse.dim_host host
    LEFT JOIN 
        warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
distinct_host_count AS (
    SELECT
        TO_CHAR(h.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        COUNT(DISTINCT h.host_id) AS num_distinct_hosts
    FROM
        host_neighbourhood_lga_transform h
    GROUP BY
        TO_CHAR(h.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
),
estimated_revenue AS (
    SELECT
        TO_CHAR(l.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        SUM((30 - l.availability_30) * l.price) AS total_estimated_revenue
    FROM
        warehouse.fact_listing l
    LEFT JOIN
        host_neighbourhood_lga_transform h ON l.surrogate_key_host = h.surrogate_key_host
    WHERE
        l.has_availability = 't'
    GROUP BY
        TO_CHAR(l.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
)
SELECT
    dhct.month_year,
    dhct.host_neighbourhood_lga,
    dhct.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dhct.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dhct.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM
    distinct_host_count dhct
LEFT JOIN
    estimated_revenue er ON dhct.month_year = er.month_year AND dhct.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY
    dhct.month_year, dhct.host_neighbourhood_lga
  );
  
[0m12:28:58.843114 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:28:58.854886 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:28:58.717536 => 12:28:58.854729
[0m12:28:58.855170 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:28:58.860635 [debug] [Thread-3 (]: Database Error in model dm_property_type (models/datamart/dm_property_type.sql)
  syntax error at or near "AS"
  LINE 96:     ) AS avg_estimated_revenue_per_active_listing
                 ^
  compiled Code at target/run/bde/models/datamart/dm_property_type.sql
[0m12:28:58.861079 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106274ca0>]}
[0m12:28:58.861612 [error] [Thread-3 (]: 3 of 19 ERROR creating sql table model datamart.dm_property_type ............... [[31mERROR[0m in 0.20s]
[0m12:28:58.862113 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:28:58.862451 [debug] [Thread-3 (]: Began running node model.bde.stg_G02
[0m12:28:58.862876 [info ] [Thread-3 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:28:58.863328 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.stg_G02)
[0m12:28:58.863588 [debug] [Thread-3 (]: Began compiling node model.bde.stg_G02
[0m12:28:58.866250 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:28:58.866891 [debug] [Thread-3 (]: Timing info for model.bde.stg_G02 (compile): 12:28:58.863764 => 12:28:58.866766
[0m12:28:58.867148 [debug] [Thread-3 (]: Began executing node model.bde.stg_G02
[0m12:28:58.870006 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:28:58.870480 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_G02"
[0m12:28:58.870718 [debug] [Thread-3 (]: On model.bde.stg_G02: BEGIN
[0m12:28:58.870933 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:28:58.877309 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:58.881867 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:28:58.882152 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:28:58.893841 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:58.895819 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:28:58.896075 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:28:58.907453 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:58.918479 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:28:58.918759 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:28:58.918973 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:28:58.931526 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:58.936650 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:28:58.936923 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:28:58.951297 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:58.952244 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:28:58.705178 => 12:28:58.952134
[0m12:28:58.952503 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:28:58.953061 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061d88e0>]}
[0m12:28:58.953470 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.30s]
[0m12:28:58.953963 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:28:58.954281 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m12:28:58.954623 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:28:58.955039 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_LGA)
[0m12:28:58.955281 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m12:28:58.957288 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:28:58.957808 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 12:28:58.955449 => 12:28:58.957701
[0m12:28:58.958033 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m12:28:58.961459 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:28:58.961904 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:28:58.962131 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m12:28:58.962340 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:28:58.969940 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:58.970237 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_G02"
[0m12:28:58.970534 [debug] [Thread-3 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:28:58.985476 [debug] [Thread-3 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:58.987731 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_G02"
[0m12:28:58.987986 [debug] [Thread-3 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:28:58.996305 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:58.998071 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_G02"
[0m12:28:58.998311 [debug] [Thread-3 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:28:59.007394 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.008421 [debug] [Thread-3 (]: On model.bde.stg_G02: COMMIT
[0m12:28:59.008680 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_G02"
[0m12:28:59.008912 [debug] [Thread-3 (]: On model.bde.stg_G02: COMMIT
[0m12:28:59.019395 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:59.021231 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_G02"
[0m12:28:59.021500 [debug] [Thread-3 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:28:59.032086 [debug] [Thread-3 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:59.032972 [debug] [Thread-3 (]: Timing info for model.bde.stg_G02 (execute): 12:28:58.867323 => 12:28:59.032857
[0m12:28:59.033221 [debug] [Thread-3 (]: On model.bde.stg_G02: Close
[0m12:28:59.033760 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110149f90>]}
[0m12:28:59.034157 [info ] [Thread-3 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.17s]
[0m12:28:59.034554 [debug] [Thread-3 (]: Finished running node model.bde.stg_G02
[0m12:28:59.034843 [debug] [Thread-3 (]: Began running node model.bde.stg_fact
[0m12:28:59.035199 [info ] [Thread-3 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:28:59.035686 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_fact)
[0m12:28:59.035944 [debug] [Thread-3 (]: Began compiling node model.bde.stg_fact
[0m12:28:59.038270 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:28:59.038805 [debug] [Thread-3 (]: Timing info for model.bde.stg_fact (compile): 12:28:59.036121 => 12:28:59.038684
[0m12:28:59.039055 [debug] [Thread-3 (]: Began executing node model.bde.stg_fact
[0m12:28:59.041678 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:28:59.042075 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_fact"
[0m12:28:59.042302 [debug] [Thread-3 (]: On model.bde.stg_fact: BEGIN
[0m12:28:59.042515 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:28:59.081950 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:59.082274 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:28:59.082592 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:28:59.100993 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:59.103578 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:28:59.103866 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:28:59.113073 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.115033 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:28:59.115296 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:28:59.124241 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.125200 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:28:59.125418 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:28:59.125607 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:28:59.135406 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:59.136938 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:28:59.137176 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:28:59.148304 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:59.149187 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 12:28:58.958190 => 12:28:59.149085
[0m12:28:59.149436 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m12:28:59.149974 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062037f0>]}
[0m12:28:59.150314 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.20s]
[0m12:28:59.150667 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m12:28:59.150928 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m12:28:59.151317 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:28:59.151734 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_host)
[0m12:28:59.151952 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m12:28:59.154709 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:28:59.155161 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 12:28:59.152127 => 12:28:59.155062
[0m12:28:59.155348 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:59.155541 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m12:28:59.155732 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_fact"
[0m12:28:59.158241 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:28:59.158703 [debug] [Thread-3 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:28:59.159247 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:28:59.159465 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m12:28:59.159655 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:28:59.177235 [debug] [Thread-3 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:59.179429 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_fact"
[0m12:28:59.179679 [debug] [Thread-3 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:28:59.189120 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.190995 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_fact"
[0m12:28:59.191223 [debug] [Thread-3 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:28:59.201415 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.202419 [debug] [Thread-3 (]: On model.bde.stg_fact: COMMIT
[0m12:28:59.202643 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_fact"
[0m12:28:59.202840 [debug] [Thread-3 (]: On model.bde.stg_fact: COMMIT
[0m12:28:59.212892 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:59.214563 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_fact"
[0m12:28:59.214819 [debug] [Thread-3 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:28:59.226229 [debug] [Thread-3 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:59.227150 [debug] [Thread-3 (]: Timing info for model.bde.stg_fact (execute): 12:28:59.039228 => 12:28:59.227034
[0m12:28:59.227403 [debug] [Thread-3 (]: On model.bde.stg_fact: Close
[0m12:28:59.228022 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11019c100>]}
[0m12:28:59.228410 [info ] [Thread-3 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.19s]
[0m12:28:59.228817 [debug] [Thread-3 (]: Finished running node model.bde.stg_fact
[0m12:28:59.229097 [debug] [Thread-3 (]: Began running node model.bde.stg_property
[0m12:28:59.229501 [info ] [Thread-3 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:28:59.229939 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_property)
[0m12:28:59.230173 [debug] [Thread-3 (]: Began compiling node model.bde.stg_property
[0m12:28:59.232375 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:28:59.232949 [debug] [Thread-3 (]: Timing info for model.bde.stg_property (compile): 12:28:59.230339 => 12:28:59.232827
[0m12:28:59.233198 [debug] [Thread-3 (]: Began executing node model.bde.stg_property
[0m12:28:59.236126 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:28:59.236657 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_property"
[0m12:28:59.236893 [debug] [Thread-3 (]: On model.bde.stg_property: BEGIN
[0m12:28:59.237106 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:28:59.257990 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:59.258314 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:28:59.258631 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:28:59.274773 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:59.277292 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:28:59.277580 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:28:59.289215 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.292250 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:28:59.292555 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:28:59.301338 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.302483 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:28:59.302753 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:28:59.303003 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:28:59.315935 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:59.343138 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:28:59.343499 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:28:59.359187 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:59.360143 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 12:28:59.155873 => 12:28:59.360026
[0m12:28:59.360410 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m12:28:59.360634 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:59.360939 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_property"
[0m12:28:59.361387 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101e9960>]}
[0m12:28:59.361706 [debug] [Thread-3 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:28:59.362165 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.21s]
[0m12:28:59.362747 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m12:28:59.363082 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m12:28:59.363449 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:28:59.364003 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_room)
[0m12:28:59.364249 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m12:28:59.366256 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:28:59.366832 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 12:28:59.364406 => 12:28:59.366722
[0m12:28:59.367055 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m12:28:59.369474 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:28:59.369889 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:28:59.370099 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m12:28:59.370292 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:28:59.377260 [debug] [Thread-3 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:59.379225 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_property"
[0m12:28:59.379468 [debug] [Thread-3 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:28:59.389383 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.391192 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_property"
[0m12:28:59.391439 [debug] [Thread-3 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:28:59.401018 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.402177 [debug] [Thread-3 (]: On model.bde.stg_property: COMMIT
[0m12:28:59.402439 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_property"
[0m12:28:59.402661 [debug] [Thread-3 (]: On model.bde.stg_property: COMMIT
[0m12:28:59.412784 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:59.414455 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_property"
[0m12:28:59.414710 [debug] [Thread-3 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:28:59.435795 [debug] [Thread-3 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:59.436851 [debug] [Thread-3 (]: Timing info for model.bde.stg_property (execute): 12:28:59.233366 => 12:28:59.436732
[0m12:28:59.437136 [debug] [Thread-3 (]: On model.bde.stg_property: Close
[0m12:28:59.437704 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106173550>]}
[0m12:28:59.438137 [info ] [Thread-3 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.21s]
[0m12:28:59.438560 [debug] [Thread-3 (]: Finished running node model.bde.stg_property
[0m12:28:59.438873 [debug] [Thread-3 (]: Began running node model.bde.stg_suburb
[0m12:28:59.439314 [info ] [Thread-3 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:28:59.439820 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_suburb)
[0m12:28:59.440101 [debug] [Thread-3 (]: Began compiling node model.bde.stg_suburb
[0m12:28:59.442130 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:28:59.442639 [debug] [Thread-3 (]: Timing info for model.bde.stg_suburb (compile): 12:28:59.440277 => 12:28:59.442528
[0m12:28:59.442875 [debug] [Thread-3 (]: Began executing node model.bde.stg_suburb
[0m12:28:59.446426 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:28:59.446842 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:28:59.447070 [debug] [Thread-3 (]: On model.bde.stg_suburb: BEGIN
[0m12:28:59.447282 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:28:59.484187 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:59.484529 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:28:59.484856 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:28:59.498263 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:59.500600 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:28:59.500871 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:28:59.511229 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.513356 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:28:59.513656 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:28:59.522765 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.524136 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:28:59.524424 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:28:59.524682 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:28:59.535180 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:59.537049 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:28:59.537330 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:28:59.548856 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:59.549863 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 12:28:59.367206 => 12:28:59.549734
[0m12:28:59.550179 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m12:28:59.550784 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061dd330>]}
[0m12:28:59.551267 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.19s]
[0m12:28:59.551736 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m12:28:59.552067 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m12:28:59.552505 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:28:59.553028 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.dim_LGA)
[0m12:28:59.553305 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m12:28:59.553598 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:59.556013 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:28:59.556355 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:28:59.556735 [debug] [Thread-3 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:28:59.557151 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 12:28:59.553845 => 12:28:59.557026
[0m12:28:59.557413 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m12:28:59.560144 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:28:59.560581 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:28:59.560834 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m12:28:59.561069 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:28:59.567409 [debug] [Thread-3 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:28:59.569637 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:28:59.569919 [debug] [Thread-3 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:28:59.578780 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.580754 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:28:59.581016 [debug] [Thread-3 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:28:59.590799 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.591948 [debug] [Thread-3 (]: On model.bde.stg_suburb: COMMIT
[0m12:28:59.592208 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:28:59.592447 [debug] [Thread-3 (]: On model.bde.stg_suburb: COMMIT
[0m12:28:59.602045 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:59.604024 [debug] [Thread-3 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:28:59.604302 [debug] [Thread-3 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:28:59.615879 [debug] [Thread-3 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:28:59.617005 [debug] [Thread-3 (]: Timing info for model.bde.stg_suburb (execute): 12:28:59.443045 => 12:28:59.616868
[0m12:28:59.617317 [debug] [Thread-3 (]: On model.bde.stg_suburb: Close
[0m12:28:59.617963 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11019eec0>]}
[0m12:28:59.618435 [info ] [Thread-3 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.18s]
[0m12:28:59.618889 [debug] [Thread-3 (]: Finished running node model.bde.stg_suburb
[0m12:28:59.619213 [debug] [Thread-3 (]: Began running node model.bde.fact_G01
[0m12:28:59.619674 [info ] [Thread-3 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:28:59.620155 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.fact_G01)
[0m12:28:59.620413 [debug] [Thread-3 (]: Began compiling node model.bde.fact_G01
[0m12:28:59.623887 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:28:59.624432 [debug] [Thread-3 (]: Timing info for model.bde.fact_G01 (compile): 12:28:59.620588 => 12:28:59.624311
[0m12:28:59.624686 [debug] [Thread-3 (]: Began executing node model.bde.fact_G01
[0m12:28:59.627324 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:28:59.627761 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_G01"
[0m12:28:59.628008 [debug] [Thread-3 (]: On model.bde.fact_G01: BEGIN
[0m12:28:59.628243 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:28:59.672909 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:59.673256 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:28:59.673552 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:28:59.692759 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:28:59.695652 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:28:59.695964 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:28:59.705394 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.707540 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:28:59.707845 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:28:59.716084 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.720307 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:28:59.720637 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:28:59.720914 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:28:59.729865 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:59.733528 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:28:59.733856 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:28:59.737139 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:59.737436 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_G01"
[0m12:28:59.737725 [debug] [Thread-3 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:28:59.751225 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:59.752436 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 12:28:59.557593 => 12:28:59.752283
[0m12:28:59.752770 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m12:28:59.753519 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061bf430>]}
[0m12:28:59.754056 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.20s]
[0m12:28:59.754560 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m12:28:59.754882 [debug] [Thread-4 (]: Began running node model.bde.fact_G02
[0m12:28:59.755284 [info ] [Thread-4 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:28:59.755800 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G02)
[0m12:28:59.756085 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G02
[0m12:28:59.758586 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:28:59.759195 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (compile): 12:28:59.756287 => 12:28:59.759057
[0m12:28:59.759486 [debug] [Thread-4 (]: Began executing node model.bde.fact_G02
[0m12:28:59.762548 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:28:59.763064 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:28:59.763339 [debug] [Thread-4 (]: On model.bde.fact_G02: BEGIN
[0m12:28:59.763593 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:28:59.765091 [debug] [Thread-3 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:28:59.767164 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_G01"
[0m12:28:59.767435 [debug] [Thread-3 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:28:59.776837 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.779792 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_G01"
[0m12:28:59.780056 [debug] [Thread-3 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:28:59.789464 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.790966 [debug] [Thread-3 (]: On model.bde.fact_G01: COMMIT
[0m12:28:59.791252 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_G01"
[0m12:28:59.791509 [debug] [Thread-3 (]: On model.bde.fact_G01: COMMIT
[0m12:28:59.801183 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:59.803117 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_G01"
[0m12:28:59.803413 [debug] [Thread-3 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:28:59.819378 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:59.820430 [debug] [Thread-3 (]: Timing info for model.bde.fact_G01 (execute): 12:28:59.624857 => 12:28:59.820295
[0m12:28:59.820725 [debug] [Thread-3 (]: On model.bde.fact_G01: Close
[0m12:28:59.821364 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062893f0>]}
[0m12:28:59.821836 [info ] [Thread-3 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.20s]
[0m12:28:59.822298 [debug] [Thread-3 (]: Finished running node model.bde.fact_G01
[0m12:28:59.822628 [debug] [Thread-3 (]: Began running node model.bde.fact_listing
[0m12:28:59.823045 [info ] [Thread-3 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:28:59.823623 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_listing)
[0m12:28:59.823945 [debug] [Thread-3 (]: Began compiling node model.bde.fact_listing
[0m12:28:59.826406 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:28:59.827002 [debug] [Thread-3 (]: Timing info for model.bde.fact_listing (compile): 12:28:59.824160 => 12:28:59.826859
[0m12:28:59.827295 [debug] [Thread-3 (]: Began executing node model.bde.fact_listing
[0m12:28:59.830349 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:28:59.830814 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_listing"
[0m12:28:59.831088 [debug] [Thread-3 (]: On model.bde.fact_listing: BEGIN
[0m12:28:59.831321 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:28:59.875689 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:59.876079 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:28:59.876421 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:28:59.893628 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:28:59.896565 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:28:59.896911 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:28:59.905999 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.908558 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:28:59.908922 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:28:59.917097 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:59.918713 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:28:59.919034 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:28:59.919329 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:28:59.940545 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:59.943133 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:28:59.943534 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:59.943975 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:28:59.944411 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_listing"
[0m12:28:59.944922 [debug] [Thread-3 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:28:59.980475 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:59.983453 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (execute): 12:28:59.759686 => 12:28:59.983155
[0m12:28:59.984200 [debug] [Thread-4 (]: On model.bde.fact_G02: Close
[0m12:28:59.985903 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106171b10>]}
[0m12:28:59.986799 [info ] [Thread-4 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.23s]
[0m12:28:59.987656 [debug] [Thread-4 (]: Finished running node model.bde.fact_G02
[0m12:28:59.988220 [debug] [Thread-4 (]: Began running node model.bde.dim_host
[0m12:28:59.988882 [info ] [Thread-4 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:28:59.989821 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m12:28:59.990309 [debug] [Thread-4 (]: Began compiling node model.bde.dim_host
[0m12:28:59.993895 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:28:59.994767 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (compile): 12:28:59.990609 => 12:28:59.994557
[0m12:28:59.995159 [debug] [Thread-4 (]: Began executing node model.bde.dim_host
[0m12:29:00.000415 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:29:00.001025 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:29:00.001339 [debug] [Thread-4 (]: On model.bde.dim_host: BEGIN
[0m12:29:00.001632 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:29:00.113777 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:29:00.116113 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:29:00.117319 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    scraped_date,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:29:00.762026 [debug] [Thread-1 (]: SQL status: SELECT 217 in 2.0 seconds
[0m12:29:00.771351 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:29:00.772257 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m12:29:00.783302 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:00.787169 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:29:00.787569 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m12:29:00.796504 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:00.798759 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:29:00.799148 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:29:00.799510 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:29:00.820620 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:29:00.825995 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:29:00.826597 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m12:29:00.848551 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:29:00.853050 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:28:58.677914 => 12:29:00.852486
[0m12:29:00.854253 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:29:00.856218 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106130a60>]}
[0m12:29:00.857672 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 217[0m in 2.20s]
[0m12:29:00.858944 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:29:00.859456 [debug] [Thread-1 (]: Began running node model.bde.dim_property
[0m12:29:00.860050 [info ] [Thread-1 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:29:00.860793 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.dim_property)
[0m12:29:00.861122 [debug] [Thread-1 (]: Began compiling node model.bde.dim_property
[0m12:29:00.864276 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:29:00.865078 [debug] [Thread-1 (]: Timing info for model.bde.dim_property (compile): 12:29:00.861337 => 12:29:00.864932
[0m12:29:00.865366 [debug] [Thread-1 (]: Began executing node model.bde.dim_property
[0m12:29:00.868604 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:29:00.869107 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_property"
[0m12:29:00.869360 [debug] [Thread-1 (]: On model.bde.dim_property: BEGIN
[0m12:29:00.869599 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:29:01.099438 [debug] [Thread-4 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m12:29:01.103609 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:29:01.104069 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:29:01.210635 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:29:01.211006 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_property"
[0m12:29:01.211267 [debug] [Thread-1 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:29:01.662664 [debug] [Thread-1 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:29:01.670097 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_property"
[0m12:29:01.670617 [debug] [Thread-1 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:29:02.561490 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m12:29:02.571510 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:29:02.572408 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:29:02.581666 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:02.585708 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:29:02.586146 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:29:02.595791 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:02.597757 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:29:02.598166 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:29:02.598528 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:29:02.628690 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 2.0 seconds
[0m12:29:02.634138 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:29:02.634762 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:29:02.638144 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:29:02.641359 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:29:02.641757 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:29:02.649677 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 1.0 seconds
[0m12:29:02.653150 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_property"
[0m12:29:02.653548 [debug] [Thread-1 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:29:02.656399 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:02.658416 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:29:02.658861 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:29:02.659251 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:29:02.662744 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:02.664831 [debug] [Thread-1 (]: On model.bde.dim_property: COMMIT
[0m12:29:02.665207 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_property"
[0m12:29:02.665561 [debug] [Thread-1 (]: On model.bde.dim_property: COMMIT
[0m12:29:02.670983 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:29:02.671411 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:29:02.673145 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:28:58.715414 => 12:29:02.672904
[0m12:29:02.675971 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:29:02.676431 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:29:02.676816 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:29:02.677294 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:29:02.678008 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061d8700>]}
[0m12:29:02.680315 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_property"
[0m12:29:02.680740 [debug] [Thread-1 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:29:02.681303 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 4.02s]
[0m12:29:02.681971 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:29:02.682372 [debug] [Thread-2 (]: Began running node model.bde.dim_room
[0m12:29:02.682835 [info ] [Thread-2 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:29:02.683474 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_room)
[0m12:29:02.683806 [debug] [Thread-2 (]: Began compiling node model.bde.dim_room
[0m12:29:02.686676 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:29:02.689176 [debug] [Thread-2 (]: Timing info for model.bde.dim_room (compile): 12:29:02.684032 => 12:29:02.689040
[0m12:29:02.689477 [debug] [Thread-2 (]: Began executing node model.bde.dim_room
[0m12:29:02.693695 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:29:02.694217 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:29:02.694460 [debug] [Thread-2 (]: On model.bde.dim_room: BEGIN
[0m12:29:02.694707 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:29:02.701999 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:29:02.703087 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (execute): 12:28:59.995437 => 12:29:02.702969
[0m12:29:02.703392 [debug] [Thread-4 (]: On model.bde.dim_host: Close
[0m12:29:02.704084 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101284c0>]}
[0m12:29:02.704504 [info ] [Thread-4 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 2.71s]
[0m12:29:02.704917 [debug] [Thread-4 (]: Finished running node model.bde.dim_host
[0m12:29:02.705209 [debug] [Thread-4 (]: Began running node model.bde.dim_suburb
[0m12:29:02.705733 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:29:02.705531 [info ] [Thread-4 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:29:02.706734 [debug] [Thread-1 (]: Timing info for model.bde.dim_property (execute): 12:29:00.865568 => 12:29:02.706621
[0m12:29:02.707153 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_host, now model.bde.dim_suburb)
[0m12:29:02.707429 [debug] [Thread-1 (]: On model.bde.dim_property: Close
[0m12:29:02.707734 [debug] [Thread-4 (]: Began compiling node model.bde.dim_suburb
[0m12:29:02.709880 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:29:02.710300 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101a6e30>]}
[0m12:29:02.710739 [info ] [Thread-1 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 1.85s]
[0m12:29:02.711198 [debug] [Thread-1 (]: Finished running node model.bde.dim_property
[0m12:29:02.711608 [debug] [Thread-4 (]: Timing info for model.bde.dim_suburb (compile): 12:29:02.707998 => 12:29:02.711471
[0m12:29:02.711879 [debug] [Thread-4 (]: Began executing node model.bde.dim_suburb
[0m12:29:02.714559 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:29:02.715021 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:29:02.715257 [debug] [Thread-4 (]: On model.bde.dim_suburb: BEGIN
[0m12:29:02.715478 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:29:02.809729 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:29:02.810181 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:29:02.810505 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:29:02.824441 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:29:02.824791 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:29:02.825112 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:29:02.864608 [debug] [Thread-4 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:29:02.868716 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:29:02.869150 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:29:02.878766 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:02.882410 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:29:02.882921 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:29:02.892829 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:02.895125 [debug] [Thread-4 (]: On model.bde.dim_suburb: COMMIT
[0m12:29:02.895520 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:29:02.895862 [debug] [Thread-4 (]: On model.bde.dim_suburb: COMMIT
[0m12:29:02.913875 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:29:02.917295 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:29:02.917778 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:29:02.938492 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:29:02.940046 [debug] [Thread-4 (]: Timing info for model.bde.dim_suburb (execute): 12:29:02.712058 => 12:29:02.939878
[0m12:29:02.940421 [debug] [Thread-4 (]: On model.bde.dim_suburb: Close
[0m12:29:02.941260 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061e5a80>]}
[0m12:29:02.941843 [info ] [Thread-4 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.23s]
[0m12:29:02.942392 [debug] [Thread-4 (]: Finished running node model.bde.dim_suburb
[0m12:29:03.078320 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:29:03.086410 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:29:03.087056 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:29:03.096753 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:03.101556 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:29:03.102196 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:29:03.115469 [debug] [Thread-3 (]: SQL status: SELECT 340945 in 3.0 seconds
[0m12:29:03.116186 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:03.121618 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_listing"
[0m12:29:03.124148 [debug] [Thread-2 (]: On model.bde.dim_room: COMMIT
[0m12:29:03.124639 [debug] [Thread-3 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:29:03.125022 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:29:03.125540 [debug] [Thread-2 (]: On model.bde.dim_room: COMMIT
[0m12:29:03.137066 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:03.143147 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_listing"
[0m12:29:03.143562 [debug] [Thread-3 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:29:03.150363 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:29:03.153417 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m12:29:03.153802 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:03.154218 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:29:03.156141 [debug] [Thread-3 (]: On model.bde.fact_listing: COMMIT
[0m12:29:03.156729 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_listing"
[0m12:29:03.157178 [debug] [Thread-3 (]: On model.bde.fact_listing: COMMIT
[0m12:29:03.168171 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:29:03.170915 [debug] [Thread-3 (]: Using postgres connection "model.bde.fact_listing"
[0m12:29:03.171323 [debug] [Thread-3 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:29:03.173048 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:29:03.174301 [debug] [Thread-2 (]: Timing info for model.bde.dim_room (execute): 12:29:02.689672 => 12:29:03.174139
[0m12:29:03.174665 [debug] [Thread-2 (]: On model.bde.dim_room: Close
[0m12:29:03.175463 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102bf9a0>]}
[0m12:29:03.176037 [info ] [Thread-2 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.49s]
[0m12:29:03.176576 [debug] [Thread-2 (]: Finished running node model.bde.dim_room
[0m12:29:03.201454 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:29:03.202885 [debug] [Thread-3 (]: Timing info for model.bde.fact_listing (execute): 12:28:59.827500 => 12:29:03.202729
[0m12:29:03.203268 [debug] [Thread-3 (]: On model.bde.fact_listing: Close
[0m12:29:03.204120 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a552448-4c0e-459a-8856-fce5bbeb9a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102beb00>]}
[0m12:29:03.204669 [info ] [Thread-3 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 3.38s]
[0m12:29:03.205200 [debug] [Thread-3 (]: Finished running node model.bde.fact_listing
[0m12:29:03.206731 [debug] [MainThread]: Using postgres connection "master"
[0m12:29:03.207008 [debug] [MainThread]: On master: BEGIN
[0m12:29:03.207241 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:29:03.305928 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:29:03.306347 [debug] [MainThread]: On master: COMMIT
[0m12:29:03.306587 [debug] [MainThread]: Using postgres connection "master"
[0m12:29:03.306823 [debug] [MainThread]: On master: COMMIT
[0m12:29:03.319709 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:29:03.319993 [debug] [MainThread]: On master: Close
[0m12:29:03.320622 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:29:03.320891 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m12:29:03.321103 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:29:03.321319 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:29:03.321518 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:29:03.321843 [info ] [MainThread]: 
[0m12:29:03.322131 [info ] [MainThread]: Finished running 11 table models, 8 view models in 0 hours 0 minutes and 5.42 seconds (5.42s).
[0m12:29:03.324332 [debug] [MainThread]: Command end result
[0m12:29:03.332845 [info ] [MainThread]: 
[0m12:29:03.333207 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m12:29:03.333445 [info ] [MainThread]: 
[0m12:29:03.333670 [error] [MainThread]:   Database Error in model dm_property_type (models/datamart/dm_property_type.sql)
  syntax error at or near "AS"
  LINE 96:     ) AS avg_estimated_revenue_per_active_listing
                 ^
  compiled Code at target/run/bde/models/datamart/dm_property_type.sql
[0m12:29:03.333906 [info ] [MainThread]: 
[0m12:29:03.334129 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m12:29:03.334582 [debug] [MainThread]: Command `dbt run` failed at 12:29:03.334526 after 5.55 seconds
[0m12:29:03.334848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1036ac250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110207040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11027d900>]}
[0m12:29:03.335105 [debug] [MainThread]: Flushing usage events
[0m12:29:57.078416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051315d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11214da80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11214d3c0>]}


============================== 12:29:57.081001 | 07b818f1-438e-4307-80fa-cdb220153777 ==============================
[0m12:29:57.081001 [info ] [MainThread]: Running with dbt=1.6.6
[0m12:29:57.081332 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:29:57.135691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11214d5d0>]}
[0m12:29:57.143184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112545120>]}
[0m12:29:57.143531 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m12:29:57.152040 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m12:29:57.177380 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:29:57.177730 [debug] [MainThread]: Partial parsing: updated file: bde://models/datamart/dm_property_type.sql
[0m12:29:57.198058 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.raw
- models.bde.median
[0m12:29:57.200922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b9cbe0>]}
[0m12:29:57.208033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129b2c80>]}
[0m12:29:57.208275 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m12:29:57.208457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129b2e90>]}
[0m12:29:57.209642 [info ] [MainThread]: 
[0m12:29:57.210002 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:29:57.210831 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:29:57.211232 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:29:57.216181 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:29:57.216590 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:29:57.217643 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:29:57.217839 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:29:57.218743 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:29:57.218937 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:29:57.219145 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:29:57.219293 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:29:57.219428 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:29:57.220261 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:29:57.422312 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:29:57.423871 [debug] [ThreadPool]: On list_postgres: Close
[0m12:29:57.431490 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:29:57.431796 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:29:57.432668 [debug] [ThreadPool]: On list_postgres: Close
[0m12:29:57.433498 [debug] [ThreadPool]: On list_postgres: Close
[0m12:29:57.435882 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m12:29:57.436484 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m12:29:57.437066 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_staging)
[0m12:29:57.442132 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:29:57.442672 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_warehouse'
[0m12:29:57.444183 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:29:57.445594 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:29:57.445852 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m12:29:57.447038 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:29:57.447255 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m12:29:57.447449 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m12:29:57.447637 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:29:57.447828 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m12:29:57.448013 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:29:57.448194 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:29:57.448493 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:29:57.548260 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:29:57.548672 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:29:57.548976 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m12:29:57.554091 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:29:57.554355 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:29:57.554630 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m12:29:57.556884 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:29:57.557151 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:29:57.557447 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m12:29:57.560546 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:29:57.560803 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:29:57.561126 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m12:29:57.563696 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:29:57.565008 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m12:29:57.569961 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:29:57.571033 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m12:29:57.571455 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:29:57.572458 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m12:29:57.574267 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m12:29:57.576063 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:29:57.577155 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m12:29:57.579199 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m12:29:57.582242 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m12:29:57.586121 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m12:29:57.591814 [debug] [MainThread]: Using postgres connection "master"
[0m12:29:57.592104 [debug] [MainThread]: On master: BEGIN
[0m12:29:57.592347 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:29:57.830680 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:29:57.831441 [debug] [MainThread]: Using postgres connection "master"
[0m12:29:57.831951 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:29:57.858832 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:29:57.863521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ae3e80>]}
[0m12:29:57.864293 [debug] [MainThread]: On master: ROLLBACK
[0m12:29:57.873781 [debug] [MainThread]: Using postgres connection "master"
[0m12:29:57.874168 [debug] [MainThread]: On master: BEGIN
[0m12:29:57.893384 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:29:57.894532 [debug] [MainThread]: On master: COMMIT
[0m12:29:57.895179 [debug] [MainThread]: Using postgres connection "master"
[0m12:29:57.895701 [debug] [MainThread]: On master: COMMIT
[0m12:29:57.906693 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:29:57.907806 [debug] [MainThread]: On master: Close
[0m12:29:57.910358 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:29:57.911369 [info ] [MainThread]: 
[0m12:29:57.916523 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m12:29:57.917072 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m12:29:57.917482 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m12:29:57.917891 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m12:29:57.918476 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m12:29:57.918966 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m12:29:57.919445 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m12:29:57.919893 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m12:29:57.920595 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_host_neighbourhod)
[0m12:29:57.921116 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_listing_neighbourhood)
[0m12:29:57.921567 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.dm_property_type)
[0m12:29:57.922004 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.stg_G01)
[0m12:29:57.922306 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m12:29:57.922581 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m12:29:57.922850 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m12:29:57.923116 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m12:29:57.929792 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m12:29:57.931927 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m12:29:57.935193 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m12:29:57.937542 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m12:29:57.938853 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 12:29:57.923339 => 12:29:57.938697
[0m12:29:57.939448 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m12:29:57.952888 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 12:29:57.935433 => 12:29:57.952729
[0m12:29:57.953164 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 12:29:57.932137 => 12:29:57.953054
[0m12:29:57.964055 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m12:29:57.964317 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 12:29:57.929996 => 12:29:57.964210
[0m12:29:57.964556 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m12:29:57.964791 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m12:29:57.965055 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m12:29:57.971599 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:29:57.975342 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m12:29:57.977364 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m12:29:57.979358 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m12:29:57.979563 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m12:29:57.980045 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:29:57.980247 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:29:57.980463 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:29:57.980751 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:29:57.980969 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m12:29:57.981165 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m12:29:57.981356 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m12:29:57.981527 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:29:57.981699 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:29:57.981887 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:29:58.079123 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:29:58.079480 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:29:58.079838 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM 
        warehouse.dim_host host
    LEFT JOIN 
        warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
distinct_host_count AS (
    SELECT
        TO_CHAR(h.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        COUNT(DISTINCT h.host_id) AS num_distinct_hosts
    FROM
        host_neighbourhood_lga_transform h
    GROUP BY
        TO_CHAR(h.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
),
estimated_revenue AS (
    SELECT
        TO_CHAR(l.scraped_date, 'MM/YYYY') AS month_year,
        h.host_neighbourhood_lga,
        SUM((30 - l.availability_30) * l.price) AS total_estimated_revenue
    FROM
        warehouse.fact_listing l
    LEFT JOIN
        host_neighbourhood_lga_transform h ON l.surrogate_key_host = h.surrogate_key_host
    WHERE
        l.has_availability = 't'
    GROUP BY
        TO_CHAR(l.scraped_date, 'MM/YYYY'),
        h.host_neighbourhood_lga
)
SELECT
    dhct.month_year,
    dhct.host_neighbourhood_lga,
    dhct.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dhct.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dhct.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM
    distinct_host_count dhct
LEFT JOIN
    estimated_revenue er ON dhct.month_year = er.month_year AND dhct.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY
    dhct.month_year, dhct.host_neighbourhood_lga
  );
  
[0m12:29:58.083004 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:29:58.083294 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:29:58.083754 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:29:58.086734 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:29:58.087026 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:29:58.087370 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:29:58.087665 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:29:58.088241 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type

-- Set the configuration for the materialized view



-- Create a Common Table Expression (CTE) called sorted_listing
-- This CTE retrieves data from multiple tables and calculates various metrics
-- It includes property_type, room_type, accommodates, and more.


WITH sorted_listing AS (
    SELECT 
        prop.property_type,-- Property type
        room.room_type,-- Room type
        list.accommodates,-- Accommodates
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year, -- Truncate the date to the month
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id, -- Host ID
        host.host_is_superhost,-- Host is superhost flag
        review_scores_rating,-- Review scores rating
        availability_30-- Availability for the next 30 days
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
-- Select the aggregated metrics for the property_type, room_type, accommodates, and month_year
SELECT 
    property_type,-- Property type
    room_type,-- Room type
    accommodates,-- Number of accommodates
    month_year,-- Truncated month and year
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,-- Calculate the minimum price for active listings
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,-- Calculate the maximum price for active listings
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing, -- Calculate the median price for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts, -- Count the number of distinct hosts
     -- Calculate the superhost rate
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
     -- Calculate the average review scores rating for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


     -- Calculate the percentage change for active listing
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing

    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:29:58.089058 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,     
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m12:29:58.105379 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:29:58.111572 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:29:58.111899 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:29:58.126852 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:58.129134 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:29:58.129462 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:29:58.142095 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:58.153875 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:29:58.154170 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:29:58.154403 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:29:58.166703 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:29:58.172089 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:29:58.172363 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:29:58.185614 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:29:58.186646 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:29:57.965213 => 12:29:58.186520
[0m12:29:58.186934 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:29:58.187602 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ae2920>]}
[0m12:29:58.188055 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.27s]
[0m12:29:58.188494 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:29:58.188808 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m12:29:58.189218 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:29:58.189730 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m12:29:58.189993 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m12:29:58.192168 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:29:58.193662 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 12:29:58.190163 => 12:29:58.193533
[0m12:29:58.193904 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m12:29:58.196561 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:29:58.196998 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:29:58.197233 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m12:29:58.197440 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:29:58.310733 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:29:58.311272 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:29:58.311785 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:29:58.327147 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:29:58.330743 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:29:58.331160 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:29:58.341334 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:58.344280 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:29:58.344697 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:29:58.354134 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:58.356010 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:29:58.356390 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:29:58.356744 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:29:58.366802 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:29:58.371494 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:29:58.371898 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:29:58.384053 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:29:58.385382 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 12:29:58.194067 => 12:29:58.385205
[0m12:29:58.385767 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m12:29:58.386638 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112beca30>]}
[0m12:29:58.387260 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.20s]
[0m12:29:58.387867 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m12:29:58.388309 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m12:29:58.388899 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:29:58.389628 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m12:29:58.390038 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m12:29:58.393583 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:29:58.395802 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 12:29:58.390314 => 12:29:58.395650
[0m12:29:58.396120 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m12:29:58.399768 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:29:58.400399 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:29:58.400715 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m12:29:58.401006 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:29:58.510171 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:29:58.511580 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:29:58.512284 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:29:58.527669 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:29:58.534716 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:29:58.535362 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:29:58.546087 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:58.549978 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:29:58.550413 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:29:58.559577 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:58.561834 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:29:58.562301 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:29:58.562720 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:29:58.572352 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:29:58.575303 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:29:58.575712 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:29:58.586396 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:29:58.588135 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 12:29:58.396343 => 12:29:58.587921
[0m12:29:58.588644 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m12:29:58.589697 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114053520>]}
[0m12:29:58.590490 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.20s]
[0m12:29:58.591143 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m12:29:58.591582 [debug] [Thread-4 (]: Began running node model.bde.stg_fact
[0m12:29:58.592237 [info ] [Thread-4 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:29:58.592978 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_fact)
[0m12:29:58.593409 [debug] [Thread-4 (]: Began compiling node model.bde.stg_fact
[0m12:29:58.597022 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:29:58.599254 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (compile): 12:29:58.593689 => 12:29:58.599076
[0m12:29:58.599594 [debug] [Thread-4 (]: Began executing node model.bde.stg_fact
[0m12:29:58.603301 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:29:58.603970 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:29:58.604292 [debug] [Thread-4 (]: On model.bde.stg_fact: BEGIN
[0m12:29:58.604575 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:29:58.719789 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:29:58.720802 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:29:58.721503 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:29:58.955571 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:29:58.958416 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:29:58.958725 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:29:58.977636 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:59.004636 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:29:59.005005 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:29:59.017508 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:59.018618 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:29:59.018861 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:29:59.019093 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:29:59.029374 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:29:59.031075 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:29:59.031340 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:29:59.045924 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:29:59.046839 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (execute): 12:29:58.599813 => 12:29:59.046717
[0m12:29:59.047114 [debug] [Thread-4 (]: On model.bde.stg_fact: Close
[0m12:29:59.047733 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114097e50>]}
[0m12:29:59.048164 [info ] [Thread-4 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.46s]
[0m12:29:59.048584 [debug] [Thread-4 (]: Finished running node model.bde.stg_fact
[0m12:29:59.048874 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m12:29:59.049165 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:29:59.049844 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_host)
[0m12:29:59.050161 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m12:29:59.052562 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:29:59.054525 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 12:29:59.050358 => 12:29:59.054404
[0m12:29:59.055116 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m12:29:59.058094 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:29:59.058687 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:29:59.058951 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m12:29:59.059174 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:29:59.170919 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:29:59.171488 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:29:59.172075 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:29:59.191963 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:29:59.196506 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:29:59.197010 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:29:59.207008 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:59.210528 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:29:59.211017 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:29:59.224723 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:59.226754 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:29:59.227213 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:29:59.227633 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:29:59.238483 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:29:59.241769 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:29:59.242228 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:29:59.255090 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:29:59.256776 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 12:29:59.055366 => 12:29:59.256556
[0m12:29:59.257254 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m12:29:59.258314 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140a4af0>]}
[0m12:29:59.259089 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.21s]
[0m12:29:59.259847 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m12:29:59.260404 [debug] [Thread-4 (]: Began running node model.bde.stg_property
[0m12:29:59.261184 [info ] [Thread-4 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:29:59.262057 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_property)
[0m12:29:59.262498 [debug] [Thread-4 (]: Began compiling node model.bde.stg_property
[0m12:29:59.266248 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:29:59.268209 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (compile): 12:29:59.262794 => 12:29:59.267912
[0m12:29:59.268736 [debug] [Thread-4 (]: Began executing node model.bde.stg_property
[0m12:29:59.274674 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:29:59.275284 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:29:59.275623 [debug] [Thread-4 (]: On model.bde.stg_property: BEGIN
[0m12:29:59.275924 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:29:59.389362 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:29:59.390051 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:29:59.390681 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:29:59.405760 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:29:59.413404 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:29:59.413951 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:29:59.424345 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:59.428024 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:29:59.428436 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:29:59.437868 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:59.439892 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:29:59.440393 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:29:59.440819 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:29:59.451338 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:29:59.454446 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:29:59.454909 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:29:59.468516 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:29:59.470159 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (execute): 12:29:59.269019 => 12:29:59.469939
[0m12:29:59.470637 [debug] [Thread-4 (]: On model.bde.stg_property: Close
[0m12:29:59.471705 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bb95a0>]}
[0m12:29:59.472511 [info ] [Thread-4 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.21s]
[0m12:29:59.473255 [debug] [Thread-4 (]: Finished running node model.bde.stg_property
[0m12:29:59.473805 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m12:29:59.474607 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:29:59.475459 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_room)
[0m12:29:59.475867 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m12:29:59.479361 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:29:59.481155 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 12:29:59.476154 => 12:29:59.480997
[0m12:29:59.481479 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m12:29:59.485106 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:29:59.485858 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:29:59.486203 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m12:29:59.486509 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:29:59.597978 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:29:59.599379 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:29:59.600152 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:29:59.614154 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:29:59.622560 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:29:59.623214 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:29:59.633224 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:59.636916 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:29:59.637329 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:29:59.646930 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:59.648627 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:29:59.649010 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:29:59.649364 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:29:59.660572 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:29:59.663602 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:29:59.663987 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:29:59.675436 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:29:59.679278 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 12:29:59.481700 => 12:29:59.679097
[0m12:29:59.679663 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m12:29:59.680540 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b211b0>]}
[0m12:29:59.681175 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.21s]
[0m12:29:59.681785 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m12:29:59.682237 [debug] [Thread-4 (]: Began running node model.bde.stg_suburb
[0m12:29:59.683085 [info ] [Thread-4 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:29:59.684373 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.stg_suburb)
[0m12:29:59.684897 [debug] [Thread-4 (]: Began compiling node model.bde.stg_suburb
[0m12:29:59.688056 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:29:59.688761 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (compile): 12:29:59.685199 => 12:29:59.688595
[0m12:29:59.689101 [debug] [Thread-4 (]: Began executing node model.bde.stg_suburb
[0m12:29:59.692716 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:29:59.693295 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:29:59.693629 [debug] [Thread-4 (]: On model.bde.stg_suburb: BEGIN
[0m12:29:59.693931 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:29:59.806019 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:29:59.807204 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:29:59.807898 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:29:59.819739 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:29:59.827959 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:29:59.828599 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:29:59.838420 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:59.843640 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:29:59.844167 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:29:59.858537 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:59.861914 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m12:29:59.862470 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:29:59.862909 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m12:29:59.877377 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:29:59.882407 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:29:59.882984 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:29:59.894296 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:29:59.896300 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (execute): 12:29:59.689335 => 12:29:59.896060
[0m12:29:59.896830 [debug] [Thread-4 (]: On model.bde.stg_suburb: Close
[0m12:29:59.898021 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124eff70>]}
[0m12:29:59.898719 [info ] [Thread-4 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.21s]
[0m12:29:59.899373 [debug] [Thread-4 (]: Finished running node model.bde.stg_suburb
[0m12:29:59.899865 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m12:29:59.900548 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:29:59.901669 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.dim_LGA)
[0m12:29:59.902312 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m12:29:59.905898 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:29:59.908298 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 12:29:59.902619 => 12:29:59.908021
[0m12:29:59.908788 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m12:29:59.913081 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:29:59.913739 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:29:59.914043 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m12:29:59.914305 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:29:59.994114 [debug] [Thread-1 (]: SQL status: SELECT 217 in 2.0 seconds
[0m12:29:59.998652 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:29:59.999115 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m12:30:00.008922 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:00.014035 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:30:00.014479 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m12:30:00.024530 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:00.027530 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:30:00.027818 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:30:00.028113 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:30:00.033238 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:30:00.033728 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:30:00.034094 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:30:00.039858 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:30:00.044786 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:30:00.045223 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m12:30:00.064802 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:30:00.067811 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:30:00.068182 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:30:00.076894 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:30:00.078178 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:29:57.939678 => 12:30:00.078002
[0m12:30:00.078560 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:30:00.079417 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114026260>]}
[0m12:30:00.080002 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 217[0m in 2.16s]
[0m12:30:00.080556 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:30:00.081049 [debug] [Thread-1 (]: Began running node model.bde.fact_G01
[0m12:30:00.081906 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:00.081622 [info ] [Thread-1 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:30:00.084761 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:30:00.085360 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.fact_G01)
[0m12:30:00.085719 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:30:00.086141 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G01
[0m12:30:00.089321 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:30:00.090327 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (compile): 12:30:00.086477 => 12:30:00.090171
[0m12:30:00.090647 [debug] [Thread-1 (]: Began executing node model.bde.fact_G01
[0m12:30:00.093865 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:30:00.094400 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:30:00.094689 [debug] [Thread-1 (]: On model.bde.fact_G01: BEGIN
[0m12:30:00.094963 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:30:00.095595 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:00.097186 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:30:00.097482 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:30:00.097745 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:30:00.109001 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:30:00.110902 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:30:00.111189 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:30:00.126014 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:30:00.127287 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 12:29:59.909064 => 12:30:00.127146
[0m12:30:00.127609 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m12:30:00.128313 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bec880>]}
[0m12:30:00.128818 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.23s]
[0m12:30:00.129282 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m12:30:00.129624 [debug] [Thread-4 (]: Began running node model.bde.fact_G02
[0m12:30:00.130050 [info ] [Thread-4 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:30:00.130588 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G02)
[0m12:30:00.130868 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G02
[0m12:30:00.133806 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:30:00.134536 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (compile): 12:30:00.131155 => 12:30:00.134381
[0m12:30:00.134855 [debug] [Thread-4 (]: Began executing node model.bde.fact_G02
[0m12:30:00.138897 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:30:00.139333 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:30:00.139562 [debug] [Thread-4 (]: On model.bde.fact_G02: BEGIN
[0m12:30:00.139784 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:30:00.217013 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:30:00.217519 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:30:00.217917 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:30:00.246654 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:30:00.250345 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:30:00.250772 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:30:00.263121 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:00.266657 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:30:00.267074 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:30:00.267539 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:30:00.267943 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:30:00.268541 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:30:00.279962 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:00.281960 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:30:00.282347 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:30:00.282709 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:30:00.289734 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:30:00.293005 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:30:00.293392 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:30:00.293791 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:30:00.296722 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:30:00.297240 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:30:00.306681 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:00.309570 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:30:00.309980 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:30:00.312463 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:30:00.313811 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (execute): 12:30:00.090849 => 12:30:00.313611
[0m12:30:00.314242 [debug] [Thread-1 (]: On model.bde.fact_G01: Close
[0m12:30:00.315083 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124cabf0>]}
[0m12:30:00.315653 [info ] [Thread-1 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.23s]
[0m12:30:00.316222 [debug] [Thread-1 (]: Finished running node model.bde.fact_G01
[0m12:30:00.316638 [debug] [Thread-1 (]: Began running node model.bde.fact_listing
[0m12:30:00.317026 [info ] [Thread-1 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:30:00.317705 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_listing)
[0m12:30:00.318061 [debug] [Thread-1 (]: Began compiling node model.bde.fact_listing
[0m12:30:00.321246 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:30:00.321582 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:00.323222 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:30:00.323564 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:30:00.323862 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:30:00.324183 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (compile): 12:30:00.318304 => 12:30:00.324055
[0m12:30:00.324539 [debug] [Thread-1 (]: Began executing node model.bde.fact_listing
[0m12:30:00.327875 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:30:00.328385 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:30:00.328669 [debug] [Thread-1 (]: On model.bde.fact_listing: BEGIN
[0m12:30:00.328941 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:30:00.334496 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:30:00.337588 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:30:00.337870 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:30:00.352129 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:30:00.353411 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (execute): 12:30:00.135048 => 12:30:00.353261
[0m12:30:00.353714 [debug] [Thread-4 (]: On model.bde.fact_G02: Close
[0m12:30:00.354296 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140612d0>]}
[0m12:30:00.354691 [info ] [Thread-4 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.22s]
[0m12:30:00.355095 [debug] [Thread-4 (]: Finished running node model.bde.fact_G02
[0m12:30:00.355384 [debug] [Thread-4 (]: Began running node model.bde.dim_host
[0m12:30:00.355722 [info ] [Thread-4 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:30:00.356186 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m12:30:00.356440 [debug] [Thread-4 (]: Began compiling node model.bde.dim_host
[0m12:30:00.358581 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:30:00.359265 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (compile): 12:30:00.356618 => 12:30:00.359151
[0m12:30:00.359507 [debug] [Thread-4 (]: Began executing node model.bde.dim_host
[0m12:30:00.362370 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:30:00.362906 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:30:00.363136 [debug] [Thread-4 (]: On model.bde.dim_host: BEGIN
[0m12:30:00.363355 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:30:00.439043 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:30:00.439500 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:30:00.439785 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:30:00.468220 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:30:00.468508 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:30:00.468777 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    scraped_date,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:30:01.280676 [debug] [Thread-4 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m12:30:01.287841 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:30:01.288507 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:30:03.226349 [debug] [Thread-2 (]: SQL status: SELECT 296 in 5.0 seconds
[0m12:30:03.236964 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:30:03.237549 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:30:03.247956 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:03.251000 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:30:03.251336 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:30:03.260611 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:03.262345 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:30:03.262705 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:30:03.263016 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:30:03.285857 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:30:03.288174 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:30:03.288533 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:30:03.307557 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:30:03.309001 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:29:57.977545 => 12:30:03.308783
[0m12:30:03.309427 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:30:03.310424 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c73c10>]}
[0m12:30:03.311114 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 5.39s]
[0m12:30:03.311760 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:30:03.312215 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m12:30:03.312833 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:30:03.313546 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m12:30:03.313914 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m12:30:03.317238 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:30:03.319107 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 12:30:03.314160 => 12:30:03.318924
[0m12:30:03.319492 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m12:30:03.324091 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:30:03.324641 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:30:03.324934 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m12:30:03.325199 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:30:03.431133 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:30:03.431870 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:30:03.432326 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:30:03.944509 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 6.0 seconds
[0m12:30:03.952668 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:30:03.953418 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m12:30:03.954162 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m12:30:03.957734 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:30:03.958274 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:30:03.968796 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:03.971581 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:30:03.971939 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m12:30:03.978986 [debug] [Thread-1 (]: SQL status: SELECT 340945 in 4.0 seconds
[0m12:30:03.982079 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:30:03.982406 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:03.982770 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:30:03.984496 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:30:03.984941 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:30:03.985265 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:30:04.006661 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 3.0 seconds
[0m12:30:04.009607 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:30:04.009975 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:04.010362 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:30:04.013247 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:30:04.013667 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:30:04.021415 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:30:04.023948 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:30:04.024261 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:04.024589 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:04.024865 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:04.025161 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m12:30:04.028916 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:30:04.030354 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:30:04.031735 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:30:04.032129 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:30:04.032443 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:30:04.032714 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:30:04.033032 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:30:04.033320 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:30:04.043122 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:04.044423 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:30:04.044699 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:30:04.044951 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:30:04.046414 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:30:04.048362 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:30:04.048661 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:30:04.049216 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:30:04.051074 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:30:04.051357 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:30:04.051741 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:30:04.052775 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:29:57.975525 => 12:30:04.052627
[0m12:30:04.053087 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:30:04.053815 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140f7940>]}
[0m12:30:04.054272 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 6.13s]
[0m12:30:04.054736 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:30:04.055052 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m12:30:04.055436 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:30:04.055952 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m12:30:04.056239 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m12:30:04.058737 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:30:04.059526 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 12:30:04.056432 => 12:30:04.059404
[0m12:30:04.060001 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m12:30:04.063098 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:30:04.063382 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:30:04.065475 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:30:04.065777 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:30:04.066117 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:30:04.066382 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m12:30:04.066621 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:30:04.081899 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:30:04.082977 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (execute): 12:30:00.359682 => 12:30:04.082855
[0m12:30:04.083273 [debug] [Thread-4 (]: On model.bde.dim_host: Close
[0m12:30:04.083877 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114104040>]}
[0m12:30:04.084329 [info ] [Thread-4 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 3.73s]
[0m12:30:04.084760 [debug] [Thread-4 (]: Finished running node model.bde.dim_host
[0m12:30:04.085081 [debug] [Thread-4 (]: Began running node model.bde.dim_suburb
[0m12:30:04.085445 [info ] [Thread-4 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:30:04.085919 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_host, now model.bde.dim_suburb)
[0m12:30:04.086167 [debug] [Thread-4 (]: Began compiling node model.bde.dim_suburb
[0m12:30:04.088344 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:30:04.088604 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:30:04.089710 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 12:30:03.319737 => 12:30:04.089558
[0m12:30:04.090023 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m12:30:04.090310 [debug] [Thread-4 (]: Timing info for model.bde.dim_suburb (compile): 12:30:04.086333 => 12:30:04.090194
[0m12:30:04.090612 [debug] [Thread-4 (]: Began executing node model.bde.dim_suburb
[0m12:30:04.091021 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140e00a0>]}
[0m12:30:04.093699 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:30:04.094070 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 0.78s]
[0m12:30:04.094524 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m12:30:04.094876 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:30:04.095093 [debug] [Thread-4 (]: On model.bde.dim_suburb: BEGIN
[0m12:30:04.095308 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:30:04.107111 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:30:04.108115 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (execute): 12:30:00.324763 => 12:30:04.108005
[0m12:30:04.108363 [debug] [Thread-1 (]: On model.bde.fact_listing: Close
[0m12:30:04.108876 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c85210>]}
[0m12:30:04.109215 [info ] [Thread-1 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 3.79s]
[0m12:30:04.109561 [debug] [Thread-1 (]: Finished running node model.bde.fact_listing
[0m12:30:04.172277 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:30:04.172733 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:30:04.173021 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:30:04.190352 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:30:04.190648 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:30:04.190947 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:30:04.212057 [debug] [Thread-4 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:30:04.215306 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:30:04.215673 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:30:04.224337 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:04.228688 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:30:04.229046 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:30:04.238226 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:04.239805 [debug] [Thread-4 (]: On model.bde.dim_suburb: COMMIT
[0m12:30:04.240126 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:30:04.240417 [debug] [Thread-4 (]: On model.bde.dim_suburb: COMMIT
[0m12:30:04.257314 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:30:04.259846 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:30:04.260227 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:30:04.281048 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:30:04.282426 [debug] [Thread-4 (]: Timing info for model.bde.dim_suburb (execute): 12:30:04.091226 => 12:30:04.282247
[0m12:30:04.282856 [debug] [Thread-4 (]: On model.bde.dim_suburb: Close
[0m12:30:04.283749 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140a5000>]}
[0m12:30:04.284380 [info ] [Thread-4 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.20s]
[0m12:30:04.284986 [debug] [Thread-4 (]: Finished running node model.bde.dim_suburb
[0m12:30:04.319822 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:30:04.323634 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:30:04.324074 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:30:04.333386 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:04.336548 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:30:04.336993 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:30:04.485076 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:30:04.490421 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:30:04.491045 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:30:04.491507 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:30:04.503789 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:30:04.507376 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:30:04.507835 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:30:04.522964 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:30:04.524679 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 12:30:04.060195 => 12:30:04.524482
[0m12:30:04.525071 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m12:30:04.526023 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07b818f1-438e-4307-80fa-cdb220153777', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bff100>]}
[0m12:30:04.526600 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.47s]
[0m12:30:04.527166 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m12:30:04.528896 [debug] [MainThread]: Using postgres connection "master"
[0m12:30:04.529299 [debug] [MainThread]: On master: BEGIN
[0m12:30:04.529597 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:30:04.624069 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:30:04.624833 [debug] [MainThread]: On master: COMMIT
[0m12:30:04.625301 [debug] [MainThread]: Using postgres connection "master"
[0m12:30:04.625724 [debug] [MainThread]: On master: COMMIT
[0m12:30:04.634989 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:30:04.635413 [debug] [MainThread]: On master: Close
[0m12:30:04.636449 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:30:04.636871 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:30:04.637236 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m12:30:04.637579 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:30:04.637925 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:30:04.638447 [info ] [MainThread]: 
[0m12:30:04.638937 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 7.43 seconds (7.43s).
[0m12:30:04.642434 [debug] [MainThread]: Command end result
[0m12:30:04.653618 [info ] [MainThread]: 
[0m12:30:04.654093 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:30:04.654427 [info ] [MainThread]: 
[0m12:30:04.654746 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m12:30:04.655374 [debug] [MainThread]: Command `dbt run` succeeded at 12:30:04.655288 after 7.60 seconds
[0m12:30:04.655752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051315d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140f7940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b59330>]}
[0m12:30:04.656087 [debug] [MainThread]: Flushing usage events
[0m12:37:21.655812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034d58a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10574dae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10574d3c0>]}


============================== 12:37:21.658319 | f396c009-1405-482d-b50e-fff74bbbba71 ==============================
[0m12:37:21.658319 [info ] [MainThread]: Running with dbt=1.6.6
[0m12:37:21.658623 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m12:37:21.711165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10574d630>]}
[0m12:37:21.718934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ab1180>]}
[0m12:37:21.719315 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m12:37:21.746171 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m12:37:21.771114 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:37:21.771439 [debug] [MainThread]: Partial parsing: updated file: bde://models/datamart/dm_host_neighbourhod.sql
[0m12:37:21.791418 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.raw
- models.bde.median
[0m12:37:21.794161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10610cc40>]}
[0m12:37:21.800883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10605ad10>]}
[0m12:37:21.801115 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m12:37:21.801293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10605aef0>]}
[0m12:37:21.802408 [info ] [MainThread]: 
[0m12:37:21.802795 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:37:21.803567 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:37:21.804016 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:37:21.804375 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:37:21.808871 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:37:21.809763 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:37:21.810612 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:37:21.810786 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:37:21.810953 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:37:21.811111 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:37:21.811253 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:37:21.811398 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:37:21.811529 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:37:22.018742 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:37:22.020454 [debug] [ThreadPool]: On list_postgres: Close
[0m12:37:22.021013 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:37:22.021282 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:37:22.022187 [debug] [ThreadPool]: On list_postgres: Close
[0m12:37:22.023001 [debug] [ThreadPool]: On list_postgres: Close
[0m12:37:22.031265 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m12:37:22.031839 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_warehouse)
[0m12:37:22.032494 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_staging)
[0m12:37:22.037621 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:37:22.038191 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_raw'
[0m12:37:22.039454 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:37:22.040630 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:37:22.040856 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m12:37:22.041999 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:37:22.042216 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m12:37:22.042410 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m12:37:22.042607 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:37:22.042806 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m12:37:22.042991 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:37:22.043174 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:37:22.043541 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:37:22.143225 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:37:22.143726 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:37:22.144038 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m12:37:22.144379 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:37:22.144790 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:37:22.145076 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m12:37:22.147664 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:37:22.147910 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:37:22.148173 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m12:37:22.153896 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:37:22.154168 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:37:22.154453 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m12:37:22.158879 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:37:22.160412 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m12:37:22.160767 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:37:22.162064 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m12:37:22.165189 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:37:22.166212 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m12:37:22.168919 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:37:22.169214 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m12:37:22.170584 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m12:37:22.170895 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m12:37:22.175622 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m12:37:22.179783 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m12:37:22.185821 [debug] [MainThread]: Using postgres connection "master"
[0m12:37:22.186182 [debug] [MainThread]: On master: BEGIN
[0m12:37:22.186451 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:37:22.288615 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:37:22.290091 [debug] [MainThread]: Using postgres connection "master"
[0m12:37:22.290893 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:37:22.317709 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:37:22.322910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060c1540>]}
[0m12:37:22.323870 [debug] [MainThread]: On master: ROLLBACK
[0m12:37:22.333663 [debug] [MainThread]: Using postgres connection "master"
[0m12:37:22.334411 [debug] [MainThread]: On master: BEGIN
[0m12:37:22.357812 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:37:22.358949 [debug] [MainThread]: On master: COMMIT
[0m12:37:22.359925 [debug] [MainThread]: Using postgres connection "master"
[0m12:37:22.360827 [debug] [MainThread]: On master: COMMIT
[0m12:37:22.370175 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:37:22.370634 [debug] [MainThread]: On master: Close
[0m12:37:22.371903 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:37:22.372377 [info ] [MainThread]: 
[0m12:37:22.377860 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m12:37:22.378614 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m12:37:22.379190 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m12:37:22.379664 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m12:37:22.380300 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m12:37:22.380846 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m12:37:22.381387 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m12:37:22.381929 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m12:37:22.382769 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_host_neighbourhod)
[0m12:37:22.383413 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.dm_listing_neighbourhood)
[0m12:37:22.384032 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.dm_property_type)
[0m12:37:22.384638 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.stg_G01)
[0m12:37:22.385057 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m12:37:22.385436 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m12:37:22.385987 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m12:37:22.386433 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m12:37:22.394316 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m12:37:22.397015 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m12:37:22.401051 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m12:37:22.403783 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m12:37:22.405163 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 12:37:22.386703 => 12:37:22.404911
[0m12:37:22.405555 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m12:37:22.412203 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 12:37:22.394635 => 12:37:22.412041
[0m12:37:22.418721 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 12:37:22.397275 => 12:37:22.418565
[0m12:37:22.419014 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 12:37:22.401433 => 12:37:22.418894
[0m12:37:22.431196 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m12:37:22.431443 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m12:37:22.431698 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m12:37:22.431929 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m12:37:22.434284 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m12:37:22.436405 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m12:37:22.436659 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:37:22.446432 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m12:37:22.446799 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m12:37:22.447044 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:37:22.447328 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:37:22.447528 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:37:22.447719 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m12:37:22.447901 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:37:22.448161 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m12:37:22.448341 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:37:22.448536 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m12:37:22.448728 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:37:22.448964 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:37:22.545780 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:22.546163 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:37:22.546671 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,     
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m12:37:22.552172 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:22.552437 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:37:22.552929 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:37:22.553401 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:22.553769 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:37:22.554332 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type

-- Set the configuration for the materialized view



-- Create a Common Table Expression (CTE) called sorted_listing
-- This CTE retrieves data from multiple tables and calculates various metrics
-- It includes property_type, room_type, accommodates, and more.


WITH sorted_listing AS (
    SELECT 
        prop.property_type,-- Property type
        room.room_type,-- Room type
        list.accommodates,-- Accommodates
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year, -- Truncate the date to the month
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id, -- Host ID
        host.host_is_superhost,-- Host is superhost flag
        review_scores_rating,-- Review scores rating
        availability_30-- Availability for the next 30 days
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
-- Select the aggregated metrics for the property_type, room_type, accommodates, and month_year
SELECT 
    property_type,-- Property type
    room_type,-- Room type
    accommodates,-- Number of accommodates
    month_year,-- Truncated month and year
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,-- Calculate the minimum price for active listings
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,-- Calculate the maximum price for active listings
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing, -- Calculate the median price for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts, -- Count the number of distinct hosts
     -- Calculate the superhost rate
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
     -- Calculate the average review scores rating for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


     -- Calculate the percentage change for active listing
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing

    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:37:22.563270 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:22.563571 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:37:22.563977 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    -- Set the configuration for the materialized view


-- Create a Common Table Expression (CTE) called host_neighbourhood_lga_transform
-- This CTE retrieves data from the dim_host and dim_suburb tables and transforms it.
-- It includes host data, host neighborhood's local government area, and month_year.

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM warehouse.dim_host host
    LEFT JOIN warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
-- Create a CTE called distinct_host_count
-- This CTE calculates the number of distinct hosts for each host_neighbourhood_lga and month_year.
distinct_host_count AS (
    SELECT
        TO_CHAR(ht.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        COUNT(DISTINCT ht.host_id) AS num_distinct_hosts
    FROM host_neighbourhood_lga_transform ht
    GROUP BY TO_CHAR(ht.scraped_date, 'MM/YYYY'), ht.host_neighbourhood_lga
),
-- Create a CTE called estimated_revenue
-- This CTE calculates the total estimated revenue for each host_neighbourhood_lga and month_year.
estimated_revenue AS (
    SELECT
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        SUM((30 - list.availability_30) * list.price) AS total_estimated_revenue
    FROM warehouse.fact_listing list
    LEFT JOIN host_neighbourhood_lga_transform h ON list.surrogate_key_host = ht.surrogate_key_host
    WHERE list.has_availability = 't'
    GROUP BY
        TO_CHAR(list.scraped_date, 'MM/YYYY'),
        ht.host_neighbourhood_lga
)
-- Select the aggregated metrics including month_year, host_neighbourhood_lga, number of distinct hosts, total estimated revenue, and estimated revenue per host.
SELECT
    dh.month_year,
    dh.host_neighbourhood_lga,
    dh.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dh.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dh.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM distinct_host_count dh
LEFT JOIN estimated_revenue er ON dh.month_year = er.month_year AND dh.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY dh.host_neighbourhood_lga, dh.month_year
  );
  
[0m12:37:22.575981 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:37:22.581751 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:37:22.582051 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:37:22.590175 [debug] [Thread-1 (]: Postgres adapter: Postgres error: missing FROM-clause entry for table "ht"
LINE 45: ...hood_lga_transform h ON list.surrogate_key_host = ht.surroga...
                                                              ^

[0m12:37:22.590483 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: ROLLBACK
[0m12:37:22.595068 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:22.597225 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:37:22.597520 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:37:22.598783 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:37:22.405987 => 12:37:22.598638
[0m12:37:22.599060 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:37:22.604497 [debug] [Thread-1 (]: Database Error in model dm_host_neighbourhod (models/datamart/dm_host_neighbourhod.sql)
  missing FROM-clause entry for table "ht"
  LINE 45: ...hood_lga_transform h ON list.surrogate_key_host = ht.surroga...
                                                                ^
  compiled Code at target/run/bde/models/datamart/dm_host_neighbourhod.sql
[0m12:37:22.604851 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106416cb0>]}
[0m12:37:22.605268 [error] [Thread-1 (]: 1 of 19 ERROR creating sql table model datamart.dm_host_neighbourhod ........... [[31mERROR[0m in 0.22s]
[0m12:37:22.605665 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:37:22.605953 [debug] [Thread-1 (]: Began running node model.bde.stg_G02
[0m12:37:22.606297 [info ] [Thread-1 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:37:22.606714 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.stg_G02)
[0m12:37:22.606967 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:22.607233 [debug] [Thread-1 (]: Began compiling node model.bde.stg_G02
[0m12:37:22.617892 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:37:22.619860 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:37:22.620106 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:37:22.620394 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:37:22.620784 [debug] [Thread-1 (]: Timing info for model.bde.stg_G02 (compile): 12:37:22.618118 => 12:37:22.620679
[0m12:37:22.620996 [debug] [Thread-1 (]: Began executing node model.bde.stg_G02
[0m12:37:22.623196 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:37:22.623563 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:37:22.623763 [debug] [Thread-1 (]: On model.bde.stg_G02: BEGIN
[0m12:37:22.623958 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:37:22.631950 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:22.636744 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:37:22.637005 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:37:22.648896 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:37:22.649829 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:37:22.436814 => 12:37:22.649723
[0m12:37:22.650077 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:37:22.650619 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064c2bf0>]}
[0m12:37:22.651041 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.27s]
[0m12:37:22.651405 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:37:22.651666 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m12:37:22.651974 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:37:22.652369 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_LGA)
[0m12:37:22.652583 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m12:37:22.654359 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:37:22.655057 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 12:37:22.652732 => 12:37:22.654962
[0m12:37:22.655264 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m12:37:22.657613 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:37:22.658048 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:37:22.658261 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m12:37:22.658454 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:37:22.733761 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:22.734142 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:37:22.734480 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:37:22.750694 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:37:22.753504 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:37:22.753804 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:37:22.760633 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:22.760908 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:37:22.761215 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:37:22.762759 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:22.766029 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:37:22.766333 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:37:22.776504 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:22.777873 [debug] [Thread-1 (]: On model.bde.stg_G02: COMMIT
[0m12:37:22.778179 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:37:22.778493 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:37:22.780974 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:37:22.781295 [debug] [Thread-1 (]: On model.bde.stg_G02: COMMIT
[0m12:37:22.781572 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:37:22.790773 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:22.792873 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:37:22.793152 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:22.793437 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:37:22.795353 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_G02"
[0m12:37:22.795746 [debug] [Thread-1 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:37:22.804788 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:22.805993 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:37:22.806271 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:37:22.806523 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:37:22.807697 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:37:22.808682 [debug] [Thread-1 (]: Timing info for model.bde.stg_G02 (execute): 12:37:22.621140 => 12:37:22.808552
[0m12:37:22.808973 [debug] [Thread-1 (]: On model.bde.stg_G02: Close
[0m12:37:22.809637 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106787dc0>]}
[0m12:37:22.810115 [info ] [Thread-1 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.20s]
[0m12:37:22.810577 [debug] [Thread-1 (]: Finished running node model.bde.stg_G02
[0m12:37:22.810928 [debug] [Thread-1 (]: Began running node model.bde.stg_fact
[0m12:37:22.811322 [info ] [Thread-1 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:37:22.811853 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_fact)
[0m12:37:22.812157 [debug] [Thread-1 (]: Began compiling node model.bde.stg_fact
[0m12:37:22.814817 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:37:22.816117 [debug] [Thread-1 (]: Timing info for model.bde.stg_fact (compile): 12:37:22.812356 => 12:37:22.815995
[0m12:37:22.816392 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:22.816630 [debug] [Thread-1 (]: Began executing node model.bde.stg_fact
[0m12:37:22.818458 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:37:22.821151 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:37:22.821426 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:37:22.821879 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:37:22.822112 [debug] [Thread-1 (]: On model.bde.stg_fact: BEGIN
[0m12:37:22.822336 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:37:22.833212 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:37:22.834223 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 12:37:22.655402 => 12:37:22.834103
[0m12:37:22.834486 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m12:37:22.835045 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067d7c40>]}
[0m12:37:22.835457 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.18s]
[0m12:37:22.835881 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m12:37:22.836192 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m12:37:22.836622 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:37:22.837297 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_host)
[0m12:37:22.837675 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m12:37:22.840223 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:37:22.841300 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 12:37:22.837895 => 12:37:22.841142
[0m12:37:22.841600 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m12:37:22.872737 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:37:22.873448 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:37:22.873674 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m12:37:22.873866 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:37:22.922558 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:22.922881 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:37:22.923232 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:37:22.960903 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:37:22.963220 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:37:22.963468 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:37:22.975791 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:22.977638 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:37:22.977871 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:37:22.991213 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:22.992198 [debug] [Thread-1 (]: On model.bde.stg_fact: COMMIT
[0m12:37:22.992411 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:37:22.992606 [debug] [Thread-1 (]: On model.bde.stg_fact: COMMIT
[0m12:37:23.004601 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:23.006103 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_fact"
[0m12:37:23.006324 [debug] [Thread-1 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:37:23.020702 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:37:23.021601 [debug] [Thread-1 (]: Timing info for model.bde.stg_fact (execute): 12:37:22.818666 => 12:37:23.021487
[0m12:37:23.021853 [debug] [Thread-1 (]: On model.bde.stg_fact: Close
[0m12:37:23.022435 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064311e0>]}
[0m12:37:23.022844 [info ] [Thread-1 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.21s]
[0m12:37:23.023251 [debug] [Thread-1 (]: Finished running node model.bde.stg_fact
[0m12:37:23.023532 [debug] [Thread-1 (]: Began running node model.bde.stg_property
[0m12:37:23.023950 [info ] [Thread-1 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:37:23.024379 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_property)
[0m12:37:23.024600 [debug] [Thread-1 (]: Began compiling node model.bde.stg_property
[0m12:37:23.026665 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:37:23.026902 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:23.027213 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:37:23.027516 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:37:23.028177 [debug] [Thread-1 (]: Timing info for model.bde.stg_property (compile): 12:37:23.024758 => 12:37:23.028074
[0m12:37:23.028393 [debug] [Thread-1 (]: Began executing node model.bde.stg_property
[0m12:37:23.031054 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:37:23.031854 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:37:23.032139 [debug] [Thread-1 (]: On model.bde.stg_property: BEGIN
[0m12:37:23.032358 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:37:23.045286 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:37:23.047613 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:37:23.047859 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:37:23.057248 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:23.059083 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:37:23.059323 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:37:23.069251 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:23.070395 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:37:23.070630 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:37:23.070843 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:37:23.082649 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:23.085734 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:37:23.086017 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:37:23.096646 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:37:23.097685 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 12:37:22.841765 => 12:37:23.097564
[0m12:37:23.097950 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m12:37:23.098528 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106481210>]}
[0m12:37:23.098928 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.26s]
[0m12:37:23.099365 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m12:37:23.099676 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m12:37:23.100055 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:37:23.100493 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_room)
[0m12:37:23.100744 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m12:37:23.102892 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:37:23.104156 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 12:37:23.100929 => 12:37:23.104036
[0m12:37:23.104394 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m12:37:23.106989 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:37:23.107580 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:37:23.107807 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m12:37:23.108017 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:37:23.160056 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:23.160492 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:37:23.160855 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:37:23.180339 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:37:23.183101 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:37:23.183427 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:37:23.193620 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:23.196269 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:37:23.196588 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:37:23.205970 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:23.207202 [debug] [Thread-1 (]: On model.bde.stg_property: COMMIT
[0m12:37:23.207535 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:37:23.207923 [debug] [Thread-1 (]: On model.bde.stg_property: COMMIT
[0m12:37:23.217832 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:23.219770 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_property"
[0m12:37:23.220088 [debug] [Thread-1 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:37:23.232369 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:37:23.233540 [debug] [Thread-1 (]: Timing info for model.bde.stg_property (execute): 12:37:23.028547 => 12:37:23.233389
[0m12:37:23.233874 [debug] [Thread-1 (]: On model.bde.stg_property: Close
[0m12:37:23.234575 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079116f0>]}
[0m12:37:23.234904 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:23.235400 [info ] [Thread-1 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.21s]
[0m12:37:23.235796 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:37:23.236241 [debug] [Thread-1 (]: Finished running node model.bde.stg_property
[0m12:37:23.236561 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:37:23.236921 [debug] [Thread-1 (]: Began running node model.bde.stg_suburb
[0m12:37:23.237421 [info ] [Thread-1 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:37:23.237942 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_suburb)
[0m12:37:23.238225 [debug] [Thread-1 (]: Began compiling node model.bde.stg_suburb
[0m12:37:23.240482 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:37:23.241094 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (compile): 12:37:23.238421 => 12:37:23.240948
[0m12:37:23.241376 [debug] [Thread-1 (]: Began executing node model.bde.stg_suburb
[0m12:37:23.244429 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:37:23.245128 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:37:23.245417 [debug] [Thread-1 (]: On model.bde.stg_suburb: BEGIN
[0m12:37:23.245670 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:37:23.252737 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:37:23.255025 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:37:23.255301 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:37:23.269623 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:23.273074 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:37:23.273369 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:37:23.284329 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:23.285608 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:37:23.285905 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:37:23.286165 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:37:23.310814 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:23.312960 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:37:23.313303 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:37:23.325206 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:37:23.326375 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 12:37:23.104558 => 12:37:23.326226
[0m12:37:23.326708 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m12:37:23.327466 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106790f70>]}
[0m12:37:23.328003 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.23s]
[0m12:37:23.328552 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m12:37:23.328928 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m12:37:23.329304 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:37:23.329993 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.dim_LGA)
[0m12:37:23.330322 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m12:37:23.332875 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:37:23.333854 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 12:37:23.330546 => 12:37:23.333711
[0m12:37:23.334260 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m12:37:23.337328 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:37:23.338032 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:37:23.338324 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m12:37:23.338585 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:37:23.364346 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:23.364676 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:37:23.365053 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:37:23.376473 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:37:23.379470 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:37:23.379802 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:37:23.388881 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:23.391923 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:37:23.392259 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:37:23.402293 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:23.403993 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:37:23.404339 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:37:23.404647 [debug] [Thread-1 (]: On model.bde.stg_suburb: COMMIT
[0m12:37:23.414742 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:23.417162 [debug] [Thread-1 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:37:23.417563 [debug] [Thread-1 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:37:23.428820 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:37:23.430039 [debug] [Thread-1 (]: Timing info for model.bde.stg_suburb (execute): 12:37:23.241578 => 12:37:23.429886
[0m12:37:23.430429 [debug] [Thread-1 (]: On model.bde.stg_suburb: Close
[0m12:37:23.431139 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064165c0>]}
[0m12:37:23.431651 [info ] [Thread-1 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.19s]
[0m12:37:23.432164 [debug] [Thread-1 (]: Finished running node model.bde.stg_suburb
[0m12:37:23.432531 [debug] [Thread-1 (]: Began running node model.bde.fact_G01
[0m12:37:23.432907 [info ] [Thread-1 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:37:23.433695 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.fact_G01)
[0m12:37:23.434089 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G01
[0m12:37:23.436825 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:37:23.438256 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (compile): 12:37:23.434338 => 12:37:23.438121
[0m12:37:23.438655 [debug] [Thread-1 (]: Began executing node model.bde.fact_G01
[0m12:37:23.443146 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:37:23.443858 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:37:23.444141 [debug] [Thread-1 (]: On model.bde.fact_G01: BEGIN
[0m12:37:23.444382 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:37:23.454883 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:23.455173 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:37:23.455424 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:37:23.472473 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:37:23.475446 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:37:23.475769 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:37:23.485588 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:23.487788 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:37:23.488086 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:37:23.497685 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:23.502226 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:37:23.502561 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:37:23.502844 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:37:23.512503 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:23.516234 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:37:23.516565 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:37:23.530998 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:37:23.532141 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 12:37:23.334494 => 12:37:23.531988
[0m12:37:23.532437 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m12:37:23.533042 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064b2e90>]}
[0m12:37:23.533494 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.20s]
[0m12:37:23.533945 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m12:37:23.534266 [debug] [Thread-4 (]: Began running node model.bde.fact_G02
[0m12:37:23.534652 [info ] [Thread-4 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:37:23.535117 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G02)
[0m12:37:23.535374 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G02
[0m12:37:23.537573 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:37:23.538104 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (compile): 12:37:23.535554 => 12:37:23.537985
[0m12:37:23.538361 [debug] [Thread-4 (]: Began executing node model.bde.fact_G02
[0m12:37:23.541180 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:37:23.541624 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:37:23.541869 [debug] [Thread-4 (]: On model.bde.fact_G02: BEGIN
[0m12:37:23.542097 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:37:23.557857 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:23.558164 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:37:23.558421 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:37:23.586180 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:37:23.588901 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:37:23.589219 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:37:23.599076 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:23.601400 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:37:23.601710 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:37:23.612106 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:23.613648 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:37:23.614003 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:37:23.614329 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:37:23.624956 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:23.628756 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:37:23.629065 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:37:23.650478 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:37:23.651603 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (execute): 12:37:23.438878 => 12:37:23.651449
[0m12:37:23.651932 [debug] [Thread-1 (]: On model.bde.fact_G01: Close
[0m12:37:23.652632 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067fb670>]}
[0m12:37:23.653137 [info ] [Thread-1 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.22s]
[0m12:37:23.653659 [debug] [Thread-1 (]: Finished running node model.bde.fact_G01
[0m12:37:23.654025 [debug] [Thread-1 (]: Began running node model.bde.fact_listing
[0m12:37:23.654404 [info ] [Thread-1 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:37:23.655097 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_listing)
[0m12:37:23.655499 [debug] [Thread-1 (]: Began compiling node model.bde.fact_listing
[0m12:37:23.658460 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:37:23.659951 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (compile): 12:37:23.655760 => 12:37:23.659800
[0m12:37:23.660252 [debug] [Thread-1 (]: Began executing node model.bde.fact_listing
[0m12:37:23.663246 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:37:23.663754 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:37:23.664041 [debug] [Thread-1 (]: On model.bde.fact_listing: BEGIN
[0m12:37:23.664321 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:37:23.680336 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:23.680642 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:37:23.680944 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:37:23.699385 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:37:23.702420 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:37:23.702762 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:37:23.712043 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:23.714660 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:37:23.715008 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:37:23.723624 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:23.725227 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:37:23.725553 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:37:23.725856 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:37:23.735739 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:23.737897 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:37:23.738226 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:37:23.754290 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:37:23.755426 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (execute): 12:37:23.538569 => 12:37:23.755279
[0m12:37:23.755755 [debug] [Thread-4 (]: On model.bde.fact_G02: Close
[0m12:37:23.756472 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a7ae90>]}
[0m12:37:23.757052 [info ] [Thread-4 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.22s]
[0m12:37:23.757570 [debug] [Thread-4 (]: Finished running node model.bde.fact_G02
[0m12:37:23.757940 [debug] [Thread-4 (]: Began running node model.bde.dim_host
[0m12:37:23.758418 [info ] [Thread-4 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:37:23.759085 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m12:37:23.759437 [debug] [Thread-4 (]: Began compiling node model.bde.dim_host
[0m12:37:23.762359 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:37:23.764216 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (compile): 12:37:23.759672 => 12:37:23.764081
[0m12:37:23.764504 [debug] [Thread-4 (]: Began executing node model.bde.dim_host
[0m12:37:23.767664 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:37:23.768378 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:37:23.768658 [debug] [Thread-4 (]: On model.bde.dim_host: BEGIN
[0m12:37:23.768919 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:37:23.775452 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:23.775722 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:37:23.776030 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:37:23.877735 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:23.878376 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:37:23.878890 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    scraped_date,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:37:24.539286 [debug] [Thread-4 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m12:37:24.550614 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:37:24.551339 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:37:26.788477 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m12:37:26.798422 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:37:26.799377 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:37:26.809621 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:26.813758 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:37:26.814321 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:37:26.823307 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:26.825932 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:37:26.826729 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:37:26.827152 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:37:26.845873 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:26.849654 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:37:26.850213 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:37:26.872395 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:37:26.874396 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:37:22.432165 => 12:37:26.874143
[0m12:37:26.874935 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:37:26.876237 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106087310>]}
[0m12:37:26.877107 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 4.49s]
[0m12:37:26.877952 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:37:26.878528 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m12:37:26.879238 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:37:26.880096 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m12:37:26.880520 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m12:37:26.884474 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:37:26.886669 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 12:37:26.880803 => 12:37:26.886440
[0m12:37:26.887074 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m12:37:26.891107 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:37:26.891820 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:37:26.892157 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m12:37:26.892473 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:37:27.007442 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:27.008767 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:37:27.009373 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:37:27.644359 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m12:37:27.645649 [debug] [Thread-1 (]: SQL status: SELECT 340945 in 4.0 seconds
[0m12:37:27.653838 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:37:27.657802 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:37:27.658283 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:37:27.658701 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:37:27.760168 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 5.0 seconds
[0m12:37:27.766561 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:37:27.767573 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m12:37:27.780017 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:27.783982 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:37:27.784525 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m12:37:27.793665 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:27.796017 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:37:27.796491 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:37:27.796922 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:37:27.806973 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:27.810181 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:37:27.810688 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:27.811130 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 3.0 seconds
[0m12:37:27.811631 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:27.812107 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m12:37:27.815134 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:37:27.818357 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:37:27.820799 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:37:27.821581 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:37:27.822175 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:37:27.822854 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:37:27.832572 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:27.832951 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:27.834695 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:37:27.834962 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:27.836358 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:37:27.836630 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:37:27.836900 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:37:27.838071 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:37:27.838336 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:37:27.839283 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:37:22.434506 => 12:37:27.839156
[0m12:37:27.839551 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m12:37:27.839799 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:37:27.840057 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m12:37:27.840319 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:37:27.840632 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:37:27.841303 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106444d00>]}
[0m12:37:27.841732 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 5.46s]
[0m12:37:27.842154 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:37:27.842440 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m12:37:27.842773 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:37:27.843205 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m12:37:27.843458 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m12:37:27.845756 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:37:27.846537 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 12:37:27.843629 => 12:37:27.846420
[0m12:37:27.846783 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m12:37:27.849518 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:37:27.850096 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:37:27.850337 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m12:37:27.850556 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:37:27.852751 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:27.853069 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:27.854907 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m12:37:27.856336 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:27.857787 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m12:37:27.858049 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:37:27.859502 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:37:27.859759 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:37:27.860016 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:37:27.880179 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:37:27.881212 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (execute): 12:37:23.764696 => 12:37:27.881094
[0m12:37:27.881467 [debug] [Thread-4 (]: On model.bde.dim_host: Close
[0m12:37:27.882073 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106430c10>]}
[0m12:37:27.882487 [info ] [Thread-4 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 4.12s]
[0m12:37:27.882864 [debug] [Thread-4 (]: Finished running node model.bde.dim_host
[0m12:37:27.883144 [debug] [Thread-4 (]: Began running node model.bde.dim_suburb
[0m12:37:27.883422 [info ] [Thread-4 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:37:27.883889 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_host, now model.bde.dim_suburb)
[0m12:37:27.884115 [debug] [Thread-4 (]: Began compiling node model.bde.dim_suburb
[0m12:37:27.886223 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:37:27.887021 [debug] [Thread-4 (]: Timing info for model.bde.dim_suburb (compile): 12:37:27.884266 => 12:37:27.886880
[0m12:37:27.887271 [debug] [Thread-4 (]: Began executing node model.bde.dim_suburb
[0m12:37:27.889755 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:37:27.889992 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:37:27.890846 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 12:37:26.887314 => 12:37:27.890745
[0m12:37:27.891090 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m12:37:27.891354 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:37:27.891720 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067bfe80>]}
[0m12:37:27.891957 [debug] [Thread-4 (]: On model.bde.dim_suburb: BEGIN
[0m12:37:27.892292 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 1.01s]
[0m12:37:27.892534 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:37:27.892828 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m12:37:27.913267 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:37:27.914273 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (execute): 12:37:23.660468 => 12:37:27.914169
[0m12:37:27.914525 [debug] [Thread-1 (]: On model.bde.fact_listing: Close
[0m12:37:27.915013 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ab17b0>]}
[0m12:37:27.915383 [info ] [Thread-1 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 4.26s]
[0m12:37:27.915726 [debug] [Thread-1 (]: Finished running node model.bde.fact_listing
[0m12:37:27.960991 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:27.961432 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:37:27.961772 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:37:27.981397 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:37:27.981710 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:37:27.981992 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:37:28.002667 [debug] [Thread-4 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:37:28.005632 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:37:28.005964 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:37:28.014404 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:28.016600 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:37:28.016900 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:37:28.034550 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:28.036089 [debug] [Thread-4 (]: On model.bde.dim_suburb: COMMIT
[0m12:37:28.036410 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:37:28.036684 [debug] [Thread-4 (]: On model.bde.dim_suburb: COMMIT
[0m12:37:28.054094 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:28.056261 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:37:28.056571 [debug] [Thread-4 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:37:28.072488 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:37:28.073564 [debug] [Thread-4 (]: Timing info for model.bde.dim_suburb (execute): 12:37:27.887432 => 12:37:28.073426
[0m12:37:28.073866 [debug] [Thread-4 (]: On model.bde.dim_suburb: Close
[0m12:37:28.074524 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107940130>]}
[0m12:37:28.074990 [info ] [Thread-4 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.19s]
[0m12:37:28.075459 [debug] [Thread-4 (]: Finished running node model.bde.dim_suburb
[0m12:37:28.139623 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:37:28.142921 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:37:28.143340 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:37:28.154251 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:28.158527 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:37:28.158896 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:37:28.167823 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:37:28.169467 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:37:28.169824 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:37:28.170127 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:37:28.194217 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:37:28.196858 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:37:28.197257 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:37:28.212316 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:37:28.214037 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 12:37:27.846948 => 12:37:28.213792
[0m12:37:28.214566 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m12:37:28.215623 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f396c009-1405-482d-b50e-fff74bbbba71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10646e020>]}
[0m12:37:28.216282 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.37s]
[0m12:37:28.216902 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m12:37:28.218802 [debug] [MainThread]: Using postgres connection "master"
[0m12:37:28.219280 [debug] [MainThread]: On master: BEGIN
[0m12:37:28.219671 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:37:28.349323 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:37:28.351427 [debug] [MainThread]: On master: COMMIT
[0m12:37:28.352528 [debug] [MainThread]: Using postgres connection "master"
[0m12:37:28.353506 [debug] [MainThread]: On master: COMMIT
[0m12:37:28.363913 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:37:28.364476 [debug] [MainThread]: On master: Close
[0m12:37:28.365382 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:37:28.365726 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:37:28.366044 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m12:37:28.366353 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:37:28.366627 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:37:28.367087 [info ] [MainThread]: 
[0m12:37:28.367516 [info ] [MainThread]: Finished running 11 table models, 8 view models in 0 hours 0 minutes and 6.56 seconds (6.56s).
[0m12:37:28.370481 [debug] [MainThread]: Command end result
[0m12:37:28.380530 [info ] [MainThread]: 
[0m12:37:28.380857 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m12:37:28.381099 [info ] [MainThread]: 
[0m12:37:28.381357 [error] [MainThread]:   Database Error in model dm_host_neighbourhod (models/datamart/dm_host_neighbourhod.sql)
  missing FROM-clause entry for table "ht"
  LINE 45: ...hood_lga_transform h ON list.surrogate_key_host = ht.surroga...
                                                                ^
  compiled Code at target/run/bde/models/datamart/dm_host_neighbourhod.sql
[0m12:37:28.381644 [info ] [MainThread]: 
[0m12:37:28.381909 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m12:37:28.382504 [debug] [MainThread]: Command `dbt run` failed at 12:37:28.382429 after 6.74 seconds
[0m12:37:28.382868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034d58a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a78370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a7b460>]}
[0m12:37:28.383197 [debug] [MainThread]: Flushing usage events
[0m12:39:32.320260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074c18a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10941dae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10941d420>]}


============================== 12:39:32.322663 | e14056cd-45ae-4410-84df-3804326b7676 ==============================
[0m12:39:32.322663 [info ] [MainThread]: Running with dbt=1.6.6
[0m12:39:32.322956 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:39:32.373444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10941d630>]}
[0m12:39:32.380961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10985d180>]}
[0m12:39:32.381339 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m12:39:32.389623 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m12:39:32.412811 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:39:32.413213 [debug] [MainThread]: Partial parsing: updated file: bde://models/datamart/dm_host_neighbourhod.sql
[0m12:39:32.433249 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.raw
- models.bde.median
[0m12:39:32.436015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e68c40>]}
[0m12:39:32.442114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c82d10>]}
[0m12:39:32.442383 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m12:39:32.442573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c82ef0>]}
[0m12:39:32.443754 [info ] [MainThread]: 
[0m12:39:32.444128 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:39:32.444949 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:39:32.445393 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:39:32.445748 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:39:32.450500 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:39:32.451518 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:39:32.452428 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:39:32.452612 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:39:32.452793 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:39:32.452973 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:39:32.453134 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:39:32.453277 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:39:32.453423 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:39:32.592386 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:39:32.593733 [debug] [ThreadPool]: On list_postgres: Close
[0m12:39:32.593999 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:39:32.594247 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:39:32.595085 [debug] [ThreadPool]: On list_postgres: Close
[0m12:39:32.596220 [debug] [ThreadPool]: On list_postgres: Close
[0m12:39:32.598020 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m12:39:32.598468 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_warehouse)
[0m12:39:32.598911 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_staging)
[0m12:39:32.603305 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:39:32.603811 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_raw'
[0m12:39:32.605045 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:39:32.606164 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:39:32.606374 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m12:39:32.607482 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:39:32.607687 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m12:39:32.607864 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m12:39:32.608040 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:39:32.608216 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m12:39:32.608386 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:39:32.608553 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:39:32.608831 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:39:32.708517 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:39:32.708910 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:39:32.709179 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m12:39:32.715771 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:39:32.716008 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:39:32.716273 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:39:32.716497 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:39:32.716749 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:39:32.716990 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:39:32.717248 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m12:39:32.717577 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m12:39:32.717883 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m12:39:32.726395 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:39:32.727468 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m12:39:32.732739 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:39:32.733630 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m12:39:32.736164 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:39:32.737020 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m12:39:32.737261 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:39:32.737512 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m12:39:32.738529 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m12:39:32.741938 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m12:39:32.746997 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m12:39:32.748889 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m12:39:32.753948 [debug] [MainThread]: Using postgres connection "master"
[0m12:39:32.754214 [debug] [MainThread]: On master: BEGIN
[0m12:39:32.754419 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:39:32.848826 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:39:32.849237 [debug] [MainThread]: Using postgres connection "master"
[0m12:39:32.849761 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:39:32.874425 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:39:32.878888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109db3eb0>]}
[0m12:39:32.879502 [debug] [MainThread]: On master: ROLLBACK
[0m12:39:32.888596 [debug] [MainThread]: Using postgres connection "master"
[0m12:39:32.889003 [debug] [MainThread]: On master: BEGIN
[0m12:39:32.909751 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:39:32.910767 [debug] [MainThread]: On master: COMMIT
[0m12:39:32.911385 [debug] [MainThread]: Using postgres connection "master"
[0m12:39:32.911903 [debug] [MainThread]: On master: COMMIT
[0m12:39:32.923065 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:39:32.923573 [debug] [MainThread]: On master: Close
[0m12:39:32.924480 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:39:32.924893 [info ] [MainThread]: 
[0m12:39:32.928567 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m12:39:32.928968 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m12:39:32.929325 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m12:39:32.929683 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m12:39:32.930121 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m12:39:32.930604 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m12:39:32.931260 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m12:39:32.931874 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m12:39:32.932700 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_host_neighbourhod)
[0m12:39:32.933311 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.dm_listing_neighbourhood)
[0m12:39:32.933833 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.dm_property_type)
[0m12:39:32.934270 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.stg_G01)
[0m12:39:32.934588 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m12:39:32.934880 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m12:39:32.935224 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m12:39:32.935529 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m12:39:32.942280 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m12:39:32.944618 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m12:39:32.947942 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m12:39:32.950362 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m12:39:32.951183 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 12:39:32.935750 => 12:39:32.950989
[0m12:39:32.951737 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 12:39:32.942543 => 12:39:32.951541
[0m12:39:32.952079 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 12:39:32.944849 => 12:39:32.951938
[0m12:39:32.952397 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m12:39:32.952709 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m12:39:32.952988 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 12:39:32.948199 => 12:39:32.952872
[0m12:39:32.953295 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m12:39:32.980936 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m12:39:32.982065 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m12:39:32.982335 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m12:39:32.984434 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m12:39:32.994381 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m12:39:32.994680 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:39:32.994886 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:39:32.995189 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m12:39:32.995376 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:39:32.995575 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m12:39:32.995774 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:39:32.995958 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:39:32.996136 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m12:39:32.996318 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:39:32.996580 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m12:39:32.996768 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:39:32.997032 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:39:33.093645 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:33.093975 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:39:33.094487 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type

-- Set the configuration for the materialized view



-- Create a Common Table Expression (CTE) called sorted_listing
-- This CTE retrieves data from multiple tables and calculates various metrics
-- It includes property_type, room_type, accommodates, and more.


WITH sorted_listing AS (
    SELECT 
        prop.property_type,-- Property type
        room.room_type,-- Room type
        list.accommodates,-- Accommodates
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year, -- Truncate the date to the month
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id, -- Host ID
        host.host_is_superhost,-- Host is superhost flag
        review_scores_rating,-- Review scores rating
        availability_30-- Availability for the next 30 days
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
-- Select the aggregated metrics for the property_type, room_type, accommodates, and month_year
SELECT 
    property_type,-- Property type
    room_type,-- Room type
    accommodates,-- Number of accommodates
    month_year,-- Truncated month and year
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,-- Calculate the minimum price for active listings
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,-- Calculate the maximum price for active listings
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing, -- Calculate the median price for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts, -- Count the number of distinct hosts
     -- Calculate the superhost rate
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
     -- Calculate the average review scores rating for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


     -- Calculate the percentage change for active listing
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing

    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:39:33.104992 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:33.105295 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:33.105586 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:33.105870 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:39:33.106147 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:39:33.106430 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:39:33.106960 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,     
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m12:39:33.107699 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:39:33.108308 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    -- Set the configuration for the materialized view


-- Create a Common Table Expression (CTE) called host_neighbourhood_lga_transform
-- This CTE retrieves data from the dim_host and dim_suburb tables and transforms it.
-- It includes host data, host neighborhood's local government area, and month_year.

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM warehouse.dim_host host
    LEFT JOIN warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
-- Create a CTE called distinct_host_count
-- This CTE calculates the number of distinct hosts for each host_neighbourhood_lga and month_year.
distinct_host_count AS (
    SELECT
        TO_CHAR(ht.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        COUNT(DISTINCT ht.host_id) AS num_distinct_hosts
    FROM host_neighbourhood_lga_transform ht
    GROUP BY TO_CHAR(ht.scraped_date, 'MM/YYYY'), ht.host_neighbourhood_lga
),
-- Create a CTE called estimated_revenue
-- This CTE calculates the total estimated revenue for each host_neighbourhood_lga and month_year.
estimated_revenue AS (
    SELECT
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        SUM((30 - list.availability_30) * list.price) AS total_estimated_revenue
    FROM warehouse.fact_listing list
    LEFT JOIN host_neighbourhood_lga_transform ht ON list.surrogate_key_host = ht.surrogate_key_host
    WHERE list.has_availability = 't'
    GROUP BY
        TO_CHAR(list.scraped_date, 'MM/YYYY'),
        ht.host_neighbourhood_lga
)
-- Select the aggregated metrics including month_year, host_neighbourhood_lga, number of distinct hosts, total estimated revenue, and estimated revenue per host.
SELECT
    dh.month_year,
    dh.host_neighbourhood_lga,
    dh.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dh.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dh.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM distinct_host_count dh
LEFT JOIN estimated_revenue er ON dh.month_year = er.month_year AND dh.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY dh.host_neighbourhood_lga, dh.month_year
  );
  
[0m12:39:33.144368 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:39:33.150427 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:39:33.150833 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:39:33.161603 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:33.163956 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:39:33.164274 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:39:33.174692 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:33.187290 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:39:33.187603 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:39:33.187860 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:39:33.198384 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:33.204037 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:39:33.204334 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:39:33.217618 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:39:33.218753 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:39:32.984749 => 12:39:33.218611
[0m12:39:33.219090 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:39:33.219781 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f53040>]}
[0m12:39:33.220224 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.29s]
[0m12:39:33.220649 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:39:33.220943 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m12:39:33.221336 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:39:33.221853 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m12:39:33.222136 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m12:39:33.224423 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:39:33.225039 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 12:39:33.222324 => 12:39:33.224909
[0m12:39:33.225321 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m12:39:33.228101 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:39:33.228548 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:39:33.228771 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m12:39:33.228978 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:39:33.348705 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:33.349221 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:39:33.349735 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:39:33.364707 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:39:33.368964 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:39:33.369389 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:39:33.379340 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:33.382955 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:39:33.383443 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:39:33.392453 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:33.394711 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:39:33.395194 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:39:33.395615 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:39:33.404992 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:33.408439 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:39:33.408965 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:39:33.421690 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:39:33.423073 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 12:39:33.225496 => 12:39:33.422886
[0m12:39:33.423486 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m12:39:33.424370 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109eb95a0>]}
[0m12:39:33.425017 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.20s]
[0m12:39:33.425616 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m12:39:33.426058 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m12:39:33.426598 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:39:33.427322 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m12:39:33.427729 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m12:39:33.432445 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:39:33.433406 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 12:39:33.427991 => 12:39:33.433217
[0m12:39:33.433772 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m12:39:33.437789 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:39:33.438545 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:39:33.438832 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m12:39:33.439098 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:39:33.544656 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:33.545306 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:39:33.545863 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:39:33.558807 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:39:33.565486 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:39:33.566064 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:39:33.575625 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:33.579419 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:39:33.579914 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:39:33.591535 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:33.593650 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:39:33.594133 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:39:33.594594 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:39:33.605344 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:33.608847 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:39:33.609395 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:39:33.619984 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:39:33.621716 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 12:39:33.434005 => 12:39:33.621483
[0m12:39:33.622202 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m12:39:33.623306 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f03e1a0>]}
[0m12:39:33.624106 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.20s]
[0m12:39:33.624862 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m12:39:33.625404 [debug] [Thread-4 (]: Began running node model.bde.stg_fact
[0m12:39:33.626185 [info ] [Thread-4 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:39:33.626904 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_fact)
[0m12:39:33.627298 [debug] [Thread-4 (]: Began compiling node model.bde.stg_fact
[0m12:39:33.631023 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:39:33.631975 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (compile): 12:39:33.627577 => 12:39:33.631781
[0m12:39:33.632387 [debug] [Thread-4 (]: Began executing node model.bde.stg_fact
[0m12:39:33.636155 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:39:33.636769 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:39:33.637086 [debug] [Thread-4 (]: On model.bde.stg_fact: BEGIN
[0m12:39:33.637401 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:39:33.771988 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:33.773724 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:39:33.774556 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:39:33.792866 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:39:33.800703 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:39:33.801462 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:39:33.811874 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:33.817939 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:39:33.818446 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:39:33.831484 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:33.833514 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:39:33.833964 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:39:33.834342 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:39:33.847121 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:33.891818 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:39:33.892332 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:39:33.904858 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:39:33.905758 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (execute): 12:39:33.632655 => 12:39:33.905655
[0m12:39:33.906002 [debug] [Thread-4 (]: On model.bde.stg_fact: Close
[0m12:39:33.906553 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109827040>]}
[0m12:39:33.906917 [info ] [Thread-4 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.28s]
[0m12:39:33.907284 [debug] [Thread-4 (]: Finished running node model.bde.stg_fact
[0m12:39:33.907534 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m12:39:33.907923 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:39:33.908384 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_host)
[0m12:39:33.908620 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m12:39:33.910590 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:39:33.911111 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 12:39:33.908784 => 12:39:33.911004
[0m12:39:33.911334 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m12:39:33.913588 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:39:33.913970 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:39:33.914172 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m12:39:33.914355 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:39:34.019646 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:34.020118 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:39:34.020587 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:39:34.039428 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:39:34.042979 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:39:34.043399 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:39:34.052473 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:34.055398 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:39:34.055816 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:39:34.065477 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:34.067322 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:39:34.067730 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:39:34.068081 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:39:34.078055 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:34.080810 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:39:34.081222 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:39:34.092324 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:39:34.093781 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 12:39:33.911478 => 12:39:34.093596
[0m12:39:34.094200 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m12:39:34.095139 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109de95d0>]}
[0m12:39:34.095776 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.19s]
[0m12:39:34.096396 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m12:39:34.096844 [debug] [Thread-4 (]: Began running node model.bde.stg_property
[0m12:39:34.097520 [info ] [Thread-4 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:39:34.098261 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_property)
[0m12:39:34.098655 [debug] [Thread-4 (]: Began compiling node model.bde.stg_property
[0m12:39:34.102035 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:39:34.102777 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (compile): 12:39:34.098924 => 12:39:34.102615
[0m12:39:34.103122 [debug] [Thread-4 (]: Began executing node model.bde.stg_property
[0m12:39:34.106703 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:39:34.107383 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:39:34.107702 [debug] [Thread-4 (]: On model.bde.stg_property: BEGIN
[0m12:39:34.108002 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:39:34.210881 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:34.212139 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:39:34.212786 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:39:34.232199 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:39:34.241164 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:39:34.241768 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:39:34.251910 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:34.254680 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:39:34.255051 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:39:34.267575 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:34.268805 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:39:34.269094 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:39:34.269352 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:39:34.279902 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:34.281520 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:39:34.281746 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:39:34.291983 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:39:34.292873 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (execute): 12:39:34.103369 => 12:39:34.292753
[0m12:39:34.293125 [debug] [Thread-4 (]: On model.bde.stg_property: Close
[0m12:39:34.293694 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f010f40>]}
[0m12:39:34.294094 [info ] [Thread-4 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.20s]
[0m12:39:34.294491 [debug] [Thread-4 (]: Finished running node model.bde.stg_property
[0m12:39:34.294778 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m12:39:34.295167 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:39:34.295589 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_room)
[0m12:39:34.295813 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m12:39:34.297898 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:39:34.298456 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 12:39:34.295988 => 12:39:34.298346
[0m12:39:34.298686 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m12:39:34.301170 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:39:34.301657 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:39:34.301900 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m12:39:34.302112 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:39:34.421435 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:34.421921 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:39:34.422368 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:39:34.436618 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:39:34.440217 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:39:34.440649 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:39:34.452890 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:34.456007 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:39:34.456437 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:39:34.466379 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:34.468461 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:39:34.468876 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:39:34.469236 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:39:34.480052 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:34.483173 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:39:34.483607 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:39:34.496739 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:39:34.498429 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 12:39:34.298837 => 12:39:34.498201
[0m12:39:34.498839 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m12:39:34.499750 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f01d690>]}
[0m12:39:34.500389 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.20s]
[0m12:39:34.500995 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m12:39:34.501440 [debug] [Thread-4 (]: Began running node model.bde.stg_suburb
[0m12:39:34.502107 [info ] [Thread-4 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:39:34.502831 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.stg_suburb)
[0m12:39:34.503221 [debug] [Thread-4 (]: Began compiling node model.bde.stg_suburb
[0m12:39:34.508210 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:39:34.509001 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (compile): 12:39:34.503491 => 12:39:34.508837
[0m12:39:34.509332 [debug] [Thread-4 (]: Began executing node model.bde.stg_suburb
[0m12:39:34.512808 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:39:34.513385 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:39:34.513716 [debug] [Thread-4 (]: On model.bde.stg_suburb: BEGIN
[0m12:39:34.514103 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:39:34.619609 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:34.620580 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:39:34.621165 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:39:34.632074 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:39:34.639019 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:39:34.639808 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:39:34.658997 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:34.663658 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:39:34.664182 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:39:34.673165 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:34.675448 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m12:39:34.675946 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:39:34.676381 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m12:39:34.686029 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:34.689221 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:39:34.689706 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:39:34.700728 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:39:34.702485 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (execute): 12:39:34.509551 => 12:39:34.702261
[0m12:39:34.703012 [debug] [Thread-4 (]: On model.bde.stg_suburb: Close
[0m12:39:34.704062 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f02ec80>]}
[0m12:39:34.704756 [info ] [Thread-4 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.20s]
[0m12:39:34.705377 [debug] [Thread-4 (]: Finished running node model.bde.stg_suburb
[0m12:39:34.705826 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m12:39:34.706522 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:39:34.707385 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.dim_LGA)
[0m12:39:34.707815 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m12:39:34.711289 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:39:34.712255 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 12:39:34.708096 => 12:39:34.712061
[0m12:39:34.712595 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m12:39:34.716374 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:39:34.717029 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:39:34.717361 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m12:39:34.717665 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:39:34.802744 [debug] [Thread-1 (]: SQL status: SELECT 217 in 2.0 seconds
[0m12:39:34.806868 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:39:34.807337 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m12:39:34.816684 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:34.821463 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:39:34.821900 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m12:39:34.831706 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:34.836995 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:39:34.837392 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:39:34.837712 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:39:34.847999 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:34.848320 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:39:34.848706 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:34.849168 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:39:34.853588 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:39:34.854086 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m12:39:34.869793 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:39:34.871008 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:39:32.953515 => 12:39:34.870847
[0m12:39:34.871356 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:39:34.872117 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109dbc040>]}
[0m12:39:34.872663 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 217[0m in 1.94s]
[0m12:39:34.873193 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:39:34.873566 [debug] [Thread-1 (]: Began running node model.bde.fact_G01
[0m12:39:34.874025 [info ] [Thread-1 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:39:34.874646 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.fact_G01)
[0m12:39:34.874980 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G01
[0m12:39:34.877827 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:39:34.878603 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (compile): 12:39:34.875215 => 12:39:34.878437
[0m12:39:34.878948 [debug] [Thread-1 (]: Began executing node model.bde.fact_G01
[0m12:39:34.882106 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:39:34.882443 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:39:34.884977 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:39:34.885354 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:39:34.885741 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:39:34.886044 [debug] [Thread-1 (]: On model.bde.fact_G01: BEGIN
[0m12:39:34.886304 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:39:34.894969 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:34.897204 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:39:34.897632 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:39:34.907420 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:34.909003 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:39:34.909310 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:39:34.909579 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:39:34.929295 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:34.931673 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:39:34.932029 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:39:34.948168 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:39:34.949397 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 12:39:34.712818 => 12:39:34.949242
[0m12:39:34.949765 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m12:39:34.950483 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109de2e00>]}
[0m12:39:34.951043 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.24s]
[0m12:39:34.951574 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m12:39:34.951947 [debug] [Thread-4 (]: Began running node model.bde.fact_G02
[0m12:39:34.952387 [info ] [Thread-4 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:39:34.952925 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G02)
[0m12:39:34.953228 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G02
[0m12:39:34.955821 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:39:34.956435 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (compile): 12:39:34.953437 => 12:39:34.956296
[0m12:39:34.956743 [debug] [Thread-4 (]: Began executing node model.bde.fact_G02
[0m12:39:34.961027 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:39:34.961499 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:39:34.961757 [debug] [Thread-4 (]: On model.bde.fact_G02: BEGIN
[0m12:39:34.962000 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:39:35.005847 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:35.006241 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:39:35.006476 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:39:35.034233 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:39:35.036605 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:39:35.036861 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:39:35.069477 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:35.069734 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:39:35.069990 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:39:35.095658 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:39:35.098190 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:39:35.098495 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:39:35.107488 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:35.109682 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:39:35.109982 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:39:35.119379 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:35.120781 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:39:35.121069 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:39:35.121339 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m12:39:35.132124 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:35.134197 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m12:39:35.134492 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:39:35.150419 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:39:35.151632 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (execute): 12:39:34.956952 => 12:39:35.151476
[0m12:39:35.151978 [debug] [Thread-4 (]: On model.bde.fact_G02: Close
[0m12:39:35.152736 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f04db10>]}
[0m12:39:35.153244 [info ] [Thread-4 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.20s]
[0m12:39:35.153703 [debug] [Thread-4 (]: Finished running node model.bde.fact_G02
[0m12:39:35.154043 [debug] [Thread-4 (]: Began running node model.bde.fact_listing
[0m12:39:35.154447 [info ] [Thread-4 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:39:35.154956 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.fact_listing)
[0m12:39:35.155229 [debug] [Thread-4 (]: Began compiling node model.bde.fact_listing
[0m12:39:35.157756 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:39:35.158392 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (compile): 12:39:35.155424 => 12:39:35.158257
[0m12:39:35.158697 [debug] [Thread-4 (]: Began executing node model.bde.fact_listing
[0m12:39:35.162068 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:39:35.162767 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:39:35.163036 [debug] [Thread-4 (]: On model.bde.fact_listing: BEGIN
[0m12:39:35.163272 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:39:35.263452 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:35.264054 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:39:35.264479 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:35.265040 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:39:35.268542 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:39:35.268978 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:39:35.284291 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:35.286280 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:39:35.286666 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:39:35.287010 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:39:35.299340 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:35.304133 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:39:35.304557 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:39:35.320810 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:39:35.322372 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (execute): 12:39:34.879181 => 12:39:35.322172
[0m12:39:35.322787 [debug] [Thread-1 (]: On model.bde.fact_G01: Close
[0m12:39:35.323807 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0bf4f0>]}
[0m12:39:35.324496 [info ] [Thread-1 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.45s]
[0m12:39:35.325124 [debug] [Thread-1 (]: Finished running node model.bde.fact_G01
[0m12:39:35.325583 [debug] [Thread-1 (]: Began running node model.bde.dim_host
[0m12:39:35.326135 [info ] [Thread-1 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:39:35.326901 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.dim_host)
[0m12:39:35.327301 [debug] [Thread-1 (]: Began compiling node model.bde.dim_host
[0m12:39:35.330487 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:39:35.331399 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (compile): 12:39:35.327570 => 12:39:35.331229
[0m12:39:35.331754 [debug] [Thread-1 (]: Began executing node model.bde.dim_host
[0m12:39:35.335294 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:39:35.335917 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:39:35.336199 [debug] [Thread-1 (]: On model.bde.dim_host: BEGIN
[0m12:39:35.336473 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:39:35.444704 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:35.445395 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:39:35.445933 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    scraped_date,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:39:36.137158 [debug] [Thread-1 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m12:39:36.144443 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:39:36.145069 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:39:37.869817 [debug] [Thread-2 (]: SQL status: SELECT 296 in 5.0 seconds
[0m12:39:37.878514 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:39:37.879394 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:39:37.891270 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:37.897050 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:39:37.897773 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:39:37.907999 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:37.911095 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:39:37.912281 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:39:37.912845 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:39:37.935719 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:37.940758 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:39:37.941477 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:39:37.967342 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:39:37.972057 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:39:32.976433 => 12:39:37.971251
[0m12:39:37.972862 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:39:37.974688 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109de83d0>]}
[0m12:39:37.975587 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 5.04s]
[0m12:39:37.976399 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:39:37.976953 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m12:39:37.977680 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:39:37.978664 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m12:39:37.979130 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m12:39:37.982843 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:39:37.983918 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 12:39:37.979416 => 12:39:37.983720
[0m12:39:37.984324 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m12:39:37.989656 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:39:37.990379 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:39:37.990709 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m12:39:37.991018 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:39:38.111917 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:38.113582 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:39:38.114295 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:39:38.439659 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 5.0 seconds
[0m12:39:38.449764 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:39:38.450344 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m12:39:38.460823 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:38.463754 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:39:38.464081 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m12:39:38.472728 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:38.474082 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:39:38.474369 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:39:38.474608 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:39:38.506514 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:38.508888 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:39:38.509266 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m12:39:38.516882 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 2.0 seconds
[0m12:39:38.519396 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:39:38.519692 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:39:38.524148 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:39:38.526885 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:39:38.527228 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:39:38.538199 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:38.538593 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:39:38.540197 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m12:39:38.541370 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:39:32.982505 => 12:39:38.541197
[0m12:39:38.541712 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:39:38.542136 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:39:38.542504 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m12:39:38.543418 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109db0ee0>]}
[0m12:39:38.544229 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:38.543986 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 5.61s]
[0m12:39:38.546630 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:39:38.547095 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:39:38.547423 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:39:38.547781 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m12:39:38.548243 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:39:38.548767 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m12:39:38.549062 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m12:39:38.551524 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:39:38.552138 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 12:39:38.549262 => 12:39:38.552018
[0m12:39:38.552397 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m12:39:38.555165 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:39:38.555609 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:39:38.555850 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m12:39:38.556078 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:39:38.558301 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:38.559539 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:39:38.559807 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:39:38.561299 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:38.561547 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:39:38.563206 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:39:38.563511 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:39:38.578677 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:38.580882 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:39:38.581200 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:39:38.586656 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:39:38.587957 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (execute): 12:39:35.331990 => 12:39:38.587826
[0m12:39:38.588254 [debug] [Thread-1 (]: On model.bde.dim_host: Close
[0m12:39:38.588946 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f12ff70>]}
[0m12:39:38.589362 [info ] [Thread-1 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 3.26s]
[0m12:39:38.589748 [debug] [Thread-1 (]: Finished running node model.bde.dim_host
[0m12:39:38.590031 [debug] [Thread-1 (]: Began running node model.bde.dim_suburb
[0m12:39:38.590310 [info ] [Thread-1 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:39:38.590737 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dim_host, now model.bde.dim_suburb)
[0m12:39:38.590969 [debug] [Thread-1 (]: Began compiling node model.bde.dim_suburb
[0m12:39:38.594085 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:39:38.594793 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (compile): 12:39:38.591382 => 12:39:38.594665
[0m12:39:38.595040 [debug] [Thread-1 (]: Began executing node model.bde.dim_suburb
[0m12:39:38.597604 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:39:38.598045 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:39:38.598269 [debug] [Thread-1 (]: On model.bde.dim_suburb: BEGIN
[0m12:39:38.598462 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:39:38.605000 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:39:38.605959 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 12:39:37.984592 => 12:39:38.605862
[0m12:39:38.606178 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m12:39:38.606665 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ec3d60>]}
[0m12:39:38.606976 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 0.63s]
[0m12:39:38.607286 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m12:39:38.678830 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:38.679352 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:39:38.679678 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:39:38.947180 [debug] [Thread-4 (]: SQL status: SELECT 340945 in 4.0 seconds
[0m12:39:38.957452 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:39:38.958395 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:39:38.969146 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:38.974639 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:39:38.975238 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:39:38.975867 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:39:38.979889 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:39:38.980306 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:39:38.980874 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:39:38.981325 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:39:38.981804 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:39:38.989633 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:38.991676 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m12:39:38.992060 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:38.992464 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:39:38.995443 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:39:38.995802 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m12:39:38.996125 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:39:38.999942 [debug] [Thread-1 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:39:39.004494 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:39:39.004864 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:39:39.005428 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:39.007159 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:39:39.007500 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:39:39.007808 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:39:39.012298 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:39.014507 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:39:39.014848 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:39:39.015201 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:39.017425 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:39:39.017727 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:39:39.026596 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:39.028493 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:39:39.028786 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:39:39.034221 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:39:39.035725 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m12:39:39.036059 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:39:39.036352 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m12:39:39.046846 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:39:39.048136 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 12:39:38.552564 => 12:39:39.047959
[0m12:39:39.048460 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:39:39.048825 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m12:39:39.051201 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:39:39.051558 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:39:39.051953 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:39:39.052618 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e30a60>]}
[0m12:39:39.053760 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (execute): 12:39:35.158895 => 12:39:39.053632
[0m12:39:39.054324 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.50s]
[0m12:39:39.054688 [debug] [Thread-4 (]: On model.bde.fact_listing: Close
[0m12:39:39.055112 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m12:39:39.055771 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0a3580>]}
[0m12:39:39.056200 [info ] [Thread-4 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 3.90s]
[0m12:39:39.056655 [debug] [Thread-4 (]: Finished running node model.bde.fact_listing
[0m12:39:39.069825 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:39:39.071009 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (execute): 12:39:38.595196 => 12:39:39.070872
[0m12:39:39.071321 [debug] [Thread-1 (]: On model.bde.dim_suburb: Close
[0m12:39:39.071961 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e14056cd-45ae-4410-84df-3804326b7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109dc3430>]}
[0m12:39:39.072384 [info ] [Thread-1 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.48s]
[0m12:39:39.072829 [debug] [Thread-1 (]: Finished running node model.bde.dim_suburb
[0m12:39:39.074087 [debug] [MainThread]: Using postgres connection "master"
[0m12:39:39.074348 [debug] [MainThread]: On master: BEGIN
[0m12:39:39.074571 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:39:39.173441 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:39:39.173902 [debug] [MainThread]: On master: COMMIT
[0m12:39:39.174146 [debug] [MainThread]: Using postgres connection "master"
[0m12:39:39.174388 [debug] [MainThread]: On master: COMMIT
[0m12:39:39.182806 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:39:39.183046 [debug] [MainThread]: On master: Close
[0m12:39:39.183593 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:39:39.183817 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:39:39.184007 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m12:39:39.184186 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:39:39.184363 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:39:39.184645 [info ] [MainThread]: 
[0m12:39:39.184899 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 6.74 seconds (6.74s).
[0m12:39:39.186780 [debug] [MainThread]: Command end result
[0m12:39:39.194236 [info ] [MainThread]: 
[0m12:39:39.194579 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:39:39.194825 [info ] [MainThread]: 
[0m12:39:39.195067 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m12:39:39.195514 [debug] [MainThread]: Command `dbt run` succeeded at 12:39:39.195449 after 6.89 seconds
[0m12:39:39.195787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074c18a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f150040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f023d30>]}
[0m12:39:39.196060 [debug] [MainThread]: Flushing usage events
[0m12:41:23.639258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105098f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ff5a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ff5390>]}


============================== 12:41:23.641935 | 8c702e29-5aa2-4983-8861-d8e6db2f3550 ==============================
[0m12:41:23.641935 [info ] [MainThread]: Running with dbt=1.6.6
[0m12:41:23.642253 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'version_check': 'True', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:41:23.694405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ff55a0>]}
[0m12:41:23.702277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074390f0>]}
[0m12:41:23.702839 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m12:41:23.724989 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m12:41:23.747796 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:41:23.748165 [debug] [MainThread]: Partial parsing: updated file: bde://models/datamart/dm_host_neighbourhod.sql
[0m12:41:23.768492 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.raw
- models.bde.median
[0m12:41:23.771285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a44bb0>]}
[0m12:41:23.777548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10787ec50>]}
[0m12:41:23.777794 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m12:41:23.777976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10787ee60>]}
[0m12:41:23.779118 [info ] [MainThread]: 
[0m12:41:23.779497 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:41:23.780390 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:41:23.780890 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:41:23.781298 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m12:41:23.786376 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:41:23.787354 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:41:23.788237 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m12:41:23.788436 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:41:23.788637 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:41:23.788812 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m12:41:23.788965 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:41:23.789121 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:41:23.789256 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:41:23.935224 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:41:23.935602 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:41:23.936953 [debug] [ThreadPool]: On list_postgres: Close
[0m12:41:23.937181 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m12:41:23.937989 [debug] [ThreadPool]: On list_postgres: Close
[0m12:41:23.938787 [debug] [ThreadPool]: On list_postgres: Close
[0m12:41:23.940891 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m12:41:23.941359 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_staging)
[0m12:41:23.945794 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:41:23.946205 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_warehouse)
[0m12:41:23.946749 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_datamart'
[0m12:41:23.948203 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:41:23.948477 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m12:41:23.949536 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:41:23.950589 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:41:23.950794 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m12:41:23.950976 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:41:23.951150 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m12:41:23.951315 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m12:41:23.951482 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:41:23.951778 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:41:23.951992 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:41:24.048610 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:41:24.049107 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m12:41:24.049397 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m12:41:24.058046 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:41:24.058280 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m12:41:24.058524 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m12:41:24.062904 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:41:24.063199 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m12:41:24.063461 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m12:41:24.063848 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:41:24.064066 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m12:41:24.064299 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m12:41:24.064626 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:41:24.065696 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m12:41:24.071660 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:41:24.072526 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m12:41:24.074942 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m12:41:24.079420 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:41:24.080443 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m12:41:24.080752 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:41:24.081011 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m12:41:24.081997 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m12:41:24.114155 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m12:41:24.114401 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m12:41:24.120455 [debug] [MainThread]: Using postgres connection "master"
[0m12:41:24.120716 [debug] [MainThread]: On master: BEGIN
[0m12:41:24.120919 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:41:24.237164 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:41:24.237678 [debug] [MainThread]: Using postgres connection "master"
[0m12:41:24.238073 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:41:24.262297 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:41:24.264656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a60fd0>]}
[0m12:41:24.265090 [debug] [MainThread]: On master: ROLLBACK
[0m12:41:24.276000 [debug] [MainThread]: Using postgres connection "master"
[0m12:41:24.276289 [debug] [MainThread]: On master: BEGIN
[0m12:41:24.296113 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:41:24.296453 [debug] [MainThread]: On master: COMMIT
[0m12:41:24.296706 [debug] [MainThread]: Using postgres connection "master"
[0m12:41:24.296944 [debug] [MainThread]: On master: COMMIT
[0m12:41:24.306011 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:41:24.306440 [debug] [MainThread]: On master: Close
[0m12:41:24.307264 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:41:24.307644 [info ] [MainThread]: 
[0m12:41:24.311398 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m12:41:24.311778 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m12:41:24.312100 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m12:41:24.312416 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m12:41:24.312801 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m12:41:24.313330 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m12:41:24.313808 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m12:41:24.314180 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m12:41:24.314747 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_host_neighbourhod)
[0m12:41:24.315238 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.dm_listing_neighbourhood)
[0m12:41:24.315711 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.dm_property_type)
[0m12:41:24.316204 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.stg_G01)
[0m12:41:24.316554 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m12:41:24.316844 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m12:41:24.317147 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m12:41:24.317413 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m12:41:24.323658 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m12:41:24.326349 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m12:41:24.329698 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m12:41:24.331986 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m12:41:24.332674 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 12:41:24.317635 => 12:41:24.332493
[0m12:41:24.333288 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m12:41:24.333627 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 12:41:24.323940 => 12:41:24.333465
[0m12:41:24.333934 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 12:41:24.326625 => 12:41:24.333826
[0m12:41:24.339298 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 12:41:24.329947 => 12:41:24.339177
[0m12:41:24.357415 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m12:41:24.357693 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m12:41:24.357950 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m12:41:24.358167 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m12:41:24.360339 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m12:41:24.362405 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m12:41:24.368971 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:41:24.372949 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m12:41:24.373357 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m12:41:24.373620 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:41:24.373900 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:41:24.374151 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:41:24.374389 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m12:41:24.374757 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:41:24.375004 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m12:41:24.375216 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:41:24.375412 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m12:41:24.375586 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:41:24.375851 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:41:24.464486 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:24.464922 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:41:24.465296 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    -- Set the configuration for the materialized view


-- Create a Common Table Expression (CTE) called host_neighbourhood_lga_transform
-- This CTE retrieves data from the dim_host and dim_suburb tables and transforms it.
-- It includes host data, host neighborhood's local government area, and month_year.

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM warehouse.dim_host host
    LEFT JOIN warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
-- Create a CTE called distinct_host_count
-- This CTE calculates the number of distinct hosts for each host_neighbourhood_lga and month_year.
distinct_host_count AS (
    SELECT
        TO_CHAR(ht.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        COUNT(DISTINCT ht.host_id) AS num_distinct_hosts
    FROM host_neighbourhood_lga_transform ht
    GROUP BY TO_CHAR(ht.scraped_date, 'MM/YYYY'),ht.host_neighbourhood_lga
),
-- Create a CTE called estimated_revenue
-- This CTE calculates the total estimated revenue for each host_neighbourhood_lga and month_year.
estimated_revenue AS (
    SELECT
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        SUM((30 - list.availability_30) * list.price) AS total_estimated_revenue
    FROM warehouse.fact_listing list
    LEFT JOIN host_neighbourhood_lga_transform ht ON list.surrogate_key_host = ht.surrogate_key_host
    WHERE list.has_availability = 't'
    GROUP BY
        TO_CHAR(list.scraped_date, 'MM/YYYY'),
        ht.host_neighbourhood_lga
)
-- Select the aggregated metrics including month_year, host_neighbourhood_lga, number of distinct hosts, total estimated revenue, and estimated revenue per host.
SELECT
    dh.host_neighbourhood_lga,
    dh.month_year,
    dh.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dh.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dh.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM distinct_host_count dh
LEFT JOIN estimated_revenue er ON dh.month_year = er.month_year AND dh.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY dh.host_neighbourhood_lga, dh.month_year
  );
  
[0m12:41:24.468925 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:24.469261 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:41:24.469710 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,     
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m12:41:24.470250 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:24.470507 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:41:24.470973 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type

-- Set the configuration for the materialized view



-- Create a Common Table Expression (CTE) called sorted_listing
-- This CTE retrieves data from multiple tables and calculates various metrics
-- It includes property_type, room_type, accommodates, and more.


WITH sorted_listing AS (
    SELECT 
        prop.property_type,-- Property type
        room.room_type,-- Room type
        list.accommodates,-- Accommodates
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year, -- Truncate the date to the month
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id, -- Host ID
        host.host_is_superhost,-- Host is superhost flag
        review_scores_rating,-- Review scores rating
        availability_30-- Availability for the next 30 days
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
-- Select the aggregated metrics for the property_type, room_type, accommodates, and month_year
SELECT 
    property_type,-- Property type
    room_type,-- Room type
    accommodates,-- Number of accommodates
    month_year,-- Truncated month and year
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,-- Calculate the minimum price for active listings
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,-- Calculate the maximum price for active listings
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing, -- Calculate the median price for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts, -- Count the number of distinct hosts
     -- Calculate the superhost rate
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
     -- Calculate the average review scores rating for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


     -- Calculate the percentage change for active listing
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing

    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m12:41:24.474193 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:24.474436 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:41:24.474810 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:41:24.509360 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:41:24.515398 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:41:24.515776 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m12:41:24.527017 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:24.529486 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:41:24.529800 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m12:41:24.540936 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:24.550259 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:41:24.550538 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:41:24.550737 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m12:41:24.561469 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:24.566736 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m12:41:24.567000 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m12:41:24.579201 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:41:24.580349 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 12:41:24.362590 => 12:41:24.580222
[0m12:41:24.580643 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m12:41:24.581296 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b16aa0>]}
[0m12:41:24.581690 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.27s]
[0m12:41:24.582047 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m12:41:24.582313 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m12:41:24.582679 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m12:41:24.583116 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m12:41:24.583344 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m12:41:24.585428 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m12:41:24.585961 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 12:41:24.583506 => 12:41:24.585869
[0m12:41:24.586161 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m12:41:24.588526 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m12:41:24.589032 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:41:24.589234 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m12:41:24.589431 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:41:24.691557 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:24.691989 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:41:24.692404 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:41:24.709484 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:41:24.712729 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:41:24.713096 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m12:41:24.722326 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:24.724786 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:41:24.725132 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m12:41:24.734090 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:24.735758 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:41:24.736101 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:41:24.736409 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m12:41:24.745877 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:24.748421 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m12:41:24.748848 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m12:41:24.763587 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:41:24.764960 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 12:41:24.586295 => 12:41:24.764794
[0m12:41:24.765355 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m12:41:24.766191 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a95900>]}
[0m12:41:24.766750 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.18s]
[0m12:41:24.767339 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m12:41:24.767728 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m12:41:24.768238 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m12:41:24.768912 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m12:41:24.769251 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m12:41:24.773631 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m12:41:24.774264 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 12:41:24.769466 => 12:41:24.774133
[0m12:41:24.774545 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m12:41:24.777670 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m12:41:24.778223 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:41:24.778500 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m12:41:24.778753 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:41:24.884935 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:24.885511 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:41:24.886012 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m12:41:24.899058 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:41:24.902832 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:41:24.903264 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m12:41:24.914576 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:24.917547 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:41:24.917964 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m12:41:24.927331 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:24.929041 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:41:24.929445 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:41:24.929829 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m12:41:24.942397 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:24.945099 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m12:41:24.945503 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m12:41:24.956038 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:41:24.957497 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 12:41:24.774745 => 12:41:24.957297
[0m12:41:24.957913 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m12:41:24.958874 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b86d10>]}
[0m12:41:24.959530 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.19s]
[0m12:41:24.960152 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m12:41:24.960607 [debug] [Thread-4 (]: Began running node model.bde.stg_fact
[0m12:41:24.961343 [info ] [Thread-4 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m12:41:24.962314 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_fact)
[0m12:41:24.962843 [debug] [Thread-4 (]: Began compiling node model.bde.stg_fact
[0m12:41:24.966271 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m12:41:24.966999 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (compile): 12:41:24.963136 => 12:41:24.966834
[0m12:41:24.967329 [debug] [Thread-4 (]: Began executing node model.bde.stg_fact
[0m12:41:24.970924 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m12:41:24.971514 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:41:24.971954 [debug] [Thread-4 (]: On model.bde.stg_fact: BEGIN
[0m12:41:24.972373 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:41:25.074573 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:25.075323 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:41:25.075902 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m12:41:25.092796 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:41:25.097730 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:41:25.098197 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m12:41:25.109530 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:25.115396 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:41:25.116005 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m12:41:25.125703 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:25.127686 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:41:25.128091 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:41:25.128454 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m12:41:25.138922 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:25.185033 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m12:41:25.185447 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m12:41:25.197055 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:41:25.198308 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (execute): 12:41:24.967552 => 12:41:25.198169
[0m12:41:25.198657 [debug] [Thread-4 (]: On model.bde.stg_fact: Close
[0m12:41:25.199329 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073ff310>]}
[0m12:41:25.199728 [info ] [Thread-4 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.24s]
[0m12:41:25.200084 [debug] [Thread-4 (]: Finished running node model.bde.stg_fact
[0m12:41:25.200340 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m12:41:25.200812 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m12:41:25.201361 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_host)
[0m12:41:25.201632 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m12:41:25.203855 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m12:41:25.204465 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 12:41:25.201805 => 12:41:25.204351
[0m12:41:25.204696 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m12:41:25.207149 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m12:41:25.207586 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:41:25.207797 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m12:41:25.207990 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:41:25.313935 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:25.314459 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:41:25.314932 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m12:41:25.330613 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:41:25.333858 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:41:25.334212 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m12:41:25.343912 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:25.346580 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:41:25.346957 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m12:41:25.357467 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:25.359259 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:41:25.359655 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:41:25.360019 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m12:41:25.370123 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:25.372779 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m12:41:25.373230 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m12:41:25.384211 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:41:25.385766 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 12:41:25.204840 => 12:41:25.385570
[0m12:41:25.386182 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m12:41:25.387157 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a4fac0>]}
[0m12:41:25.387825 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.19s]
[0m12:41:25.388469 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m12:41:25.388888 [debug] [Thread-4 (]: Began running node model.bde.stg_property
[0m12:41:25.389489 [info ] [Thread-4 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m12:41:25.390225 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_property)
[0m12:41:25.390589 [debug] [Thread-4 (]: Began compiling node model.bde.stg_property
[0m12:41:25.393758 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_property"
[0m12:41:25.394636 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (compile): 12:41:25.390832 => 12:41:25.394448
[0m12:41:25.394997 [debug] [Thread-4 (]: Began executing node model.bde.stg_property
[0m12:41:25.398323 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_property"
[0m12:41:25.398883 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:41:25.399172 [debug] [Thread-4 (]: On model.bde.stg_property: BEGIN
[0m12:41:25.399454 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:41:25.513904 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:25.514849 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:41:25.515498 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m12:41:25.530387 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:41:25.538143 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:41:25.538736 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m12:41:25.549033 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:25.552123 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:41:25.552549 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m12:41:25.562907 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:25.564647 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:41:25.565043 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:41:25.565428 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m12:41:25.575288 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:25.578033 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m12:41:25.578451 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m12:41:25.589378 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:41:25.591136 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (execute): 12:41:25.395227 => 12:41:25.590913
[0m12:41:25.591567 [debug] [Thread-4 (]: On model.bde.stg_property: Close
[0m12:41:25.592537 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ac7460>]}
[0m12:41:25.593204 [info ] [Thread-4 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.20s]
[0m12:41:25.593886 [debug] [Thread-4 (]: Finished running node model.bde.stg_property
[0m12:41:25.594354 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m12:41:25.595067 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m12:41:25.595891 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_room)
[0m12:41:25.596325 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m12:41:25.599994 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m12:41:25.600911 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 12:41:25.596623 => 12:41:25.600732
[0m12:41:25.601270 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m12:41:25.604846 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m12:41:25.605653 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:41:25.605980 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m12:41:25.606259 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:41:25.727345 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:25.728703 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:41:25.729393 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m12:41:25.744492 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:41:25.752377 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:41:25.753025 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m12:41:25.762337 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:25.766265 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:41:25.766770 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m12:41:25.776046 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:25.778065 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:41:25.778526 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:41:25.778958 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m12:41:25.789500 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:25.794367 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m12:41:25.794853 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m12:41:25.805942 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:41:25.807667 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 12:41:25.601508 => 12:41:25.807441
[0m12:41:25.808151 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m12:41:25.809217 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b6a170>]}
[0m12:41:25.809888 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.21s]
[0m12:41:25.810509 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m12:41:25.810977 [debug] [Thread-4 (]: Began running node model.bde.stg_suburb
[0m12:41:25.811648 [info ] [Thread-4 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m12:41:25.812957 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.stg_suburb)
[0m12:41:25.813496 [debug] [Thread-4 (]: Began compiling node model.bde.stg_suburb
[0m12:41:25.818757 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m12:41:25.819846 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (compile): 12:41:25.813795 => 12:41:25.819617
[0m12:41:25.820273 [debug] [Thread-4 (]: Began executing node model.bde.stg_suburb
[0m12:41:25.824217 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m12:41:25.824965 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:41:25.825252 [debug] [Thread-4 (]: On model.bde.stg_suburb: BEGIN
[0m12:41:25.825525 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:41:25.938918 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:25.939747 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:41:25.940245 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m12:41:25.951344 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:41:25.956157 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:41:25.956603 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m12:41:25.967273 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:25.970517 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:41:25.970948 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m12:41:25.980650 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:25.982558 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m12:41:25.982945 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:41:25.983304 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m12:41:25.993420 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:25.996174 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m12:41:25.996581 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m12:41:26.007223 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m12:41:26.008697 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (execute): 12:41:25.820504 => 12:41:26.008493
[0m12:41:26.009128 [debug] [Thread-4 (]: On model.bde.stg_suburb: Close
[0m12:41:26.010125 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a75b40>]}
[0m12:41:26.010883 [info ] [Thread-4 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.20s]
[0m12:41:26.011574 [debug] [Thread-4 (]: Finished running node model.bde.stg_suburb
[0m12:41:26.012047 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m12:41:26.012737 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m12:41:26.013507 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.dim_LGA)
[0m12:41:26.013951 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m12:41:26.017356 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m12:41:26.018382 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 12:41:26.014237 => 12:41:26.018209
[0m12:41:26.018744 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m12:41:26.022405 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m12:41:26.023022 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:41:26.023308 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m12:41:26.023571 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:41:26.274027 [debug] [Thread-1 (]: SQL status: SELECT 217 in 2.0 seconds
[0m12:41:26.278298 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:41:26.278780 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m12:41:26.288875 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:26.293696 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:41:26.294068 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m12:41:26.314371 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:26.320320 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:41:26.320747 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:41:26.321080 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m12:41:26.347831 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:26.353161 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m12:41:26.353650 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m12:41:26.422082 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:41:26.426525 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 12:41:24.334123 => 12:41:26.426202
[0m12:41:26.427373 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m12:41:26.428648 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107989cc0>]}
[0m12:41:26.429565 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 217[0m in 2.11s]
[0m12:41:26.430369 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m12:41:26.430975 [debug] [Thread-1 (]: Began running node model.bde.fact_G01
[0m12:41:26.431699 [info ] [Thread-1 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m12:41:26.432691 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.fact_G01)
[0m12:41:26.433213 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G01
[0m12:41:26.436864 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m12:41:26.437903 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (compile): 12:41:26.433508 => 12:41:26.437688
[0m12:41:26.438314 [debug] [Thread-1 (]: Began executing node model.bde.fact_G01
[0m12:41:26.442211 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m12:41:26.442842 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:41:26.443170 [debug] [Thread-1 (]: On model.bde.fact_G01: BEGIN
[0m12:41:26.443491 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:41:26.552673 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:26.553108 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:41:26.553318 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:41:26.580126 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:41:26.582742 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:41:26.583158 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m12:41:26.594620 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:26.596806 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:41:26.597069 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m12:41:26.597587 [debug] [Thread-4 (]: SQL status: BEGIN in 1.0 seconds
[0m12:41:26.597800 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:41:26.598012 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m12:41:26.607009 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:26.608207 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:41:26.608412 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:41:26.608595 [debug] [Thread-1 (]: On model.bde.fact_G01: COMMIT
[0m12:41:26.616386 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:41:26.618151 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:41:26.618370 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m12:41:26.626917 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:26.627166 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:26.628602 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G01"
[0m12:41:26.631025 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:41:26.631249 [debug] [Thread-1 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m12:41:26.631452 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m12:41:26.642304 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:26.643285 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:41:26.643491 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:41:26.643675 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m12:41:26.645371 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:41:26.646351 [debug] [Thread-1 (]: Timing info for model.bde.fact_G01 (execute): 12:41:26.438586 => 12:41:26.646234
[0m12:41:26.646633 [debug] [Thread-1 (]: On model.bde.fact_G01: Close
[0m12:41:26.647264 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a793f0>]}
[0m12:41:26.647653 [info ] [Thread-1 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.21s]
[0m12:41:26.647959 [debug] [Thread-1 (]: Finished running node model.bde.fact_G01
[0m12:41:26.648180 [debug] [Thread-1 (]: Began running node model.bde.fact_G02
[0m12:41:26.648522 [info ] [Thread-1 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m12:41:26.649020 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_G02)
[0m12:41:26.649256 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G02
[0m12:41:26.651358 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m12:41:26.651903 [debug] [Thread-1 (]: Timing info for model.bde.fact_G02 (compile): 12:41:26.649403 => 12:41:26.651799
[0m12:41:26.652120 [debug] [Thread-1 (]: Began executing node model.bde.fact_G02
[0m12:41:26.654353 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m12:41:26.654880 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:41:26.655078 [debug] [Thread-1 (]: On model.bde.fact_G02: BEGIN
[0m12:41:26.655260 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:41:26.655791 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:26.657370 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m12:41:26.657591 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m12:41:26.674515 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:41:26.675522 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 12:41:26.018985 => 12:41:26.675426
[0m12:41:26.675759 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m12:41:26.676267 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b77370>]}
[0m12:41:26.676627 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.66s]
[0m12:41:26.676992 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m12:41:26.677253 [debug] [Thread-4 (]: Began running node model.bde.fact_listing
[0m12:41:26.677556 [info ] [Thread-4 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m12:41:26.677908 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_listing)
[0m12:41:26.678122 [debug] [Thread-4 (]: Began compiling node model.bde.fact_listing
[0m12:41:26.680035 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m12:41:26.680523 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (compile): 12:41:26.678256 => 12:41:26.680424
[0m12:41:26.680737 [debug] [Thread-4 (]: Began executing node model.bde.fact_listing
[0m12:41:26.683139 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m12:41:26.683627 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:41:26.683828 [debug] [Thread-4 (]: On model.bde.fact_listing: BEGIN
[0m12:41:26.684008 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:41:26.766946 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:26.767398 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:41:26.767714 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m12:41:26.787033 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m12:41:26.789883 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:41:26.790212 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m12:41:26.822133 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:26.824551 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:41:26.824898 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:26.825306 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m12:41:26.825668 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:41:26.826111 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m12:41:26.834640 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:26.836308 [debug] [Thread-1 (]: On model.bde.fact_G02: COMMIT
[0m12:41:26.836632 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:41:26.836923 [debug] [Thread-1 (]: On model.bde.fact_G02: COMMIT
[0m12:41:26.847184 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:26.850905 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m12:41:26.851270 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m12:41:26.868576 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:41:26.870036 [debug] [Thread-1 (]: Timing info for model.bde.fact_G02 (execute): 12:41:26.652259 => 12:41:26.869828
[0m12:41:26.870438 [debug] [Thread-1 (]: On model.bde.fact_G02: Close
[0m12:41:26.871317 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a87fa0>]}
[0m12:41:26.871953 [info ] [Thread-1 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.22s]
[0m12:41:26.872556 [debug] [Thread-1 (]: Finished running node model.bde.fact_G02
[0m12:41:26.872989 [debug] [Thread-1 (]: Began running node model.bde.dim_host
[0m12:41:26.873513 [info ] [Thread-1 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m12:41:26.874224 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m12:41:26.874572 [debug] [Thread-1 (]: Began compiling node model.bde.dim_host
[0m12:41:26.877525 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_host"
[0m12:41:26.878334 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (compile): 12:41:26.874816 => 12:41:26.878166
[0m12:41:26.878690 [debug] [Thread-1 (]: Began executing node model.bde.dim_host
[0m12:41:26.882021 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_host"
[0m12:41:26.882526 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:41:26.882820 [debug] [Thread-1 (]: On model.bde.dim_host: BEGIN
[0m12:41:26.883114 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:41:26.991394 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:26.992426 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:41:26.992969 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    scraped_date,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m12:41:27.773068 [debug] [Thread-1 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m12:41:27.777761 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:41:27.778302 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m12:41:28.900638 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m12:41:28.908836 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:41:28.909718 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m12:41:28.919906 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:28.923975 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:41:28.924461 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m12:41:28.932986 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:28.935404 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:41:28.935882 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:41:28.936298 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m12:41:28.970403 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:28.976575 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m12:41:28.977522 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m12:41:29.002748 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:41:29.006933 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 12:41:24.358398 => 12:41:29.006465
[0m12:41:29.007931 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m12:41:29.009711 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107aa6230>]}
[0m12:41:29.010694 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 4.69s]
[0m12:41:29.011378 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m12:41:29.011863 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m12:41:29.012479 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m12:41:29.013313 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m12:41:29.013731 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m12:41:29.017443 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m12:41:29.018408 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 12:41:29.014030 => 12:41:29.018241
[0m12:41:29.018743 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m12:41:29.023937 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m12:41:29.024579 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:41:29.024856 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m12:41:29.025117 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:41:29.125207 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:29.126004 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:41:29.126529 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m12:41:29.718992 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m12:41:29.726961 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:41:29.727780 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m12:41:30.015670 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 6.0 seconds
[0m12:41:30.024540 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:41:30.025590 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m12:41:30.036500 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:30.041944 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:41:30.042681 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m12:41:30.054048 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:30.056743 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:41:30.057252 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:41:30.057702 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m12:41:30.093135 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:30.094145 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:30.094756 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 2.0 seconds
[0m12:41:30.100601 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:41:30.104792 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m12:41:30.107900 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:41:30.108350 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m12:41:30.108760 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m12:41:30.109146 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m12:41:30.117479 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:30.119417 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:41:30.119801 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:30.120174 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:41:30.121998 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m12:41:30.122387 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m12:41:30.122748 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:41:30.123187 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m12:41:30.137544 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:41:30.138936 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 12:41:24.360558 => 12:41:30.138743
[0m12:41:30.139365 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m12:41:30.140340 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a94df0>]}
[0m12:41:30.141008 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 5.82s]
[0m12:41:30.141644 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m12:41:30.142086 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m12:41:30.142613 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m12:41:30.143024 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:30.143643 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m12:41:30.146114 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m12:41:30.146460 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m12:41:30.146787 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m12:41:30.150129 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m12:41:30.150458 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:30.153863 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m12:41:30.154212 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m12:41:30.154724 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 12:41:30.147361 => 12:41:30.154571
[0m12:41:30.155015 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m12:41:30.158190 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m12:41:30.158730 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:41:30.158998 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m12:41:30.159255 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:41:30.172588 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:41:30.173675 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 12:41:29.018975 => 12:41:30.173556
[0m12:41:30.173947 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m12:41:30.174542 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c87c10>]}
[0m12:41:30.174944 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 1.16s]
[0m12:41:30.175375 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m12:41:30.175675 [debug] [Thread-2 (]: Began running node model.bde.dim_suburb
[0m12:41:30.176051 [info ] [Thread-2 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m12:41:30.176551 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dim_property, now model.bde.dim_suburb)
[0m12:41:30.176822 [debug] [Thread-2 (]: Began compiling node model.bde.dim_suburb
[0m12:41:30.178979 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m12:41:30.179248 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:41:30.180269 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (execute): 12:41:26.878915 => 12:41:30.180145
[0m12:41:30.180577 [debug] [Thread-1 (]: On model.bde.dim_host: Close
[0m12:41:30.180943 [debug] [Thread-2 (]: Timing info for model.bde.dim_suburb (compile): 12:41:30.176999 => 12:41:30.180808
[0m12:41:30.181433 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c87f40>]}
[0m12:41:30.181934 [debug] [Thread-2 (]: Began executing node model.bde.dim_suburb
[0m12:41:30.182404 [info ] [Thread-1 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 3.31s]
[0m12:41:30.185300 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m12:41:30.185673 [debug] [Thread-1 (]: Finished running node model.bde.dim_host
[0m12:41:30.186146 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:41:30.186376 [debug] [Thread-2 (]: On model.bde.dim_suburb: BEGIN
[0m12:41:30.186595 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:41:30.277132 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:30.277575 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:41:30.277949 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m12:41:30.290450 [debug] [Thread-4 (]: SQL status: SELECT 340945 in 3.0 seconds
[0m12:41:30.293474 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:41:30.293825 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m12:41:30.300387 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m12:41:30.300698 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:41:30.301012 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m12:41:30.302962 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:30.305482 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:41:30.305837 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m12:41:30.314791 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:30.316532 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m12:41:30.316855 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:41:30.317150 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m12:41:30.320808 [debug] [Thread-2 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m12:41:30.323429 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:41:30.323780 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m12:41:30.333281 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:30.335767 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:41:30.336118 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m12:41:30.342931 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:30.346567 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m12:41:30.346927 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:30.347363 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m12:41:30.348985 [debug] [Thread-2 (]: On model.bde.dim_suburb: COMMIT
[0m12:41:30.349395 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:41:30.349710 [debug] [Thread-2 (]: On model.bde.dim_suburb: COMMIT
[0m12:41:30.364187 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:30.366417 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m12:41:30.366768 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m12:41:30.384191 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:41:30.385557 [debug] [Thread-2 (]: Timing info for model.bde.dim_suburb (execute): 12:41:30.182689 => 12:41:30.385366
[0m12:41:30.385959 [debug] [Thread-2 (]: On model.bde.dim_suburb: Close
[0m12:41:30.386861 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b6b2e0>]}
[0m12:41:30.387512 [info ] [Thread-2 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.21s]
[0m12:41:30.388113 [debug] [Thread-2 (]: Finished running node model.bde.dim_suburb
[0m12:41:30.398282 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:41:30.399604 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (execute): 12:41:26.680892 => 12:41:30.399446
[0m12:41:30.399970 [debug] [Thread-4 (]: On model.bde.fact_listing: Close
[0m12:41:30.400745 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b6b2e0>]}
[0m12:41:30.401251 [info ] [Thread-4 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 3.72s]
[0m12:41:30.401764 [debug] [Thread-4 (]: Finished running node model.bde.fact_listing
[0m12:41:30.459463 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m12:41:30.463297 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:41:30.463715 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m12:41:30.479734 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:30.482739 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:41:30.483252 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m12:41:30.492307 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:41:30.494131 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:41:30.494503 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:41:30.494843 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m12:41:30.511946 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m12:41:30.514492 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m12:41:30.514890 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m12:41:30.529837 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:41:30.531616 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 12:41:30.155220 => 12:41:30.531381
[0m12:41:30.532132 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m12:41:30.533162 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c702e29-5aa2-4983-8861-d8e6db2f3550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c14a30>]}
[0m12:41:30.533795 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.39s]
[0m12:41:30.534401 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m12:41:30.536194 [debug] [MainThread]: Using postgres connection "master"
[0m12:41:30.536573 [debug] [MainThread]: On master: BEGIN
[0m12:41:30.536890 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:41:30.639625 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:41:30.641075 [debug] [MainThread]: On master: COMMIT
[0m12:41:30.641711 [debug] [MainThread]: Using postgres connection "master"
[0m12:41:30.642256 [debug] [MainThread]: On master: COMMIT
[0m12:41:30.651074 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:41:30.652185 [debug] [MainThread]: On master: Close
[0m12:41:30.654153 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:41:30.654709 [debug] [MainThread]: Connection 'model.bde.dim_host' was properly closed.
[0m12:41:30.655110 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m12:41:30.655481 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m12:41:30.655840 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m12:41:30.656534 [info ] [MainThread]: 
[0m12:41:30.657067 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 6.88 seconds (6.88s).
[0m12:41:30.661154 [debug] [MainThread]: Command end result
[0m12:41:30.671994 [info ] [MainThread]: 
[0m12:41:30.672432 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:41:30.672776 [info ] [MainThread]: 
[0m12:41:30.673121 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m12:41:30.673795 [debug] [MainThread]: Command `dbt run` succeeded at 12:41:30.673711 after 7.05 seconds
[0m12:41:30.674193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105098f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ae81c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c4afb0>]}
[0m12:41:30.674554 [debug] [MainThread]: Flushing usage events
[0m17:42:21.690759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104edd5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070c1ae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070c1420>]}


============================== 17:42:21.693579 | 6d540809-10eb-49d6-b7f8-65be3b5deb00 ==============================
[0m17:42:21.693579 [info ] [MainThread]: Running with dbt=1.6.6
[0m17:42:21.693921 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:42:21.924369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070c1630>]}
[0m17:42:21.933530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107425180>]}
[0m17:42:21.933972 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m17:42:21.947424 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m17:42:21.977731 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m17:42:21.978236 [debug] [MainThread]: Partial parsing: updated file: bde://models/warehouse/fact_listing.sql
[0m17:42:21.978470 [debug] [MainThread]: Partial parsing: updated file: bde://models/staging/stg_fact.sql
[0m17:42:22.001592 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.median
- models.bde.raw
[0m17:42:22.004496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a8cdf0>]}
[0m17:42:22.011556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078bed10>]}
[0m17:42:22.011807 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m17:42:22.011986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078beef0>]}
[0m17:42:22.013157 [info ] [MainThread]: 
[0m17:42:22.013531 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:42:22.014354 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m17:42:22.014788 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m17:42:22.019758 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m17:42:22.020194 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m17:42:22.021299 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m17:42:22.021513 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m17:42:22.022443 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m17:42:22.022651 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m17:42:22.022896 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:42:22.023068 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m17:42:22.023235 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:42:22.023554 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:42:22.234036 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:42:22.235510 [debug] [ThreadPool]: On list_postgres: Close
[0m17:42:22.235750 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:42:22.236778 [debug] [ThreadPool]: On list_postgres: Close
[0m17:42:22.240446 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:42:22.241349 [debug] [ThreadPool]: On list_postgres: Close
[0m17:42:22.243196 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m17:42:22.243869 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_warehouse)
[0m17:42:22.248147 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m17:42:22.248655 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m17:42:22.249151 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_staging'
[0m17:42:22.250432 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m17:42:22.250687 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m17:42:22.251753 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m17:42:22.252794 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m17:42:22.253024 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m17:42:22.253297 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:42:22.253587 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m17:42:22.253819 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m17:42:22.254015 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:42:22.254306 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:42:22.254515 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:42:22.349026 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:42:22.349513 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m17:42:22.349812 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m17:42:22.350950 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:42:22.351218 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m17:42:22.351476 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m17:42:22.363338 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:42:22.363609 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m17:42:22.363922 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m17:42:22.364251 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:42:22.364682 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m17:42:22.364979 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m17:42:22.370511 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:42:22.371845 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m17:42:22.372722 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:42:22.373776 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m17:42:22.379667 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m17:42:22.381426 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m17:42:22.384026 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:42:22.385097 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m17:42:22.385389 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:42:22.386468 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m17:42:22.394160 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m17:42:22.395724 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m17:42:22.401773 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:22.402080 [debug] [MainThread]: On master: BEGIN
[0m17:42:22.402314 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:42:22.493524 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:42:22.494017 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:22.494620 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:42:22.522401 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m17:42:22.524694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c0d360>]}
[0m17:42:22.525057 [debug] [MainThread]: On master: ROLLBACK
[0m17:42:22.533996 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:22.534508 [debug] [MainThread]: On master: BEGIN
[0m17:42:22.551689 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:42:22.552024 [debug] [MainThread]: On master: COMMIT
[0m17:42:22.552240 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:22.552430 [debug] [MainThread]: On master: COMMIT
[0m17:42:22.560936 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:42:22.561181 [debug] [MainThread]: On master: Close
[0m17:42:22.561760 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:42:22.562014 [info ] [MainThread]: 
[0m17:42:22.564282 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m17:42:22.564584 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m17:42:22.564826 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m17:42:22.565109 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m17:42:22.565543 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m17:42:22.566027 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m17:42:22.566374 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m17:42:22.566672 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m17:42:22.567163 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_host_neighbourhod)
[0m17:42:22.567607 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.dm_listing_neighbourhood)
[0m17:42:22.567992 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_property_type)
[0m17:42:22.568369 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.stg_G01)
[0m17:42:22.568624 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m17:42:22.568862 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m17:42:22.569082 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m17:42:22.569300 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m17:42:22.574582 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m17:42:22.576415 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m17:42:22.579181 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m17:42:22.581063 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m17:42:22.582525 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 17:42:22.569473 => 17:42:22.582407
[0m17:42:22.582831 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m17:42:22.589573 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 17:42:22.574800 => 17:42:22.589450
[0m17:42:22.596139 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 17:42:22.579380 => 17:42:22.595987
[0m17:42:22.596421 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 17:42:22.576623 => 17:42:22.596295
[0m17:42:22.605406 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m17:42:22.605684 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m17:42:22.606007 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m17:42:22.606220 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m17:42:22.608540 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m17:42:22.614847 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:42:22.618332 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m17:42:22.620512 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m17:42:22.620838 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m17:42:22.621282 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:42:22.621611 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:42:22.621857 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:42:22.622049 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m17:42:22.622383 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:42:22.622570 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m17:42:22.622784 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m17:42:22.623000 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m17:42:22.623193 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:22.623457 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m17:42:22.714977 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:22.715384 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:42:22.715671 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    -- Set the configuration for the materialized view


-- Create a Common Table Expression (CTE) called host_neighbourhood_lga_transform
-- This CTE retrieves data from the dim_host and dim_suburb tables and transforms it.
-- It includes host data, host neighborhood's local government area, and month_year.

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM warehouse.dim_host host
    LEFT JOIN warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
-- Create a CTE called distinct_host_count
-- This CTE calculates the number of distinct hosts for each host_neighbourhood_lga and month_year.
distinct_host_count AS (
    SELECT
        TO_CHAR(ht.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        COUNT(DISTINCT ht.host_id) AS num_distinct_hosts
    FROM host_neighbourhood_lga_transform ht
    GROUP BY TO_CHAR(ht.scraped_date, 'MM/YYYY'),ht.host_neighbourhood_lga
),
-- Create a CTE called estimated_revenue
-- This CTE calculates the total estimated revenue for each host_neighbourhood_lga and month_year.
estimated_revenue AS (
    SELECT
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        SUM((30 - list.availability_30) * list.price) AS total_estimated_revenue
    FROM warehouse.fact_listing list
    LEFT JOIN host_neighbourhood_lga_transform ht ON list.surrogate_key_host = ht.surrogate_key_host
    WHERE list.has_availability = 't'
    GROUP BY
        TO_CHAR(list.scraped_date, 'MM/YYYY'),
        ht.host_neighbourhood_lga
)
-- Select the aggregated metrics including month_year, host_neighbourhood_lga, number of distinct hosts, total estimated revenue, and estimated revenue per host.
SELECT
    dh.host_neighbourhood_lga,
    dh.month_year,
    dh.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dh.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dh.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM distinct_host_count dh
LEFT JOIN estimated_revenue er ON dh.month_year = er.month_year AND dh.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY dh.host_neighbourhood_lga, dh.month_year
  );
  
[0m17:42:22.730655 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:22.730932 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:42:22.731300 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m17:42:22.731693 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:22.731950 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:42:22.732307 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type

-- Set the configuration for the materialized view



-- Create a Common Table Expression (CTE) called sorted_listing
-- This CTE retrieves data from multiple tables and calculates various metrics
-- It includes property_type, room_type, accommodates, and more.


WITH sorted_listing AS (
    SELECT 
        prop.property_type,-- Property type
        room.room_type,-- Room type
        list.accommodates,-- Accommodates
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year, -- Truncate the date to the month
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id, -- Host ID
        host.host_is_superhost,-- Host is superhost flag
        review_scores_rating,-- Review scores rating
        availability_30-- Availability for the next 30 days
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
-- Select the aggregated metrics for the property_type, room_type, accommodates, and month_year
SELECT 
    property_type,-- Property type
    room_type,-- Room type
    accommodates,-- Number of accommodates
    month_year,-- Truncated month and year
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,-- Calculate the minimum price for active listings
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,-- Calculate the maximum price for active listings
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing, -- Calculate the median price for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts, -- Count the number of distinct hosts
     -- Calculate the superhost rate
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
     -- Calculate the average review scores rating for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


     -- Calculate the percentage change for active listing
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing

    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m17:42:22.736749 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:22.736948 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:42:22.737301 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,     
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m17:42:22.772394 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:22.777488 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:42:22.777777 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m17:42:22.787750 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:22.789720 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:42:22.790012 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m17:42:22.814471 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:22.825428 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m17:42:22.825838 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:42:22.826077 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m17:42:22.838591 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:22.843820 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:42:22.844115 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m17:42:22.860042 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:22.861222 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 17:42:22.608769 => 17:42:22.861098
[0m17:42:22.861490 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m17:42:22.862143 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ca9360>]}
[0m17:42:22.862557 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.29s]
[0m17:42:22.862946 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m17:42:22.863238 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m17:42:22.863520 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m17:42:22.864053 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m17:42:22.864392 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m17:42:22.866676 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m17:42:22.868133 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 17:42:22.864577 => 17:42:22.867998
[0m17:42:22.868392 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m17:42:22.871185 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m17:42:22.871681 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:42:22.871923 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m17:42:22.872134 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:23.025285 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:23.026008 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:42:23.026637 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m17:42:23.044081 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:23.048822 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:42:23.049272 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m17:42:23.060546 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:23.064125 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:42:23.064760 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m17:42:23.091232 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:23.093551 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m17:42:23.094094 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:42:23.094457 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m17:42:23.105033 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:23.108295 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:42:23.108729 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m17:42:23.121612 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:23.123100 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 17:42:22.868543 => 17:42:23.122913
[0m17:42:23.123519 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m17:42:23.124470 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c21db0>]}
[0m17:42:23.125097 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.26s]
[0m17:42:23.125674 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m17:42:23.126089 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m17:42:23.126665 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m17:42:23.127435 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m17:42:23.127846 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m17:42:23.132426 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m17:42:23.134045 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 17:42:23.128104 => 17:42:23.133905
[0m17:42:23.134336 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m17:42:23.137474 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m17:42:23.138178 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:42:23.138453 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m17:42:23.138702 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:23.256585 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:23.257292 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:42:23.257863 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m17:42:23.272156 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:23.276587 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:42:23.277006 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m17:42:23.287341 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:23.290480 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:42:23.290880 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m17:42:23.301154 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:23.302802 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m17:42:23.303190 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:42:23.303545 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m17:42:23.314092 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:23.317208 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:42:23.317692 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m17:42:23.329070 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:23.330740 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 17:42:23.134536 => 17:42:23.330515
[0m17:42:23.331235 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m17:42:23.332404 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107cd7760>]}
[0m17:42:23.333234 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.21s]
[0m17:42:23.333900 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m17:42:23.334358 [debug] [Thread-4 (]: Began running node model.bde.stg_fact
[0m17:42:23.335006 [info ] [Thread-4 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m17:42:23.335981 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_fact)
[0m17:42:23.336428 [debug] [Thread-4 (]: Began compiling node model.bde.stg_fact
[0m17:42:23.340390 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m17:42:23.341772 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (compile): 17:42:23.336714 => 17:42:23.341546
[0m17:42:23.342185 [debug] [Thread-4 (]: Began executing node model.bde.stg_fact
[0m17:42:23.346110 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m17:42:23.347055 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:42:23.347448 [debug] [Thread-4 (]: On model.bde.stg_fact: BEGIN
[0m17:42:23.347724 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:23.457258 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:23.457968 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:42:23.458566 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        LISTING_NEIGHBOURHOOD,
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m17:42:23.489579 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:23.493292 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:42:23.493691 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m17:42:23.503559 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:23.507979 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:42:23.508376 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m17:42:23.517898 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:23.519305 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m17:42:23.519621 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:42:23.519901 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m17:42:23.529761 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:23.566270 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:42:23.566740 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m17:42:23.578411 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:23.579505 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (execute): 17:42:23.342445 => 17:42:23.579390
[0m17:42:23.580598 [debug] [Thread-4 (]: On model.bde.stg_fact: Close
[0m17:42:23.581225 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c32c50>]}
[0m17:42:23.581625 [info ] [Thread-4 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.25s]
[0m17:42:23.582078 [debug] [Thread-4 (]: Finished running node model.bde.stg_fact
[0m17:42:23.582368 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m17:42:23.582725 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m17:42:23.583229 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_host)
[0m17:42:23.583449 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m17:42:23.585617 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m17:42:23.586748 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 17:42:23.583595 => 17:42:23.586641
[0m17:42:23.586964 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m17:42:23.589398 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m17:42:23.589814 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:42:23.590010 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m17:42:23.590195 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:23.701303 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:23.701738 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:42:23.702141 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m17:42:23.721542 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:23.725060 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:42:23.725487 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m17:42:23.735853 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:23.739071 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:42:23.739607 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m17:42:23.749122 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:23.750852 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m17:42:23.751182 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:42:23.751465 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m17:42:23.762653 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:23.764822 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:42:23.765136 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m17:42:23.778275 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:23.779375 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 17:42:23.587112 => 17:42:23.779233
[0m17:42:23.779681 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m17:42:23.780393 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078bfeb0>]}
[0m17:42:23.780918 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.20s]
[0m17:42:23.781393 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m17:42:23.781760 [debug] [Thread-4 (]: Began running node model.bde.stg_property
[0m17:42:23.782249 [info ] [Thread-4 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m17:42:23.782946 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_property)
[0m17:42:23.783278 [debug] [Thread-4 (]: Began compiling node model.bde.stg_property
[0m17:42:23.785992 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_property"
[0m17:42:23.787566 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (compile): 17:42:23.783493 => 17:42:23.787441
[0m17:42:23.787825 [debug] [Thread-4 (]: Began executing node model.bde.stg_property
[0m17:42:23.790615 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_property"
[0m17:42:23.791106 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:42:23.791350 [debug] [Thread-4 (]: On model.bde.stg_property: BEGIN
[0m17:42:23.791584 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:23.942635 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:23.943185 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:42:23.943576 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m17:42:23.958209 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:23.962869 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:42:23.963261 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m17:42:23.972937 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:23.975129 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:42:23.975475 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m17:42:23.985749 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:23.987008 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m17:42:23.987339 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:42:23.987596 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m17:42:23.997377 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:23.999473 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:42:23.999783 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m17:42:24.011261 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:24.012314 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (execute): 17:42:23.788006 => 17:42:24.012189
[0m17:42:24.012583 [debug] [Thread-4 (]: On model.bde.stg_property: Close
[0m17:42:24.013242 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c4ebc0>]}
[0m17:42:24.013687 [info ] [Thread-4 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.23s]
[0m17:42:24.014164 [debug] [Thread-4 (]: Finished running node model.bde.stg_property
[0m17:42:24.014492 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m17:42:24.014958 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m17:42:24.015487 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_room)
[0m17:42:24.015753 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m17:42:24.018036 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m17:42:24.019603 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 17:42:24.015924 => 17:42:24.019478
[0m17:42:24.019871 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m17:42:24.022535 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m17:42:24.023188 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:42:24.023422 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m17:42:24.023645 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:24.134997 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:24.135592 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:42:24.136015 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m17:42:24.149028 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:24.152624 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:42:24.153002 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m17:42:24.166964 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:24.169769 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:42:24.170125 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m17:42:24.179446 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:24.180923 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m17:42:24.181276 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:42:24.181582 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m17:42:24.191115 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:24.193591 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:42:24.193936 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m17:42:24.206366 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:24.207658 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 17:42:24.020038 => 17:42:24.207489
[0m17:42:24.208017 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m17:42:24.208879 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111212cb0>]}
[0m17:42:24.209466 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.19s]
[0m17:42:24.210007 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m17:42:24.210395 [debug] [Thread-4 (]: Began running node model.bde.stg_suburb
[0m17:42:24.211009 [info ] [Thread-4 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m17:42:24.211729 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.stg_suburb)
[0m17:42:24.212105 [debug] [Thread-4 (]: Began compiling node model.bde.stg_suburb
[0m17:42:24.216275 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m17:42:24.217810 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (compile): 17:42:24.212354 => 17:42:24.217660
[0m17:42:24.218109 [debug] [Thread-4 (]: Began executing node model.bde.stg_suburb
[0m17:42:24.221259 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m17:42:24.221827 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:42:24.222099 [debug] [Thread-4 (]: On model.bde.stg_suburb: BEGIN
[0m17:42:24.222357 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:24.331484 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:24.332102 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:42:24.332567 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m17:42:24.345672 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:24.349494 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:42:24.349943 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m17:42:24.360069 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:24.363052 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:42:24.363446 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m17:42:24.372993 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:24.374936 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m17:42:24.375294 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:42:24.375609 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m17:42:24.385765 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:24.388397 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:42:24.388773 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m17:42:24.402183 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:24.403577 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (execute): 17:42:24.218303 => 17:42:24.403390
[0m17:42:24.404004 [debug] [Thread-4 (]: On model.bde.stg_suburb: Close
[0m17:42:24.404960 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111260af0>]}
[0m17:42:24.405637 [info ] [Thread-4 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.19s]
[0m17:42:24.406298 [debug] [Thread-4 (]: Finished running node model.bde.stg_suburb
[0m17:42:24.406697 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m17:42:24.407289 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m17:42:24.407919 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.dim_LGA)
[0m17:42:24.408244 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m17:42:24.411458 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m17:42:24.414281 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 17:42:24.408486 => 17:42:24.414093
[0m17:42:24.414646 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m17:42:24.418116 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m17:42:24.418766 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:42:24.419050 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m17:42:24.419315 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:24.536530 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:24.537832 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:42:24.538482 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m17:42:24.555600 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m17:42:24.563007 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:42:24.563856 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m17:42:24.586961 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:24.596773 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:42:24.597506 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m17:42:24.606540 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:24.613210 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m17:42:24.613685 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:42:24.614078 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m17:42:24.627413 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:24.631901 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:42:24.632262 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m17:42:24.643464 [debug] [Thread-1 (]: SQL status: SELECT 217 in 2.0 seconds
[0m17:42:24.646077 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:42:24.646382 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m17:42:24.659470 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:24.659813 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:24.661125 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 17:42:24.414871 => 17:42:24.660961
[0m17:42:24.663619 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:42:24.663988 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m17:42:24.664332 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m17:42:24.665137 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079d7f10>]}
[0m17:42:24.665676 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.26s]
[0m17:42:24.666132 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m17:42:24.666460 [debug] [Thread-4 (]: Began running node model.bde.fact_G01
[0m17:42:24.666850 [info ] [Thread-4 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m17:42:24.667347 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G01)
[0m17:42:24.667627 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G01
[0m17:42:24.670178 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m17:42:24.671662 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (compile): 17:42:24.667817 => 17:42:24.671468
[0m17:42:24.672245 [debug] [Thread-4 (]: Began executing node model.bde.fact_G01
[0m17:42:24.675223 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m17:42:24.675767 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:42:24.676024 [debug] [Thread-4 (]: On model.bde.fact_G01: BEGIN
[0m17:42:24.676321 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:24.676684 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:24.678380 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m17:42:24.678850 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:42:24.679119 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m17:42:24.695657 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:24.697657 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:42:24.697906 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m17:42:24.729960 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:24.731037 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 17:42:22.583154 => 17:42:24.730927
[0m17:42:24.731284 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m17:42:24.731822 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078bd090>]}
[0m17:42:24.732215 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 217[0m in 2.16s]
[0m17:42:24.732570 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m17:42:24.732831 [debug] [Thread-1 (]: Began running node model.bde.fact_G02
[0m17:42:24.733095 [info ] [Thread-1 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m17:42:24.733551 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.fact_G02)
[0m17:42:24.733824 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G02
[0m17:42:24.735927 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m17:42:24.736596 [debug] [Thread-1 (]: Timing info for model.bde.fact_G02 (compile): 17:42:24.733981 => 17:42:24.736496
[0m17:42:24.736801 [debug] [Thread-1 (]: Began executing node model.bde.fact_G02
[0m17:42:24.740507 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m17:42:24.741081 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m17:42:24.741287 [debug] [Thread-1 (]: On model.bde.fact_G02: BEGIN
[0m17:42:24.741474 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:42:24.786988 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:24.787378 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:42:24.787653 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m17:42:24.821999 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m17:42:24.824709 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:42:24.825001 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m17:42:24.836019 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:24.838343 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:42:24.838639 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m17:42:24.847806 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:24.849294 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m17:42:24.849641 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:42:24.849914 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m17:42:24.859907 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:24.861818 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:42:24.862109 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m17:42:24.868038 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:24.868300 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m17:42:24.868574 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m17:42:24.877384 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:24.878606 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (execute): 17:42:24.672492 => 17:42:24.878450
[0m17:42:24.878943 [debug] [Thread-4 (]: On model.bde.fact_G01: Close
[0m17:42:24.879693 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c91930>]}
[0m17:42:24.880239 [info ] [Thread-4 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.21s]
[0m17:42:24.880774 [debug] [Thread-4 (]: Finished running node model.bde.fact_G01
[0m17:42:24.881171 [debug] [Thread-4 (]: Began running node model.bde.fact_listing
[0m17:42:24.881632 [info ] [Thread-4 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m17:42:24.882233 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_listing)
[0m17:42:24.882512 [debug] [Thread-4 (]: Began compiling node model.bde.fact_listing
[0m17:42:24.885124 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m17:42:24.886037 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (compile): 17:42:24.882724 => 17:42:24.885888
[0m17:42:24.886337 [debug] [Thread-4 (]: Began executing node model.bde.fact_listing
[0m17:42:24.889578 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m17:42:24.890159 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m17:42:24.890432 [debug] [Thread-4 (]: On model.bde.fact_listing: BEGIN
[0m17:42:24.890689 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:24.891709 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m17:42:24.894003 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m17:42:24.894296 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m17:42:24.903586 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:24.905679 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m17:42:24.905946 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m17:42:24.922780 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:24.924295 [debug] [Thread-1 (]: On model.bde.fact_G02: COMMIT
[0m17:42:24.924574 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m17:42:24.924837 [debug] [Thread-1 (]: On model.bde.fact_G02: COMMIT
[0m17:42:24.934543 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:24.936555 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m17:42:24.936837 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m17:42:24.950168 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:24.952932 [debug] [Thread-1 (]: Timing info for model.bde.fact_G02 (execute): 17:42:24.736968 => 17:42:24.952778
[0m17:42:24.953254 [debug] [Thread-1 (]: On model.bde.fact_G02: Close
[0m17:42:24.953874 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079cbfd0>]}
[0m17:42:24.954323 [info ] [Thread-1 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.22s]
[0m17:42:24.954781 [debug] [Thread-1 (]: Finished running node model.bde.fact_G02
[0m17:42:24.955109 [debug] [Thread-1 (]: Began running node model.bde.dim_host
[0m17:42:24.955497 [info ] [Thread-1 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m17:42:24.956061 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m17:42:24.956346 [debug] [Thread-1 (]: Began compiling node model.bde.dim_host
[0m17:42:24.958775 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_host"
[0m17:42:24.959905 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (compile): 17:42:24.956553 => 17:42:24.959774
[0m17:42:24.960177 [debug] [Thread-1 (]: Began executing node model.bde.dim_host
[0m17:42:24.963027 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_host"
[0m17:42:24.963654 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:42:24.963897 [debug] [Thread-1 (]: On model.bde.dim_host: BEGIN
[0m17:42:24.964124 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:42:24.995881 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:24.996238 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m17:42:24.996560 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    LISTING_NEIGHBOURHOOD,,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m17:42:25.012817 [debug] [Thread-4 (]: Postgres adapter: Postgres error: syntax error at or near ","
LINE 19:     LISTING_NEIGHBOURHOOD,,
                                   ^

[0m17:42:25.013169 [debug] [Thread-4 (]: On model.bde.fact_listing: ROLLBACK
[0m17:42:25.022195 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (execute): 17:42:24.886536 => 17:42:25.022022
[0m17:42:25.022578 [debug] [Thread-4 (]: On model.bde.fact_listing: Close
[0m17:42:25.027710 [debug] [Thread-4 (]: Database Error in model fact_listing (models/warehouse/fact_listing.sql)
  syntax error at or near ","
  LINE 19:     LISTING_NEIGHBOURHOOD,,
                                     ^
  compiled Code at target/run/bde/models/warehouse/fact_listing.sql
[0m17:42:25.028095 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107cf4160>]}
[0m17:42:25.028584 [error] [Thread-4 (]: 15 of 19 ERROR creating sql table model warehouse.fact_listing ................. [[31mERROR[0m in 0.15s]
[0m17:42:25.029043 [debug] [Thread-4 (]: Finished running node model.bde.fact_listing
[0m17:42:25.029372 [debug] [Thread-4 (]: Began running node model.bde.dim_property
[0m17:42:25.029767 [info ] [Thread-4 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m17:42:25.030267 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_listing, now model.bde.dim_property)
[0m17:42:25.030545 [debug] [Thread-4 (]: Began compiling node model.bde.dim_property
[0m17:42:25.033086 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_property"
[0m17:42:25.033899 [debug] [Thread-4 (]: Timing info for model.bde.dim_property (compile): 17:42:25.030741 => 17:42:25.033763
[0m17:42:25.034151 [debug] [Thread-4 (]: Began executing node model.bde.dim_property
[0m17:42:25.036956 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_property"
[0m17:42:25.037434 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_property"
[0m17:42:25.037683 [debug] [Thread-4 (]: On model.bde.dim_property: BEGIN
[0m17:42:25.037914 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:25.067000 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:25.067360 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:42:25.067679 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    scraped_date,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m17:42:25.145739 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:25.146226 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_property"
[0m17:42:25.146634 [debug] [Thread-4 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m17:42:25.642747 [debug] [Thread-4 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m17:42:25.647114 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_property"
[0m17:42:25.647653 [debug] [Thread-4 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m17:42:25.663285 [debug] [Thread-1 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m17:42:25.666924 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:42:25.667380 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m17:42:26.767546 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m17:42:26.770158 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:42:26.770463 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m17:42:26.779638 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:26.781504 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:42:26.781765 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m17:42:26.791469 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:26.793649 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m17:42:26.793884 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:42:26.794088 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m17:42:26.803375 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:26.804953 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:42:26.805201 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m17:42:26.829956 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:26.830877 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 17:42:22.606473 => 17:42:26.830752
[0m17:42:26.831154 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m17:42:26.831773 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c4e230>]}
[0m17:42:26.832196 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 4.26s]
[0m17:42:26.832613 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m17:42:26.832903 [debug] [Thread-2 (]: Began running node model.bde.dim_room
[0m17:42:26.833291 [info ] [Thread-2 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m17:42:26.833834 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_room)
[0m17:42:26.834130 [debug] [Thread-2 (]: Began compiling node model.bde.dim_room
[0m17:42:26.836350 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_room"
[0m17:42:26.837090 [debug] [Thread-2 (]: Timing info for model.bde.dim_room (compile): 17:42:26.834320 => 17:42:26.836982
[0m17:42:26.837317 [debug] [Thread-2 (]: Began executing node model.bde.dim_room
[0m17:42:26.840299 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_room"
[0m17:42:26.840973 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m17:42:26.841221 [debug] [Thread-2 (]: On model.bde.dim_room: BEGIN
[0m17:42:26.841445 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m17:42:26.936129 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:26.936709 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m17:42:26.937119 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m17:42:27.180602 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m17:42:27.188430 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m17:42:27.189049 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m17:42:27.408832 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 5.0 seconds
[0m17:42:27.419115 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:42:27.419757 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m17:42:27.429848 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:27.434118 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:42:27.434691 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m17:42:27.444616 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:27.446828 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m17:42:27.447321 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:42:27.447763 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m17:42:27.459743 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 2.0 seconds
[0m17:42:27.460241 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 2.0 seconds
[0m17:42:27.460760 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:27.461163 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:27.464708 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:42:27.467497 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_property"
[0m17:42:27.471623 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m17:42:27.474022 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:42:27.474375 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m17:42:27.474710 [debug] [Thread-4 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m17:42:27.475032 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m17:42:27.475354 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m17:42:27.493829 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:27.494234 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:27.494602 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:27.496479 [debug] [Thread-4 (]: On model.bde.dim_property: COMMIT
[0m17:42:27.498293 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m17:42:27.500213 [debug] [Thread-2 (]: On model.bde.dim_room: COMMIT
[0m17:42:27.500671 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:27.501000 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_property"
[0m17:42:27.501342 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:42:27.501670 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m17:42:27.502967 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 17:42:22.618550 => 17:42:27.502796
[0m17:42:27.503311 [debug] [Thread-4 (]: On model.bde.dim_property: COMMIT
[0m17:42:27.503627 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m17:42:27.503930 [debug] [Thread-2 (]: On model.bde.dim_room: COMMIT
[0m17:42:27.504270 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m17:42:27.505240 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ca96f0>]}
[0m17:42:27.505745 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 4.94s]
[0m17:42:27.506217 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m17:42:27.506567 [debug] [Thread-3 (]: Began running node model.bde.dim_suburb
[0m17:42:27.507045 [info ] [Thread-3 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m17:42:27.507651 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_suburb)
[0m17:42:27.507978 [debug] [Thread-3 (]: Began compiling node model.bde.dim_suburb
[0m17:42:27.510507 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m17:42:27.511873 [debug] [Thread-3 (]: Timing info for model.bde.dim_suburb (compile): 17:42:27.508190 => 17:42:27.511704
[0m17:42:27.512184 [debug] [Thread-3 (]: Began executing node model.bde.dim_suburb
[0m17:42:27.515409 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m17:42:27.515713 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:27.515990 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:27.516317 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:27.518576 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_room"
[0m17:42:27.520432 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_property"
[0m17:42:27.522231 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:42:27.522541 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:42:27.522914 [debug] [Thread-2 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m17:42:27.523254 [debug] [Thread-4 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m17:42:27.523546 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m17:42:27.523851 [debug] [Thread-3 (]: On model.bde.dim_suburb: BEGIN
[0m17:42:27.524322 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m17:42:27.550080 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:27.551176 [debug] [Thread-4 (]: Timing info for model.bde.dim_property (execute): 17:42:25.034331 => 17:42:27.551063
[0m17:42:27.551438 [debug] [Thread-4 (]: On model.bde.dim_property: Close
[0m17:42:27.551979 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c89030>]}
[0m17:42:27.552364 [info ] [Thread-4 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 2.52s]
[0m17:42:27.552725 [debug] [Thread-4 (]: Finished running node model.bde.dim_property
[0m17:42:27.556748 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:27.556982 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:27.557847 [debug] [Thread-2 (]: Timing info for model.bde.dim_room (execute): 17:42:26.837473 => 17:42:27.557744
[0m17:42:27.558636 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (execute): 17:42:24.960367 => 17:42:27.558534
[0m17:42:27.558889 [debug] [Thread-2 (]: On model.bde.dim_room: Close
[0m17:42:27.559172 [debug] [Thread-1 (]: On model.bde.dim_host: Close
[0m17:42:27.559909 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079fac80>]}
[0m17:42:27.560391 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111260c10>]}
[0m17:42:27.560816 [info ] [Thread-2 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.73s]
[0m17:42:27.561171 [info ] [Thread-1 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 2.60s]
[0m17:42:27.561543 [debug] [Thread-2 (]: Finished running node model.bde.dim_room
[0m17:42:27.561856 [debug] [Thread-1 (]: Finished running node model.bde.dim_host
[0m17:42:27.641348 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:27.641857 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:42:27.642189 [debug] [Thread-3 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m17:42:27.661599 [debug] [Thread-3 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m17:42:27.664981 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:42:27.665348 [debug] [Thread-3 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m17:42:27.675295 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:27.679314 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:42:27.679673 [debug] [Thread-3 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m17:42:27.690008 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:27.691617 [debug] [Thread-3 (]: On model.bde.dim_suburb: COMMIT
[0m17:42:27.691964 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:42:27.692267 [debug] [Thread-3 (]: On model.bde.dim_suburb: COMMIT
[0m17:42:27.715140 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:27.717941 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:42:27.718345 [debug] [Thread-3 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m17:42:27.742188 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:27.743558 [debug] [Thread-3 (]: Timing info for model.bde.dim_suburb (execute): 17:42:27.512390 => 17:42:27.743374
[0m17:42:27.743983 [debug] [Thread-3 (]: On model.bde.dim_suburb: Close
[0m17:42:27.744902 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d540809-10eb-49d6-b7f8-65be3b5deb00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114f6bc0>]}
[0m17:42:27.745545 [info ] [Thread-3 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.24s]
[0m17:42:27.746166 [debug] [Thread-3 (]: Finished running node model.bde.dim_suburb
[0m17:42:27.747872 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:27.748307 [debug] [MainThread]: On master: BEGIN
[0m17:42:27.748642 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:42:27.850685 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:42:27.852708 [debug] [MainThread]: On master: COMMIT
[0m17:42:27.853781 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:27.854793 [debug] [MainThread]: On master: COMMIT
[0m17:42:27.865299 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:42:27.865866 [debug] [MainThread]: On master: Close
[0m17:42:27.866907 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:42:27.867311 [debug] [MainThread]: Connection 'model.bde.dim_host' was properly closed.
[0m17:42:27.867678 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m17:42:27.868023 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m17:42:27.868359 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m17:42:27.868884 [info ] [MainThread]: 
[0m17:42:27.869339 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 5.86 seconds (5.86s).
[0m17:42:27.872588 [debug] [MainThread]: Command end result
[0m17:42:27.884159 [info ] [MainThread]: 
[0m17:42:27.884683 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m17:42:27.885000 [info ] [MainThread]: 
[0m17:42:27.885290 [error] [MainThread]:   Database Error in model fact_listing (models/warehouse/fact_listing.sql)
  syntax error at or near ","
  LINE 19:     LISTING_NEIGHBOURHOOD,,
                                     ^
  compiled Code at target/run/bde/models/warehouse/fact_listing.sql
[0m17:42:27.885564 [info ] [MainThread]: 
[0m17:42:27.885833 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m17:42:27.886422 [debug] [MainThread]: Command `dbt run` failed at 17:42:27.886343 after 6.21 seconds
[0m17:42:27.886781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104edd5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107425180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111228a30>]}
[0m17:42:27.887133 [debug] [MainThread]: Flushing usage events
[0m17:42:43.339304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10351a500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105471ab0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105471390>]}


============================== 17:42:43.341804 | e28465c7-0cbc-4cf7-9a1f-d79494684028 ==============================
[0m17:42:43.341804 [info ] [MainThread]: Running with dbt=1.6.6
[0m17:42:43.342100 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:42:43.385553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105471600>]}
[0m17:42:43.393113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058b5150>]}
[0m17:42:43.393517 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m17:42:43.401615 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m17:42:43.424521 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:42:43.424910 [debug] [MainThread]: Partial parsing: updated file: bde://models/warehouse/fact_listing.sql
[0m17:42:43.444635 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.median
- models.bde.raw
[0m17:42:43.447439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10605b0d0>]}
[0m17:42:43.453289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e02ce0>]}
[0m17:42:43.453540 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m17:42:43.453728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e02ec0>]}
[0m17:42:43.454894 [info ] [MainThread]: 
[0m17:42:43.455283 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:42:43.456128 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m17:42:43.456544 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m17:42:43.461376 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m17:42:43.461789 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m17:42:43.462833 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m17:42:43.463035 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m17:42:43.463968 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m17:42:43.464158 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m17:42:43.464375 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:42:43.464528 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m17:42:43.464667 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:42:43.464932 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:42:43.612986 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:42:43.614352 [debug] [ThreadPool]: On list_postgres: Close
[0m17:42:43.618933 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:42:43.619722 [debug] [ThreadPool]: On list_postgres: Close
[0m17:42:43.620455 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:42:43.621133 [debug] [ThreadPool]: On list_postgres: Close
[0m17:42:43.622710 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m17:42:43.623182 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_warehouse)
[0m17:42:43.623634 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m17:42:43.628164 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m17:42:43.628788 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_staging'
[0m17:42:43.630030 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m17:42:43.631151 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m17:42:43.631370 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m17:42:43.632449 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m17:42:43.632649 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m17:42:43.632863 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m17:42:43.633072 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:42:43.633269 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m17:42:43.633497 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:42:43.633679 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:42:43.634094 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:42:43.743672 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:42:43.744354 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m17:42:43.744711 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m17:42:43.761120 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:42:43.762382 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m17:42:43.767486 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:42:43.767832 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:42:43.768162 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m17:42:43.768510 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m17:42:43.768843 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m17:42:43.769193 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m17:42:43.773904 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:42:43.774150 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m17:42:43.774446 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m17:42:43.774798 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m17:42:43.785874 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:42:43.786970 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m17:42:43.794713 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m17:42:43.796284 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:42:43.797202 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m17:42:43.809609 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:42:43.809878 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m17:42:43.810962 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m17:42:43.820408 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m17:42:43.826210 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:43.826607 [debug] [MainThread]: On master: BEGIN
[0m17:42:43.826862 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:42:43.926775 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:42:43.927397 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:43.927938 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:42:43.954380 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m17:42:43.957608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106033d60>]}
[0m17:42:43.958175 [debug] [MainThread]: On master: ROLLBACK
[0m17:42:43.967128 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:43.967547 [debug] [MainThread]: On master: BEGIN
[0m17:42:43.986759 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:42:43.987349 [debug] [MainThread]: On master: COMMIT
[0m17:42:43.987759 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:43.988134 [debug] [MainThread]: On master: COMMIT
[0m17:42:43.997131 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:42:43.997614 [debug] [MainThread]: On master: Close
[0m17:42:43.998717 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:42:43.999154 [info ] [MainThread]: 
[0m17:42:44.003530 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m17:42:44.004028 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m17:42:44.004425 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m17:42:44.004881 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m17:42:44.005488 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m17:42:44.005947 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m17:42:44.006409 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m17:42:44.007079 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m17:42:44.007868 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_host_neighbourhod)
[0m17:42:44.008536 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.dm_listing_neighbourhood)
[0m17:42:44.009356 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_property_type)
[0m17:42:44.009944 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.stg_G01)
[0m17:42:44.010324 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m17:42:44.010739 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m17:42:44.011064 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m17:42:44.011438 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m17:42:44.018525 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m17:42:44.021082 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m17:42:44.024806 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m17:42:44.027407 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m17:42:44.028127 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 17:42:44.011736 => 17:42:44.027988
[0m17:42:44.028544 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 17:42:44.018865 => 17:42:44.028365
[0m17:42:44.028864 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m17:42:44.029288 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m17:42:44.029607 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 17:42:44.025115 => 17:42:44.029458
[0m17:42:44.029899 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 17:42:44.021380 => 17:42:44.029777
[0m17:42:44.054200 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m17:42:44.056667 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m17:42:44.056961 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m17:42:44.057189 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m17:42:44.067343 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m17:42:44.067595 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:42:44.069601 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m17:42:44.069798 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:42:44.070076 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m17:42:44.070339 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:42:44.070546 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m17:42:44.070796 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:42:44.071001 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:42:44.071180 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m17:42:44.071398 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m17:42:44.071669 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m17:42:44.071851 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:44.072107 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m17:42:44.170025 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:44.170493 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:42:44.171048 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,     
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m17:42:44.188830 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:44.189126 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:42:44.189525 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    -- Set the configuration for the materialized view


-- Create a Common Table Expression (CTE) called host_neighbourhood_lga_transform
-- This CTE retrieves data from the dim_host and dim_suburb tables and transforms it.
-- It includes host data, host neighborhood's local government area, and month_year.

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM warehouse.dim_host host
    LEFT JOIN warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
-- Create a CTE called distinct_host_count
-- This CTE calculates the number of distinct hosts for each host_neighbourhood_lga and month_year.
distinct_host_count AS (
    SELECT
        TO_CHAR(ht.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        COUNT(DISTINCT ht.host_id) AS num_distinct_hosts
    FROM host_neighbourhood_lga_transform ht
    GROUP BY TO_CHAR(ht.scraped_date, 'MM/YYYY'),ht.host_neighbourhood_lga
),
-- Create a CTE called estimated_revenue
-- This CTE calculates the total estimated revenue for each host_neighbourhood_lga and month_year.
estimated_revenue AS (
    SELECT
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        SUM((30 - list.availability_30) * list.price) AS total_estimated_revenue
    FROM warehouse.fact_listing list
    LEFT JOIN host_neighbourhood_lga_transform ht ON list.surrogate_key_host = ht.surrogate_key_host
    WHERE list.has_availability = 't'
    GROUP BY
        TO_CHAR(list.scraped_date, 'MM/YYYY'),
        ht.host_neighbourhood_lga
)
-- Select the aggregated metrics including month_year, host_neighbourhood_lga, number of distinct hosts, total estimated revenue, and estimated revenue per host.
SELECT
    dh.host_neighbourhood_lga,
    dh.month_year,
    dh.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dh.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dh.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM distinct_host_count dh
LEFT JOIN estimated_revenue er ON dh.month_year = er.month_year AND dh.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY dh.host_neighbourhood_lga, dh.month_year
  );
  
[0m17:42:44.190002 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:44.190247 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:42:44.190663 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m17:42:44.191800 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:44.192045 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:42:44.192547 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type

-- Set the configuration for the materialized view



-- Create a Common Table Expression (CTE) called sorted_listing
-- This CTE retrieves data from multiple tables and calculates various metrics
-- It includes property_type, room_type, accommodates, and more.


WITH sorted_listing AS (
    SELECT 
        prop.property_type,-- Property type
        room.room_type,-- Room type
        list.accommodates,-- Accommodates
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year, -- Truncate the date to the month
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id, -- Host ID
        host.host_is_superhost,-- Host is superhost flag
        review_scores_rating,-- Review scores rating
        availability_30-- Availability for the next 30 days
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
-- Select the aggregated metrics for the property_type, room_type, accommodates, and month_year
SELECT 
    property_type,-- Property type
    room_type,-- Room type
    accommodates,-- Number of accommodates
    month_year,-- Truncated month and year
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,-- Calculate the minimum price for active listings
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,-- Calculate the maximum price for active listings
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing, -- Calculate the median price for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts, -- Count the number of distinct hosts
     -- Calculate the superhost rate
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
     -- Calculate the average review scores rating for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


     -- Calculate the percentage change for active listing
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing

    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m17:42:44.224968 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:44.231165 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:42:44.231473 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m17:42:44.241887 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:44.244022 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:42:44.244314 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m17:42:44.254895 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:44.266312 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m17:42:44.266601 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:42:44.266845 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m17:42:44.277473 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:44.282834 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:42:44.283118 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m17:42:44.296310 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:44.297315 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 17:42:44.057521 => 17:42:44.297185
[0m17:42:44.297586 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m17:42:44.298193 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063b10f0>]}
[0m17:42:44.298644 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.29s]
[0m17:42:44.299059 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m17:42:44.299359 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m17:42:44.299743 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m17:42:44.300269 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m17:42:44.300541 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m17:42:44.302747 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m17:42:44.303363 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 17:42:44.300727 => 17:42:44.303243
[0m17:42:44.303626 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m17:42:44.306232 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m17:42:44.306681 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:42:44.306891 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m17:42:44.307089 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:44.412934 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:44.413416 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:42:44.413776 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m17:42:44.427719 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:44.430690 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:42:44.430998 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m17:42:44.441035 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:44.443218 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:42:44.443528 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m17:42:44.452860 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:44.454218 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m17:42:44.454501 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:42:44.454756 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m17:42:44.466743 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:44.469175 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:42:44.469640 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m17:42:44.482343 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:44.483734 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 17:42:44.303791 => 17:42:44.483574
[0m17:42:44.484108 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m17:42:44.484912 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065665c0>]}
[0m17:42:44.485545 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.18s]
[0m17:42:44.486095 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m17:42:44.486500 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m17:42:44.486962 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m17:42:44.487523 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m17:42:44.487841 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m17:42:44.491736 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m17:42:44.492417 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 17:42:44.488093 => 17:42:44.492278
[0m17:42:44.492702 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m17:42:44.495693 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m17:42:44.496322 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:42:44.496610 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m17:42:44.496910 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:44.601108 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:44.601644 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:42:44.602164 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m17:42:44.626978 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:44.630969 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:42:44.631355 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m17:42:44.640354 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:44.643401 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:42:44.643789 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m17:42:44.652382 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:44.654082 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m17:42:44.654485 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:42:44.654816 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m17:42:44.663648 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:44.666277 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:42:44.666752 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m17:42:44.676749 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:44.678112 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 17:42:44.492879 => 17:42:44.677964
[0m17:42:44.678431 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m17:42:44.679104 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106536260>]}
[0m17:42:44.679548 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.19s]
[0m17:42:44.680056 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m17:42:44.680388 [debug] [Thread-4 (]: Began running node model.bde.stg_fact
[0m17:42:44.680905 [info ] [Thread-4 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m17:42:44.681492 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_fact)
[0m17:42:44.681786 [debug] [Thread-4 (]: Began compiling node model.bde.stg_fact
[0m17:42:44.684435 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m17:42:44.685129 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (compile): 17:42:44.681981 => 17:42:44.684943
[0m17:42:44.685483 [debug] [Thread-4 (]: Began executing node model.bde.stg_fact
[0m17:42:44.688320 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m17:42:44.688830 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:42:44.689072 [debug] [Thread-4 (]: On model.bde.stg_fact: BEGIN
[0m17:42:44.689303 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:44.798330 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:44.798970 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:42:44.799574 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        LISTING_NEIGHBOURHOOD,
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m17:42:44.830980 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:44.835175 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:42:44.835603 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m17:42:44.845818 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:44.850534 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:42:44.850950 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m17:42:44.861224 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:44.862917 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m17:42:44.863302 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:42:44.863655 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m17:42:44.874125 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:44.914504 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:42:44.914917 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m17:42:44.927273 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:44.928306 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (execute): 17:42:44.685676 => 17:42:44.928180
[0m17:42:44.928567 [debug] [Thread-4 (]: On model.bde.stg_fact: Close
[0m17:42:44.929177 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105879150>]}
[0m17:42:44.929582 [info ] [Thread-4 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.25s]
[0m17:42:44.929997 [debug] [Thread-4 (]: Finished running node model.bde.stg_fact
[0m17:42:44.930286 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m17:42:44.930683 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m17:42:44.931127 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_host)
[0m17:42:44.931358 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m17:42:44.933594 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m17:42:44.934185 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 17:42:44.931520 => 17:42:44.934070
[0m17:42:44.934426 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m17:42:44.936895 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m17:42:44.937504 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:42:44.937782 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m17:42:44.938082 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:45.035873 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:45.036318 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:42:45.036736 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m17:42:45.054263 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:45.057459 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:42:45.057818 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m17:42:45.066726 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:45.069430 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:42:45.069813 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m17:42:45.079291 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:45.080912 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m17:42:45.081263 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:42:45.081585 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m17:42:45.090997 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:45.093280 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:42:45.093645 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m17:42:45.105576 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:45.106983 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 17:42:44.934580 => 17:42:45.106795
[0m17:42:45.107408 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m17:42:45.108334 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065851b0>]}
[0m17:42:45.108918 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.18s]
[0m17:42:45.109465 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m17:42:45.109849 [debug] [Thread-4 (]: Began running node model.bde.stg_property
[0m17:42:45.110266 [info ] [Thread-4 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m17:42:45.111073 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_property)
[0m17:42:45.111451 [debug] [Thread-4 (]: Began compiling node model.bde.stg_property
[0m17:42:45.114536 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_property"
[0m17:42:45.115317 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (compile): 17:42:45.111694 => 17:42:45.115180
[0m17:42:45.115623 [debug] [Thread-4 (]: Began executing node model.bde.stg_property
[0m17:42:45.118931 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_property"
[0m17:42:45.119783 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:42:45.120293 [debug] [Thread-4 (]: On model.bde.stg_property: BEGIN
[0m17:42:45.120601 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:45.231190 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:45.231889 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:42:45.232547 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m17:42:45.245449 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:45.250904 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:42:45.251381 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m17:42:45.261737 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:45.263968 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:42:45.264283 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m17:42:45.273204 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:45.274236 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m17:42:45.274473 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:42:45.274689 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m17:42:45.284178 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:45.285793 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:42:45.286024 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m17:42:45.296488 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:45.297379 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (execute): 17:42:45.115852 => 17:42:45.297271
[0m17:42:45.297611 [debug] [Thread-4 (]: On model.bde.stg_property: Close
[0m17:42:45.298158 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060a8400>]}
[0m17:42:45.298522 [info ] [Thread-4 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.19s]
[0m17:42:45.298883 [debug] [Thread-4 (]: Finished running node model.bde.stg_property
[0m17:42:45.299149 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m17:42:45.299519 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m17:42:45.299908 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_room)
[0m17:42:45.300129 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m17:42:45.302141 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m17:42:45.302672 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 17:42:45.300277 => 17:42:45.302559
[0m17:42:45.302887 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m17:42:45.305196 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m17:42:45.305658 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:42:45.305876 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m17:42:45.306074 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:45.423481 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:45.424023 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:42:45.424420 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m17:42:45.436161 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:45.439254 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:42:45.439625 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m17:42:45.448401 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:45.451113 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:42:45.451738 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m17:42:45.460352 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:45.461892 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m17:42:45.462242 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:42:45.462550 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m17:42:45.472405 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:45.475006 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:42:45.475355 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m17:42:45.486186 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:45.487618 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 17:42:45.303032 => 17:42:45.487429
[0m17:42:45.488021 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m17:42:45.488812 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106536cb0>]}
[0m17:42:45.489375 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.19s]
[0m17:42:45.489942 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m17:42:45.490357 [debug] [Thread-4 (]: Began running node model.bde.stg_suburb
[0m17:42:45.490930 [info ] [Thread-4 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m17:42:45.491593 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.stg_suburb)
[0m17:42:45.491942 [debug] [Thread-4 (]: Began compiling node model.bde.stg_suburb
[0m17:42:45.496372 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m17:42:45.497102 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (compile): 17:42:45.492183 => 17:42:45.496974
[0m17:42:45.497375 [debug] [Thread-4 (]: Began executing node model.bde.stg_suburb
[0m17:42:45.500507 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m17:42:45.501008 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:42:45.501272 [debug] [Thread-4 (]: On model.bde.stg_suburb: BEGIN
[0m17:42:45.501538 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:45.602837 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:45.603473 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:42:45.604011 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m17:42:45.616744 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:42:45.621134 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:42:45.621576 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m17:42:45.630633 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:45.633359 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:42:45.633740 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m17:42:45.644631 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:45.645893 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m17:42:45.646168 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:42:45.646410 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m17:42:45.656253 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:45.658003 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:42:45.658268 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m17:42:45.669442 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:42:45.670296 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (execute): 17:42:45.497564 => 17:42:45.670184
[0m17:42:45.670546 [debug] [Thread-4 (]: On model.bde.stg_suburb: Close
[0m17:42:45.671077 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106535bd0>]}
[0m17:42:45.671464 [info ] [Thread-4 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.18s]
[0m17:42:45.671841 [debug] [Thread-4 (]: Finished running node model.bde.stg_suburb
[0m17:42:45.672109 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m17:42:45.672500 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m17:42:45.672982 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.dim_LGA)
[0m17:42:45.673229 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m17:42:45.675275 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m17:42:45.675828 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 17:42:45.673398 => 17:42:45.675713
[0m17:42:45.676066 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m17:42:45.678629 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m17:42:45.679053 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:42:45.679280 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m17:42:45.679499 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:45.782555 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:45.783014 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:42:45.783365 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m17:42:45.802496 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m17:42:45.805925 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:42:45.806344 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m17:42:45.815501 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:45.820188 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:42:45.820553 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m17:42:45.829353 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:45.834417 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m17:42:45.834792 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:42:45.835114 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m17:42:45.845212 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:45.849442 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:42:45.849822 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m17:42:45.864905 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:45.866103 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 17:42:45.676228 => 17:42:45.865947
[0m17:42:45.866440 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m17:42:45.867192 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063fbb50>]}
[0m17:42:45.867733 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.19s]
[0m17:42:45.868271 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m17:42:45.868640 [debug] [Thread-4 (]: Began running node model.bde.fact_G01
[0m17:42:45.869132 [info ] [Thread-4 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m17:42:45.869807 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G01)
[0m17:42:45.870157 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G01
[0m17:42:45.873023 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m17:42:45.873715 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (compile): 17:42:45.870392 => 17:42:45.873572
[0m17:42:45.874004 [debug] [Thread-4 (]: Began executing node model.bde.fact_G01
[0m17:42:45.877118 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m17:42:45.877630 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:42:45.877917 [debug] [Thread-4 (]: On model.bde.fact_G01: BEGIN
[0m17:42:45.878183 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:46.002146 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:46.003358 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:42:46.003907 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m17:42:46.044309 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m17:42:46.051212 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:42:46.052035 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m17:42:46.062997 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:46.066894 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:42:46.067398 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m17:42:46.076711 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:46.079371 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m17:42:46.079913 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:42:46.080302 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m17:42:46.090989 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:46.093790 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:42:46.094169 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m17:42:46.132094 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:46.134104 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (execute): 17:42:45.874205 => 17:42:46.133861
[0m17:42:46.134670 [debug] [Thread-4 (]: On model.bde.fact_G01: Close
[0m17:42:46.135780 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106341240>]}
[0m17:42:46.136528 [info ] [Thread-4 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.27s]
[0m17:42:46.137178 [debug] [Thread-4 (]: Finished running node model.bde.fact_G01
[0m17:42:46.137658 [debug] [Thread-4 (]: Began running node model.bde.fact_G02
[0m17:42:46.138229 [info ] [Thread-4 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m17:42:46.138998 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_G02)
[0m17:42:46.139403 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G02
[0m17:42:46.143294 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m17:42:46.144501 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (compile): 17:42:46.139683 => 17:42:46.144304
[0m17:42:46.144892 [debug] [Thread-4 (]: Began executing node model.bde.fact_G02
[0m17:42:46.151540 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m17:42:46.151952 [debug] [Thread-1 (]: SQL status: SELECT 217 in 2.0 seconds
[0m17:42:46.154878 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:42:46.155345 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m17:42:46.155787 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m17:42:46.156287 [debug] [Thread-4 (]: On model.bde.fact_G02: BEGIN
[0m17:42:46.156606 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:46.165576 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:46.168058 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:42:46.168484 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m17:42:46.177895 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:46.179301 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m17:42:46.179598 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:42:46.179864 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m17:42:46.189568 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:46.191502 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:42:46.191795 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m17:42:46.209362 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:46.210589 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 17:42:44.030104 => 17:42:46.210424
[0m17:42:46.210984 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m17:42:46.211738 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106033a90>]}
[0m17:42:46.212259 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 217[0m in 2.20s]
[0m17:42:46.212788 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m17:42:46.213170 [debug] [Thread-1 (]: Began running node model.bde.fact_listing
[0m17:42:46.213656 [info ] [Thread-1 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m17:42:46.214296 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.fact_listing)
[0m17:42:46.214612 [debug] [Thread-1 (]: Began compiling node model.bde.fact_listing
[0m17:42:46.217221 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m17:42:46.217843 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (compile): 17:42:46.214818 => 17:42:46.217696
[0m17:42:46.218144 [debug] [Thread-1 (]: Began executing node model.bde.fact_listing
[0m17:42:46.221256 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m17:42:46.221742 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m17:42:46.222021 [debug] [Thread-1 (]: On model.bde.fact_listing: BEGIN
[0m17:42:46.222255 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:42:46.264036 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:46.264470 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m17:42:46.264778 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m17:42:46.285309 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m17:42:46.288056 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m17:42:46.288372 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m17:42:46.297349 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:46.299991 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m17:42:46.300331 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m17:42:46.309151 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:46.310497 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m17:42:46.310788 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m17:42:46.311037 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m17:42:46.321268 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:46.323487 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m17:42:46.323835 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m17:42:46.334287 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:46.334621 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m17:42:46.334975 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    LISTING_NEIGHBOURHOOD,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m17:42:46.336908 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:46.339680 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (execute): 17:42:46.145142 => 17:42:46.339522
[0m17:42:46.340042 [debug] [Thread-4 (]: On model.bde.fact_G02: Close
[0m17:42:46.340750 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10605b790>]}
[0m17:42:46.341256 [info ] [Thread-4 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.20s]
[0m17:42:46.341705 [debug] [Thread-4 (]: Finished running node model.bde.fact_G02
[0m17:42:46.342022 [debug] [Thread-4 (]: Began running node model.bde.dim_host
[0m17:42:46.342420 [info ] [Thread-4 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m17:42:46.342982 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m17:42:46.343294 [debug] [Thread-4 (]: Began compiling node model.bde.dim_host
[0m17:42:46.345723 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_host"
[0m17:42:46.346335 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (compile): 17:42:46.343496 => 17:42:46.346195
[0m17:42:46.346629 [debug] [Thread-4 (]: Began executing node model.bde.dim_host
[0m17:42:46.349659 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_host"
[0m17:42:46.350119 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m17:42:46.350369 [debug] [Thread-4 (]: On model.bde.dim_host: BEGIN
[0m17:42:46.350597 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:46.459829 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:46.460479 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m17:42:46.461016 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    scraped_date,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m17:42:47.147708 [debug] [Thread-4 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m17:42:47.155776 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m17:42:47.156538 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m17:42:48.138320 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m17:42:48.143087 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:42:48.143645 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m17:42:48.153022 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:48.156029 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:42:48.156406 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m17:42:48.170188 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:48.171818 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m17:42:48.172154 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:42:48.172463 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m17:42:48.214469 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:48.221034 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:42:48.221827 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m17:42:48.251878 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:48.256865 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 17:42:44.054463 => 17:42:48.256552
[0m17:42:48.257778 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m17:42:48.259636 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060ab250>]}
[0m17:42:48.260669 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 4.25s]
[0m17:42:48.261469 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m17:42:48.262021 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m17:42:48.262744 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m17:42:48.263779 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m17:42:48.264228 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m17:42:48.268519 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m17:42:48.269800 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 17:42:48.264531 => 17:42:48.269620
[0m17:42:48.270172 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m17:42:48.276421 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m17:42:48.277400 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:42:48.277721 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m17:42:48.278008 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m17:42:48.395471 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:48.397158 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:42:48.397742 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m17:42:49.024816 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m17:42:49.033779 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:42:49.034721 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m17:42:50.012978 [debug] [Thread-1 (]: SQL status: SELECT 340945 in 4.0 seconds
[0m17:42:50.014666 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 6.0 seconds
[0m17:42:50.022803 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m17:42:50.026557 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:42:50.027038 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m17:42:50.027487 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m17:42:50.037171 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:50.040870 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:42:50.041309 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m17:42:50.051162 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:50.053031 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m17:42:50.053444 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:42:50.053809 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m17:42:50.133574 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:50.134890 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:50.135860 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 3.0 seconds
[0m17:42:50.136341 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 1.0 seconds
[0m17:42:50.141009 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m17:42:50.144093 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:42:50.147091 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m17:42:50.149963 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:42:50.150315 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m17:42:50.150654 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m17:42:50.150984 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m17:42:50.151302 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m17:42:50.162005 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:50.163640 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m17:42:50.163975 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:50.164302 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:50.164603 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m17:42:50.166127 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m17:42:50.169375 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m17:42:50.169738 [debug] [Thread-1 (]: On model.bde.fact_listing: COMMIT
[0m17:42:50.170060 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:42:50.170362 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m17:42:50.170721 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m17:42:50.171026 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:50.171305 [debug] [Thread-4 (]: On model.bde.dim_host: COMMIT
[0m17:42:50.172425 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 17:42:44.067765 => 17:42:50.172247
[0m17:42:50.172777 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m17:42:50.173551 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10605bf10>]}
[0m17:42:50.174119 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 6.16s]
[0m17:42:50.174608 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m17:42:50.174929 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m17:42:50.175334 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m17:42:50.175861 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m17:42:50.176136 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m17:42:50.178682 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m17:42:50.179357 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 17:42:50.176325 => 17:42:50.179223
[0m17:42:50.179642 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m17:42:50.182665 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m17:42:50.183003 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:50.183274 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:50.183495 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:50.185312 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_listing"
[0m17:42:50.187138 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:42:50.188815 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_host"
[0m17:42:50.189124 [debug] [Thread-1 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m17:42:50.189419 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:42:50.189657 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m17:42:50.189915 [debug] [Thread-4 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m17:42:50.190195 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m17:42:50.190539 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m17:42:50.223023 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:50.224275 [debug] [Thread-1 (]: Timing info for model.bde.fact_listing (execute): 17:42:46.218346 => 17:42:50.224147
[0m17:42:50.224584 [debug] [Thread-1 (]: On model.bde.fact_listing: Close
[0m17:42:50.224865 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:50.225854 [debug] [Thread-4 (]: Timing info for model.bde.dim_host (execute): 17:42:46.346833 => 17:42:50.225738
[0m17:42:50.226396 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063505b0>]}
[0m17:42:50.226708 [debug] [Thread-4 (]: On model.bde.dim_host: Close
[0m17:42:50.227215 [info ] [Thread-1 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 4.01s]
[0m17:42:50.227749 [debug] [Thread-1 (]: Finished running node model.bde.fact_listing
[0m17:42:50.228205 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10659b8e0>]}
[0m17:42:50.228515 [debug] [Thread-1 (]: Began running node model.bde.dim_suburb
[0m17:42:50.228955 [info ] [Thread-4 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 3.89s]
[0m17:42:50.229324 [info ] [Thread-1 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m17:42:50.229718 [debug] [Thread-4 (]: Finished running node model.bde.dim_host
[0m17:42:50.230158 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_listing, now model.bde.dim_suburb)
[0m17:42:50.230520 [debug] [Thread-1 (]: Began compiling node model.bde.dim_suburb
[0m17:42:50.232851 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m17:42:50.233104 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:50.234096 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 17:42:48.270410 => 17:42:50.233984
[0m17:42:50.234362 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m17:42:50.234895 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106033b80>]}
[0m17:42:50.235194 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (compile): 17:42:50.230718 => 17:42:50.235069
[0m17:42:50.235562 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 1.97s]
[0m17:42:50.235846 [debug] [Thread-1 (]: Began executing node model.bde.dim_suburb
[0m17:42:50.236180 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m17:42:50.238948 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m17:42:50.239490 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:42:50.239724 [debug] [Thread-1 (]: On model.bde.dim_suburb: BEGIN
[0m17:42:50.239936 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:42:50.314919 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:50.315399 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:42:50.315727 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m17:42:50.370492 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:42:50.370892 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:42:50.371307 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m17:42:50.392413 [debug] [Thread-1 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m17:42:50.396728 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:42:50.397247 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m17:42:50.406697 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:50.412642 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:42:50.413147 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m17:42:50.422783 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:50.424599 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m17:42:50.424983 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:42:50.425338 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m17:42:50.446817 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:50.450176 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:42:50.450665 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m17:42:50.516249 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m17:42:50.516877 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:50.520960 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:42:50.522632 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (execute): 17:42:50.236353 => 17:42:50.522420
[0m17:42:50.523067 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m17:42:50.523486 [debug] [Thread-1 (]: On model.bde.dim_suburb: Close
[0m17:42:50.524523 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106548940>]}
[0m17:42:50.525237 [info ] [Thread-1 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.29s]
[0m17:42:50.525904 [debug] [Thread-1 (]: Finished running node model.bde.dim_suburb
[0m17:42:50.535299 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:50.538505 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:42:50.538941 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m17:42:50.548779 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:42:50.550786 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m17:42:50.551198 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:42:50.551510 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m17:42:50.563135 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m17:42:50.566145 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:42:50.566522 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m17:42:50.583105 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:42:50.584593 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 17:42:50.179839 => 17:42:50.584391
[0m17:42:50.585003 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m17:42:50.585948 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e28465c7-0cbc-4cf7-9a1f-d79494684028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065279a0>]}
[0m17:42:50.586602 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.41s]
[0m17:42:50.587224 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m17:42:50.589028 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:50.589410 [debug] [MainThread]: On master: BEGIN
[0m17:42:50.589696 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:42:50.691842 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:42:50.692269 [debug] [MainThread]: On master: COMMIT
[0m17:42:50.692504 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:50.692717 [debug] [MainThread]: On master: COMMIT
[0m17:42:50.701708 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:42:50.701930 [debug] [MainThread]: On master: Close
[0m17:42:50.702472 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:42:50.702680 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m17:42:50.702866 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m17:42:50.703043 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m17:42:50.703222 [debug] [MainThread]: Connection 'model.bde.dim_host' was properly closed.
[0m17:42:50.703510 [info ] [MainThread]: 
[0m17:42:50.703772 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 7.25 seconds (7.25s).
[0m17:42:50.705636 [debug] [MainThread]: Command end result
[0m17:42:50.712815 [info ] [MainThread]: 
[0m17:42:50.713151 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:42:50.713386 [info ] [MainThread]: 
[0m17:42:50.713623 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m17:42:50.714080 [debug] [MainThread]: Command `dbt run` succeeded at 17:42:50.714020 after 7.39 seconds
[0m17:42:50.714343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10351a500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106520820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10605a110>]}
[0m17:42:50.714599 [debug] [MainThread]: Flushing usage events
[0m17:43:35.808109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103d98a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11364dae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11364d3c0>]}


============================== 17:43:35.810782 | 1f60dee9-9d5e-4683-ae28-941e1231a181 ==============================
[0m17:43:35.810782 [info ] [MainThread]: Running with dbt=1.6.6
[0m17:43:35.811123 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m17:43:35.867542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11364d630>]}
[0m17:43:35.875097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142b1180>]}
[0m17:43:35.875496 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m17:43:35.884553 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m17:43:35.910795 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:43:35.911185 [debug] [MainThread]: Partial parsing: updated file: bde://models/warehouse/fact_listing.sql
[0m17:43:35.930483 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.median
- models.bde.raw
[0m17:43:35.933373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114aecc40>]}
[0m17:43:35.939741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11474ad10>]}
[0m17:43:35.939980 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m17:43:35.940167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11474aef0>]}
[0m17:43:35.941273 [info ] [MainThread]: 
[0m17:43:35.941664 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:43:35.942486 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m17:43:35.942897 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m17:43:35.943231 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m17:43:35.947981 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m17:43:35.948939 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m17:43:35.949767 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m17:43:35.949940 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m17:43:35.950111 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m17:43:35.950271 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m17:43:35.950424 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:43:35.950564 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:43:35.950702 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:43:36.125467 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:43:36.127048 [debug] [ThreadPool]: On list_postgres: Close
[0m17:43:36.128947 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:43:36.129709 [debug] [ThreadPool]: On list_postgres: Close
[0m17:43:36.130273 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:43:36.131088 [debug] [ThreadPool]: On list_postgres: Close
[0m17:43:36.132864 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_warehouse)
[0m17:43:36.133372 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m17:43:36.138049 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m17:43:36.138431 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m17:43:36.138863 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_staging'
[0m17:43:36.140116 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m17:43:36.140339 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m17:43:36.141418 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m17:43:36.142530 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m17:43:36.142760 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m17:43:36.142975 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:43:36.143154 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m17:43:36.143345 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m17:43:36.143511 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:43:36.143793 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:43:36.144139 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:43:36.243964 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:43:36.244417 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m17:43:36.244691 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m17:43:36.244992 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:43:36.245320 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m17:43:36.245561 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m17:43:36.247999 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:43:36.248248 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m17:43:36.248519 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m17:43:36.250956 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:43:36.251184 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m17:43:36.251415 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m17:43:36.262694 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:43:36.263944 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m17:43:36.266119 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:43:36.267079 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m17:43:36.269101 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:43:36.270124 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m17:43:36.270408 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:43:36.271455 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m17:43:36.273389 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m17:43:36.276259 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m17:43:36.279031 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m17:43:36.282699 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m17:43:36.288277 [debug] [MainThread]: Using postgres connection "master"
[0m17:43:36.288677 [debug] [MainThread]: On master: BEGIN
[0m17:43:36.288913 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:43:36.386103 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:43:36.386626 [debug] [MainThread]: Using postgres connection "master"
[0m17:43:36.387153 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:43:36.414468 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m17:43:36.419282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114a68070>]}
[0m17:43:36.419955 [debug] [MainThread]: On master: ROLLBACK
[0m17:43:36.429676 [debug] [MainThread]: Using postgres connection "master"
[0m17:43:36.430063 [debug] [MainThread]: On master: BEGIN
[0m17:43:36.449014 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:43:36.450161 [debug] [MainThread]: On master: COMMIT
[0m17:43:36.450823 [debug] [MainThread]: Using postgres connection "master"
[0m17:43:36.451306 [debug] [MainThread]: On master: COMMIT
[0m17:43:36.461344 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:43:36.462012 [debug] [MainThread]: On master: Close
[0m17:43:36.463791 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:43:36.464621 [info ] [MainThread]: 
[0m17:43:36.470743 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m17:43:36.471372 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m17:43:36.471919 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m17:43:36.472432 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m17:43:36.473032 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m17:43:36.473679 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m17:43:36.474260 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m17:43:36.474750 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m17:43:36.475498 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.dm_host_neighbourhod)
[0m17:43:36.476123 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_listing_neighbourhood)
[0m17:43:36.476724 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_property_type)
[0m17:43:36.477326 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.stg_G01)
[0m17:43:36.477750 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m17:43:36.478119 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m17:43:36.478485 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m17:43:36.478839 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m17:43:36.487828 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m17:43:36.490859 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m17:43:36.495056 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m17:43:36.498129 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m17:43:36.499941 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 17:43:36.479538 => 17:43:36.499684
[0m17:43:36.500384 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m17:43:36.512402 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 17:43:36.491165 => 17:43:36.512231
[0m17:43:36.519110 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 17:43:36.495445 => 17:43:36.518986
[0m17:43:36.527365 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m17:43:36.527676 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 17:43:36.488266 => 17:43:36.527562
[0m17:43:36.527908 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m17:43:36.528186 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m17:43:36.528454 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m17:43:36.530697 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m17:43:36.530943 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:43:36.541510 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m17:43:36.543930 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m17:43:36.544349 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m17:43:36.544865 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:43:36.545166 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:43:36.545483 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:43:36.545716 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m17:43:36.545907 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:43:36.546213 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m17:43:36.546404 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m17:43:36.546602 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m17:43:36.546773 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:43:36.547019 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m17:43:36.648210 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:36.648572 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:36.648912 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:43:36.649193 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:43:36.649607 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    -- Set the configuration for the materialized view


-- Create a Common Table Expression (CTE) called host_neighbourhood_lga_transform
-- This CTE retrieves data from the dim_host and dim_suburb tables and transforms it.
-- It includes host data, host neighborhood's local government area, and month_year.

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM warehouse.dim_host host
    LEFT JOIN warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
-- Create a CTE called distinct_host_count
-- This CTE calculates the number of distinct hosts for each host_neighbourhood_lga and month_year.
distinct_host_count AS (
    SELECT
        TO_CHAR(ht.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        COUNT(DISTINCT ht.host_id) AS num_distinct_hosts
    FROM host_neighbourhood_lga_transform ht
    GROUP BY TO_CHAR(ht.scraped_date, 'MM/YYYY'),ht.host_neighbourhood_lga
),
-- Create a CTE called estimated_revenue
-- This CTE calculates the total estimated revenue for each host_neighbourhood_lga and month_year.
estimated_revenue AS (
    SELECT
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        SUM((30 - list.availability_30) * list.price) AS total_estimated_revenue
    FROM warehouse.fact_listing list
    LEFT JOIN host_neighbourhood_lga_transform ht ON list.surrogate_key_host = ht.surrogate_key_host
    WHERE list.has_availability = 't'
    GROUP BY
        TO_CHAR(list.scraped_date, 'MM/YYYY'),
        ht.host_neighbourhood_lga
)
-- Select the aggregated metrics including month_year, host_neighbourhood_lga, number of distinct hosts, total estimated revenue, and estimated revenue per host.
SELECT
    dh.host_neighbourhood_lga,
    dh.month_year,
    dh.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dh.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dh.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM distinct_host_count dh
LEFT JOIN estimated_revenue er ON dh.month_year = er.month_year AND dh.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY dh.host_neighbourhood_lga, dh.month_year
  );
  
[0m17:43:36.650240 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type

-- Set the configuration for the materialized view



-- Create a Common Table Expression (CTE) called sorted_listing
-- This CTE retrieves data from multiple tables and calculates various metrics
-- It includes property_type, room_type, accommodates, and more.


WITH sorted_listing AS (
    SELECT 
        prop.property_type,-- Property type
        room.room_type,-- Room type
        list.accommodates,-- Accommodates
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year, -- Truncate the date to the month
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id, -- Host ID
        host.host_is_superhost,-- Host is superhost flag
        review_scores_rating,-- Review scores rating
        availability_30-- Availability for the next 30 days
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
-- Select the aggregated metrics for the property_type, room_type, accommodates, and month_year
SELECT 
    property_type,-- Property type
    room_type,-- Room type
    accommodates,-- Number of accommodates
    month_year,-- Truncated month and year
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,-- Calculate the minimum price for active listings
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,-- Calculate the maximum price for active listings
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing, -- Calculate the median price for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts, -- Count the number of distinct hosts
     -- Calculate the superhost rate
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
     -- Calculate the average review scores rating for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


     -- Calculate the percentage change for active listing
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing

    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m17:43:36.658011 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:36.658305 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:43:36.658800 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,     
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m17:43:36.661402 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:36.661653 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:43:36.662071 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m17:43:36.692549 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:43:36.698759 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:43:36.699080 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m17:43:36.709491 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:36.711820 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:43:36.712117 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m17:43:36.723282 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:36.735305 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m17:43:36.735628 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:43:36.735936 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m17:43:36.747499 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:36.753491 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:43:36.753850 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m17:43:36.766317 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:43:36.767455 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 17:43:36.531096 => 17:43:36.767326
[0m17:43:36.767773 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m17:43:36.768471 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c21e10>]}
[0m17:43:36.768974 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.29s]
[0m17:43:36.769442 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m17:43:36.769766 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m17:43:36.770135 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m17:43:36.770598 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m17:43:36.770836 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m17:43:36.773216 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m17:43:36.774926 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 17:43:36.771013 => 17:43:36.774797
[0m17:43:36.775178 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m17:43:36.777962 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m17:43:36.778659 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:43:36.778911 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m17:43:36.779131 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:43:36.883092 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:36.883579 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:43:36.883955 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m17:43:36.898698 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:43:36.901427 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:43:36.901799 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m17:43:36.910714 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:36.912701 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:43:36.912975 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m17:43:36.921244 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:36.922618 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m17:43:36.922928 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:43:36.923186 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m17:43:36.947297 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:36.949501 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:43:36.949831 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m17:43:36.964975 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:43:36.966054 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 17:43:36.775345 => 17:43:36.965931
[0m17:43:36.966301 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m17:43:36.966868 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11696e5f0>]}
[0m17:43:36.967262 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.20s]
[0m17:43:36.967601 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m17:43:36.967842 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m17:43:36.968183 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m17:43:36.968561 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m17:43:36.968758 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m17:43:36.971574 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m17:43:36.972536 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 17:43:36.968883 => 17:43:36.972444
[0m17:43:36.972715 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m17:43:36.974713 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m17:43:36.975100 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:43:36.975272 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m17:43:36.975432 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:43:37.082248 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:37.082741 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:43:37.083124 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m17:43:37.095999 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:43:37.099362 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:43:37.099706 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m17:43:37.108968 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:37.111821 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:43:37.112147 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m17:43:37.122778 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:37.124268 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m17:43:37.124616 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:43:37.124914 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m17:43:37.134534 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:37.136758 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:43:37.137093 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m17:43:37.148622 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:43:37.149792 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 17:43:36.972899 => 17:43:37.149635
[0m17:43:37.150134 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m17:43:37.150909 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116943190>]}
[0m17:43:37.151467 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.18s]
[0m17:43:37.152001 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m17:43:37.152380 [debug] [Thread-4 (]: Began running node model.bde.stg_fact
[0m17:43:37.152980 [info ] [Thread-4 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m17:43:37.153654 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_fact)
[0m17:43:37.154077 [debug] [Thread-4 (]: Began compiling node model.bde.stg_fact
[0m17:43:37.157517 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m17:43:37.160191 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (compile): 17:43:37.154348 => 17:43:37.160022
[0m17:43:37.160526 [debug] [Thread-4 (]: Began executing node model.bde.stg_fact
[0m17:43:37.163797 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m17:43:37.164441 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:43:37.164773 [debug] [Thread-4 (]: On model.bde.stg_fact: BEGIN
[0m17:43:37.165055 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:43:37.300674 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:37.302363 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:43:37.303922 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        LISTING_NEIGHBOURHOOD,
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m17:43:37.323946 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:43:37.330026 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:43:37.331097 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m17:43:37.341667 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:37.348253 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:43:37.348774 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m17:43:37.358332 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:37.360457 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m17:43:37.360966 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:43:37.361415 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m17:43:37.374232 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:37.420170 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:43:37.420575 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m17:43:37.432878 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:43:37.433830 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (execute): 17:43:37.160730 => 17:43:37.433721
[0m17:43:37.434085 [debug] [Thread-4 (]: On model.bde.stg_fact: Close
[0m17:43:37.434652 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11427b040>]}
[0m17:43:37.435041 [info ] [Thread-4 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.28s]
[0m17:43:37.435399 [debug] [Thread-4 (]: Finished running node model.bde.stg_fact
[0m17:43:37.435659 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m17:43:37.436006 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m17:43:37.436383 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_host)
[0m17:43:37.436580 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m17:43:37.438506 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m17:43:37.440329 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 17:43:37.436713 => 17:43:37.440221
[0m17:43:37.440543 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m17:43:37.442930 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m17:43:37.443397 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:43:37.443617 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m17:43:37.443818 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:43:37.546789 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:37.547232 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:43:37.547691 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m17:43:37.563343 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:43:37.566709 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:43:37.567097 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m17:43:37.576428 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:37.579100 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:43:37.579455 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m17:43:37.588326 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:37.589909 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m17:43:37.590266 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:43:37.590565 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m17:43:37.600061 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:37.602334 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:43:37.602675 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m17:43:37.614249 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:43:37.615705 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 17:43:37.440688 => 17:43:37.615500
[0m17:43:37.616102 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m17:43:37.617045 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c801c0>]}
[0m17:43:37.617666 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.18s]
[0m17:43:37.618215 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m17:43:37.618597 [debug] [Thread-4 (]: Began running node model.bde.stg_property
[0m17:43:37.619201 [info ] [Thread-4 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m17:43:37.619897 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_property)
[0m17:43:37.620257 [debug] [Thread-4 (]: Began compiling node model.bde.stg_property
[0m17:43:37.623454 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_property"
[0m17:43:37.625449 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (compile): 17:43:37.620499 => 17:43:37.625284
[0m17:43:37.625749 [debug] [Thread-4 (]: Began executing node model.bde.stg_property
[0m17:43:37.628985 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_property"
[0m17:43:37.629589 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:43:37.629871 [debug] [Thread-4 (]: On model.bde.stg_property: BEGIN
[0m17:43:37.630139 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:43:37.742093 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:37.742801 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:43:37.743467 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m17:43:37.758622 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:43:37.767476 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:43:37.768155 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m17:43:37.778671 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:37.782525 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:43:37.783253 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m17:43:37.793002 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:37.795211 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m17:43:37.795677 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:43:37.796060 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m17:43:37.806646 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:37.809638 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:43:37.810058 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m17:43:37.823422 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:43:37.825236 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (execute): 17:43:37.625950 => 17:43:37.824995
[0m17:43:37.825744 [debug] [Thread-4 (]: On model.bde.stg_property: Close
[0m17:43:37.826780 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c4ac80>]}
[0m17:43:37.827490 [info ] [Thread-4 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.21s]
[0m17:43:37.828135 [debug] [Thread-4 (]: Finished running node model.bde.stg_property
[0m17:43:37.828629 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m17:43:37.829276 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m17:43:37.830242 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_room)
[0m17:43:37.830657 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m17:43:37.833994 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m17:43:37.835771 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 17:43:37.830936 => 17:43:37.835520
[0m17:43:37.836234 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m17:43:37.840106 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m17:43:37.840992 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:43:37.841319 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m17:43:37.841595 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:43:37.951466 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:37.952348 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:43:37.952902 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m17:43:37.966054 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:43:37.972187 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:43:37.972800 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m17:43:37.981648 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:37.985310 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:43:37.985749 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m17:43:37.994577 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:37.996411 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m17:43:37.996815 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:43:37.997173 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m17:43:38.007579 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:38.010858 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:43:38.011272 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m17:43:38.022552 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:43:38.024337 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 17:43:37.836524 => 17:43:38.024095
[0m17:43:38.024820 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m17:43:38.025926 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116924670>]}
[0m17:43:38.026624 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.20s]
[0m17:43:38.027251 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m17:43:38.027717 [debug] [Thread-4 (]: Began running node model.bde.stg_suburb
[0m17:43:38.028419 [info ] [Thread-4 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m17:43:38.029238 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.stg_suburb)
[0m17:43:38.029665 [debug] [Thread-4 (]: Began compiling node model.bde.stg_suburb
[0m17:43:38.034862 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m17:43:38.035687 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (compile): 17:43:38.029952 => 17:43:38.035519
[0m17:43:38.036073 [debug] [Thread-4 (]: Began executing node model.bde.stg_suburb
[0m17:43:38.039809 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m17:43:38.040471 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:43:38.040814 [debug] [Thread-4 (]: On model.bde.stg_suburb: BEGIN
[0m17:43:38.041144 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:43:38.155052 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:38.155745 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:43:38.156272 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m17:43:38.167880 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:43:38.174046 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:43:38.174599 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m17:43:38.183775 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:38.187677 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:43:38.188242 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m17:43:38.196906 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:38.199378 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m17:43:38.199867 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:43:38.200298 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m17:43:38.211424 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:38.214626 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:43:38.215070 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m17:43:38.226109 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:43:38.227998 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (execute): 17:43:38.036312 => 17:43:38.227747
[0m17:43:38.228493 [debug] [Thread-4 (]: On model.bde.stg_suburb: Close
[0m17:43:38.229602 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c1c850>]}
[0m17:43:38.230261 [info ] [Thread-4 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.20s]
[0m17:43:38.230881 [debug] [Thread-4 (]: Finished running node model.bde.stg_suburb
[0m17:43:38.231331 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m17:43:38.231962 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m17:43:38.232687 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.dim_LGA)
[0m17:43:38.233056 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m17:43:38.236517 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m17:43:38.238822 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 17:43:38.233317 => 17:43:38.238622
[0m17:43:38.239199 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m17:43:38.242938 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m17:43:38.243521 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:43:38.243851 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m17:43:38.244151 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:43:38.356071 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:38.356745 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:43:38.357258 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m17:43:38.375143 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m17:43:38.379620 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:43:38.380153 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m17:43:38.390177 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:38.395960 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:43:38.396388 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m17:43:38.405772 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:38.411946 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m17:43:38.412382 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:43:38.412746 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m17:43:38.422912 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:38.427832 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:43:38.428283 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m17:43:38.446576 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:43:38.448049 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 17:43:38.239451 => 17:43:38.447849
[0m17:43:38.448459 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m17:43:38.449444 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114cebf70>]}
[0m17:43:38.450137 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.22s]
[0m17:43:38.450766 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m17:43:38.451230 [debug] [Thread-4 (]: Began running node model.bde.fact_G01
[0m17:43:38.451863 [info ] [Thread-4 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m17:43:38.452642 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G01)
[0m17:43:38.453020 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G01
[0m17:43:38.456145 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m17:43:38.457610 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (compile): 17:43:38.453278 => 17:43:38.457440
[0m17:43:38.457948 [debug] [Thread-4 (]: Began executing node model.bde.fact_G01
[0m17:43:38.461491 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m17:43:38.462033 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:43:38.462314 [debug] [Thread-4 (]: On model.bde.fact_G01: BEGIN
[0m17:43:38.462565 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:43:38.585961 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:38.587755 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:43:38.588517 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m17:43:38.619360 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m17:43:38.626250 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:43:38.626995 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m17:43:38.637306 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:38.641166 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:43:38.641710 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m17:43:38.651757 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:38.654517 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m17:43:38.655071 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:43:38.655544 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m17:43:38.666169 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:38.668782 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:43:38.669161 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m17:43:38.684172 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:43:38.685546 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (execute): 17:43:38.458174 => 17:43:38.685362
[0m17:43:38.685907 [debug] [Thread-4 (]: On model.bde.fact_G01: Close
[0m17:43:38.686691 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c1d000>]}
[0m17:43:38.687232 [info ] [Thread-4 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.23s]
[0m17:43:38.687797 [debug] [Thread-4 (]: Finished running node model.bde.fact_G01
[0m17:43:38.688182 [debug] [Thread-4 (]: Began running node model.bde.fact_G02
[0m17:43:38.688640 [info ] [Thread-4 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m17:43:38.689244 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_G02)
[0m17:43:38.689603 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G02
[0m17:43:38.692642 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m17:43:38.693418 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (compile): 17:43:38.689834 => 17:43:38.693234
[0m17:43:38.693735 [debug] [Thread-4 (]: Began executing node model.bde.fact_G02
[0m17:43:38.698189 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m17:43:38.698715 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m17:43:38.698988 [debug] [Thread-4 (]: On model.bde.fact_G02: BEGIN
[0m17:43:38.699242 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:43:38.813689 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:38.814794 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m17:43:38.815557 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m17:43:38.840407 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m17:43:38.846851 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m17:43:38.847449 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m17:43:38.857105 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:38.861013 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m17:43:38.861517 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m17:43:38.871225 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:38.873507 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m17:43:38.873975 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m17:43:38.874398 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m17:43:38.884836 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:38.888021 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m17:43:38.888488 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m17:43:38.903716 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:43:38.905611 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (execute): 17:43:38.693933 => 17:43:38.905394
[0m17:43:38.906056 [debug] [Thread-4 (]: On model.bde.fact_G02: Close
[0m17:43:38.906958 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114a32050>]}
[0m17:43:38.907544 [info ] [Thread-4 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.22s]
[0m17:43:38.908098 [debug] [Thread-4 (]: Finished running node model.bde.fact_G02
[0m17:43:38.908496 [debug] [Thread-4 (]: Began running node model.bde.fact_listing
[0m17:43:38.909006 [info ] [Thread-4 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m17:43:38.909658 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.fact_listing)
[0m17:43:38.910007 [debug] [Thread-4 (]: Began compiling node model.bde.fact_listing
[0m17:43:38.913026 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m17:43:38.914625 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (compile): 17:43:38.910244 => 17:43:38.914475
[0m17:43:38.914933 [debug] [Thread-4 (]: Began executing node model.bde.fact_listing
[0m17:43:38.917985 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m17:43:38.918474 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m17:43:38.918748 [debug] [Thread-4 (]: On model.bde.fact_listing: BEGIN
[0m17:43:38.919011 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:43:39.025436 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:39.025830 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m17:43:39.026105 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    UPPER(LISTING_NEIGHBOURHOOD),
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m17:43:40.861831 [debug] [Thread-1 (]: SQL status: SELECT 217 in 4.0 seconds
[0m17:43:40.871005 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:43:40.871820 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m17:43:40.882116 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:40.886251 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:43:40.886775 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m17:43:40.895772 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:40.898193 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m17:43:40.898676 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:43:40.899033 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m17:43:40.915536 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:40.918816 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:43:40.919346 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m17:43:40.934710 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:43:40.938724 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 17:43:36.500667 => 17:43:40.938485
[0m17:43:40.939224 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m17:43:40.940329 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114748550>]}
[0m17:43:40.941036 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 217[0m in 4.47s]
[0m17:43:40.941653 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m17:43:40.942091 [debug] [Thread-1 (]: Began running node model.bde.dim_host
[0m17:43:40.942530 [info ] [Thread-1 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m17:43:40.943292 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.dim_host)
[0m17:43:40.943700 [debug] [Thread-1 (]: Began compiling node model.bde.dim_host
[0m17:43:40.947098 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_host"
[0m17:43:40.948970 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (compile): 17:43:40.943975 => 17:43:40.948812
[0m17:43:40.949291 [debug] [Thread-1 (]: Began executing node model.bde.dim_host
[0m17:43:40.952985 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_host"
[0m17:43:40.954050 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:43:40.954485 [debug] [Thread-1 (]: On model.bde.dim_host: BEGIN
[0m17:43:40.954798 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:43:41.073209 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:41.073610 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:43:41.073904 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    scraped_date,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m17:43:42.658017 [debug] [Thread-1 (]: SQL status: SELECT 28839 in 2.0 seconds
[0m17:43:42.666070 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:43:42.666791 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m17:43:48.977770 [debug] [Thread-4 (]: SQL status: SELECT 340945 in 10.0 seconds
[0m17:43:48.987839 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m17:43:48.988625 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m17:43:49.304173 [debug] [Thread-2 (]: SQL status: SELECT 296 in 13.0 seconds
[0m17:43:49.307804 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:43:49.308163 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m17:43:49.318462 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:49.320454 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:43:49.320732 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m17:43:49.333439 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:49.334622 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m17:43:49.334873 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:43:49.335086 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m17:43:49.348384 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:49.350115 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:43:49.350361 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m17:43:49.371637 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:43:49.372553 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 17:43:36.541723 => 17:43:49.372432
[0m17:43:49.372822 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m17:43:49.373408 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11698b9a0>]}
[0m17:43:49.373815 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 12.90s]
[0m17:43:49.374214 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m17:43:49.374487 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m17:43:49.374823 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m17:43:49.375235 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m17:43:49.375476 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m17:43:49.377587 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m17:43:49.378574 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 17:43:49.375660 => 17:43:49.378455
[0m17:43:49.378828 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m17:43:49.382404 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m17:43:49.383226 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:43:49.383494 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m17:43:49.383706 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m17:43:49.513203 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:49.513795 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:43:49.514436 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m17:43:49.850699 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m17:43:49.857928 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:43:49.858645 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m17:43:50.035912 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 13.0 seconds
[0m17:43:50.042914 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:43:50.043667 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m17:43:50.053872 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:50.058452 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:43:50.059261 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m17:43:50.068462 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:50.070812 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m17:43:50.071306 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:43:50.071727 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m17:43:50.082208 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 7.0 seconds
[0m17:43:50.082720 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 1.0 seconds
[0m17:43:50.083278 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:50.086902 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:43:50.090032 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m17:43:50.092604 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:43:50.093013 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m17:43:50.093377 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m17:43:50.093705 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m17:43:50.101916 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:50.102317 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:50.102694 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:50.105585 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:43:50.107329 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m17:43:50.108798 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m17:43:50.109138 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m17:43:50.109466 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m17:43:50.109810 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:43:50.110236 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:43:50.110640 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m17:43:50.111783 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 17:43:36.528613 => 17:43:50.111617
[0m17:43:50.112113 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m17:43:50.112511 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m17:43:50.113361 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142b3220>]}
[0m17:43:50.113892 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 13.64s]
[0m17:43:50.114375 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m17:43:50.114719 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m17:43:50.115122 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m17:43:50.115672 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m17:43:50.115962 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m17:43:50.119883 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m17:43:50.120185 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:50.121763 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m17:43:50.122274 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:43:50.122717 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:50.123113 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 17:43:50.116161 => 17:43:50.122973
[0m17:43:50.123419 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m17:43:50.123685 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:50.125852 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m17:43:50.126157 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m17:43:50.127996 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:43:50.128287 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m17:43:50.131100 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m17:43:50.131386 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m17:43:50.132019 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:43:50.132322 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m17:43:50.132556 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m17:43:50.152783 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:50.154867 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:43:50.155148 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m17:43:50.156511 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:43:50.157587 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (execute): 17:43:40.949514 => 17:43:50.157455
[0m17:43:50.157860 [debug] [Thread-1 (]: On model.bde.dim_host: Close
[0m17:43:50.158465 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114a68ee0>]}
[0m17:43:50.158876 [info ] [Thread-1 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 9.22s]
[0m17:43:50.159321 [debug] [Thread-1 (]: Finished running node model.bde.dim_host
[0m17:43:50.159619 [debug] [Thread-1 (]: Began running node model.bde.dim_suburb
[0m17:43:50.159964 [info ] [Thread-1 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m17:43:50.160434 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dim_host, now model.bde.dim_suburb)
[0m17:43:50.160721 [debug] [Thread-1 (]: Began compiling node model.bde.dim_suburb
[0m17:43:50.163007 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m17:43:50.163826 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (compile): 17:43:50.160905 => 17:43:50.163718
[0m17:43:50.164077 [debug] [Thread-1 (]: Began executing node model.bde.dim_suburb
[0m17:43:50.166795 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m17:43:50.167264 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:43:50.167502 [debug] [Thread-1 (]: On model.bde.dim_suburb: BEGIN
[0m17:43:50.167723 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:43:50.170790 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:43:50.171665 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 17:43:49.378987 => 17:43:50.171563
[0m17:43:50.171923 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:43:50.172231 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m17:43:50.173216 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (execute): 17:43:38.915132 => 17:43:50.173092
[0m17:43:50.173549 [debug] [Thread-4 (]: On model.bde.fact_listing: Close
[0m17:43:50.174000 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c53190>]}
[0m17:43:50.174876 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11697e830>]}
[0m17:43:50.174487 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 0.80s]
[0m17:43:50.175375 [info ] [Thread-4 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 11.27s]
[0m17:43:50.175816 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m17:43:50.176217 [debug] [Thread-4 (]: Finished running node model.bde.fact_listing
[0m17:43:50.259135 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:50.259621 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:43:50.259953 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m17:43:50.268728 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:43:50.269077 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:43:50.269399 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m17:43:50.288660 [debug] [Thread-1 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m17:43:50.291959 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:43:50.292339 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m17:43:50.301984 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:50.306358 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:43:50.306723 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m17:43:50.320814 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:50.322408 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m17:43:50.322797 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:43:50.323181 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m17:43:50.339127 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:50.342007 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:43:50.342408 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m17:43:50.359810 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:43:50.361525 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (execute): 17:43:50.164253 => 17:43:50.361291
[0m17:43:50.362014 [debug] [Thread-1 (]: On model.bde.dim_suburb: Close
[0m17:43:50.363061 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11698d000>]}
[0m17:43:50.363766 [info ] [Thread-1 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.20s]
[0m17:43:50.364454 [debug] [Thread-1 (]: Finished running node model.bde.dim_suburb
[0m17:43:50.493499 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m17:43:50.502600 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:43:50.503203 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m17:43:50.512953 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:50.518394 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:43:50.518905 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m17:43:50.530954 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:43:50.533213 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m17:43:50.533690 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:43:50.534118 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m17:43:50.607381 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m17:43:50.609832 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:43:50.610218 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m17:43:50.634475 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:43:50.636065 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 17:43:50.128494 => 17:43:50.635864
[0m17:43:50.636485 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m17:43:50.637415 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f60dee9-9d5e-4683-ae28-941e1231a181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c33d90>]}
[0m17:43:50.638064 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.52s]
[0m17:43:50.638687 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m17:43:50.640395 [debug] [MainThread]: Using postgres connection "master"
[0m17:43:50.640853 [debug] [MainThread]: On master: BEGIN
[0m17:43:50.641205 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:43:50.755236 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:43:50.757439 [debug] [MainThread]: On master: COMMIT
[0m17:43:50.758538 [debug] [MainThread]: Using postgres connection "master"
[0m17:43:50.759488 [debug] [MainThread]: On master: COMMIT
[0m17:43:50.769160 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:43:50.769725 [debug] [MainThread]: On master: Close
[0m17:43:50.770700 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:43:50.771063 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m17:43:50.771399 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m17:43:50.771707 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m17:43:50.771986 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m17:43:50.772447 [info ] [MainThread]: 
[0m17:43:50.772838 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 14.83 seconds (14.83s).
[0m17:43:50.775840 [debug] [MainThread]: Command end result
[0m17:43:50.785969 [info ] [MainThread]: 
[0m17:43:50.786347 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:43:50.786625 [info ] [MainThread]: 
[0m17:43:50.786894 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m17:43:50.787389 [debug] [MainThread]: Command `dbt run` succeeded at 17:43:50.787319 after 14.99 seconds
[0m17:43:50.787717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103d98a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114a68070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114cdee90>]}
[0m17:43:50.788045 [debug] [MainThread]: Flushing usage events
[0m17:45:57.201921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103711810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105665b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105665450>]}


============================== 17:45:57.204565 | 4a715cf2-0c9b-47df-a96e-2f9d70ac89df ==============================
[0m17:45:57.204565 [info ] [MainThread]: Running with dbt=1.6.6
[0m17:45:57.204892 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'debug': 'False', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:45:57.259631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105665660>]}
[0m17:45:57.267127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ab11b0>]}
[0m17:45:57.267487 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m17:45:57.276774 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m17:45:57.311840 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:45:57.312248 [debug] [MainThread]: Partial parsing: updated file: bde://models/warehouse/fact_listing.sql
[0m17:45:57.332941 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.median
- models.bde.raw
[0m17:45:57.335744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060224d0>]}
[0m17:45:57.342279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ecad40>]}
[0m17:45:57.342510 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m17:45:57.342690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ecaf20>]}
[0m17:45:57.343798 [info ] [MainThread]: 
[0m17:45:57.344174 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:45:57.344970 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m17:45:57.345388 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m17:45:57.350248 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m17:45:57.350599 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m17:45:57.351658 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m17:45:57.351888 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m17:45:57.352807 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m17:45:57.353000 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m17:45:57.353206 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:45:57.353355 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m17:45:57.353497 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:45:57.354507 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:45:57.495369 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:45:57.496645 [debug] [ThreadPool]: On list_postgres: Close
[0m17:45:57.498676 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:45:57.499455 [debug] [ThreadPool]: On list_postgres: Close
[0m17:45:57.504406 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:45:57.505096 [debug] [ThreadPool]: On list_postgres: Close
[0m17:45:57.506523 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m17:45:57.506939 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m17:45:57.511259 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m17:45:57.511691 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_warehouse)
[0m17:45:57.519165 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_staging'
[0m17:45:57.520653 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m17:45:57.520939 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m17:45:57.522046 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m17:45:57.523065 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m17:45:57.523269 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m17:45:57.523435 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:45:57.523601 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m17:45:57.523757 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m17:45:57.523918 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:45:57.524194 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:45:57.524415 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:45:57.633734 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:45:57.634151 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:45:57.634403 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:45:57.634717 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m17:45:57.634959 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m17:45:57.635177 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m17:45:57.635434 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m17:45:57.635700 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m17:45:57.635965 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m17:45:57.657533 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:45:57.657808 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:45:57.658041 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:45:57.658315 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m17:45:57.659515 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m17:45:57.660447 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m17:45:57.660750 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m17:45:57.669689 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:45:57.669947 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m17:45:57.670174 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m17:45:57.671142 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m17:45:57.674977 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m17:45:57.676030 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m17:45:57.682367 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m17:45:57.685900 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m17:45:57.690795 [debug] [MainThread]: Using postgres connection "master"
[0m17:45:57.691055 [debug] [MainThread]: On master: BEGIN
[0m17:45:57.691259 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:45:57.806339 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:45:57.806730 [debug] [MainThread]: Using postgres connection "master"
[0m17:45:57.807060 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:45:57.834583 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m17:45:57.837375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106023190>]}
[0m17:45:57.837908 [debug] [MainThread]: On master: ROLLBACK
[0m17:45:57.846790 [debug] [MainThread]: Using postgres connection "master"
[0m17:45:57.847158 [debug] [MainThread]: On master: BEGIN
[0m17:45:57.866405 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:45:57.866899 [debug] [MainThread]: On master: COMMIT
[0m17:45:57.867208 [debug] [MainThread]: Using postgres connection "master"
[0m17:45:57.867457 [debug] [MainThread]: On master: COMMIT
[0m17:45:57.876634 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:45:57.876956 [debug] [MainThread]: On master: Close
[0m17:45:57.877930 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:45:57.878302 [info ] [MainThread]: 
[0m17:45:57.882315 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m17:45:57.882718 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m17:45:57.883071 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m17:45:57.883418 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m17:45:57.883838 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m17:45:57.884253 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m17:45:57.884631 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m17:45:57.884981 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m17:45:57.885567 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_host_neighbourhod)
[0m17:45:57.886045 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_listing_neighbourhood)
[0m17:45:57.886489 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.dm_property_type)
[0m17:45:57.886916 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.stg_G01)
[0m17:45:57.887180 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m17:45:57.887430 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m17:45:57.887672 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m17:45:57.887928 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m17:45:57.894484 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m17:45:57.897748 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m17:45:57.901549 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m17:45:57.903919 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m17:45:57.906380 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 17:45:57.888111 => 17:45:57.906137
[0m17:45:57.906810 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m17:45:57.907154 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 17:45:57.901820 => 17:45:57.907013
[0m17:45:57.920879 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 17:45:57.898073 => 17:45:57.920700
[0m17:45:57.921218 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 17:45:57.895076 => 17:45:57.921092
[0m17:45:57.932118 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m17:45:57.932440 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m17:45:57.932754 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m17:45:57.932958 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m17:45:57.943744 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m17:45:57.946123 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m17:45:57.946440 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:45:57.948619 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m17:45:57.948999 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m17:45:57.949312 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:45:57.949510 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:45:57.949728 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:45:57.950031 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:45:57.950208 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m17:45:57.950386 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m17:45:57.950571 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m17:45:57.950751 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m17:45:57.950924 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:45:57.951100 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m17:45:58.064051 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m17:45:58.064586 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:45:58.065106 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type

-- Set the configuration for the materialized view



-- Create a Common Table Expression (CTE) called sorted_listing
-- This CTE retrieves data from multiple tables and calculates various metrics
-- It includes property_type, room_type, accommodates, and more.


WITH sorted_listing AS (
    SELECT 
        prop.property_type,-- Property type
        room.room_type,-- Room type
        list.accommodates,-- Accommodates
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year, -- Truncate the date to the month
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id, -- Host ID
        host.host_is_superhost,-- Host is superhost flag
        review_scores_rating,-- Review scores rating
        availability_30-- Availability for the next 30 days
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
-- Select the aggregated metrics for the property_type, room_type, accommodates, and month_year
SELECT 
    property_type,-- Property type
    room_type,-- Room type
    accommodates,-- Number of accommodates
    month_year,-- Truncated month and year
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,-- Calculate the minimum price for active listings
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,-- Calculate the maximum price for active listings
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing, -- Calculate the median price for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts, -- Count the number of distinct hosts
     -- Calculate the superhost rate
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
     -- Calculate the average review scores rating for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


     -- Calculate the percentage change for active listing
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing

    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m17:45:58.065618 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:45:58.065984 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:45:58.066363 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    -- Set the configuration for the materialized view


-- Create a Common Table Expression (CTE) called host_neighbourhood_lga_transform
-- This CTE retrieves data from the dim_host and dim_suburb tables and transforms it.
-- It includes host data, host neighborhood's local government area, and month_year.

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM warehouse.dim_host host
    LEFT JOIN warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
-- Create a CTE called distinct_host_count
-- This CTE calculates the number of distinct hosts for each host_neighbourhood_lga and month_year.
distinct_host_count AS (
    SELECT
        TO_CHAR(ht.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        COUNT(DISTINCT ht.host_id) AS num_distinct_hosts
    FROM host_neighbourhood_lga_transform ht
    GROUP BY TO_CHAR(ht.scraped_date, 'MM/YYYY'),ht.host_neighbourhood_lga
),
-- Create a CTE called estimated_revenue
-- This CTE calculates the total estimated revenue for each host_neighbourhood_lga and month_year.
estimated_revenue AS (
    SELECT
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        SUM((30 - list.availability_30) * list.price) AS total_estimated_revenue
    FROM warehouse.fact_listing list
    LEFT JOIN host_neighbourhood_lga_transform ht ON list.surrogate_key_host = ht.surrogate_key_host
    WHERE list.has_availability = 't'
    GROUP BY
        TO_CHAR(list.scraped_date, 'MM/YYYY'),
        ht.host_neighbourhood_lga
)
-- Select the aggregated metrics including month_year, host_neighbourhood_lga, number of distinct hosts, total estimated revenue, and estimated revenue per host.
SELECT
    dh.host_neighbourhood_lga,
    dh.month_year,
    dh.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dh.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dh.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM distinct_host_count dh
LEFT JOIN estimated_revenue er ON dh.month_year = er.month_year AND dh.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY dh.host_neighbourhood_lga, dh.month_year
  );
  
[0m17:45:58.068385 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m17:45:58.068637 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:45:58.069088 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,     
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m17:45:58.070024 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:45:58.070265 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:45:58.070639 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m17:45:58.109553 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:45:58.115422 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:45:58.115716 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m17:45:58.127685 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:58.129655 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:45:58.129921 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m17:45:58.142200 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:58.153420 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m17:45:58.153700 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:45:58.153913 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m17:45:58.165420 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:45:58.171053 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m17:45:58.171356 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m17:45:58.184598 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:45:58.185641 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 17:45:57.933241 => 17:45:58.185512
[0m17:45:58.185940 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m17:45:58.186586 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060b0e80>]}
[0m17:45:58.187037 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.30s]
[0m17:45:58.187448 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m17:45:58.187731 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m17:45:58.188133 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m17:45:58.188693 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m17:45:58.188951 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m17:45:58.191204 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m17:45:58.193880 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 17:45:58.189127 => 17:45:58.193653
[0m17:45:58.194277 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m17:45:58.197171 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m17:45:58.197672 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:45:58.197894 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m17:45:58.198097 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:45:58.311057 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:45:58.311572 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:45:58.312045 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m17:45:58.326578 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:45:58.330609 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:45:58.331073 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m17:45:58.341125 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:58.343997 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:45:58.344349 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m17:45:58.353830 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:58.355796 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m17:45:58.356214 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:45:58.356570 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m17:45:58.367020 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:45:58.371086 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m17:45:58.371436 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m17:45:58.383038 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:45:58.384489 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 17:45:58.194486 => 17:45:58.384285
[0m17:45:58.384903 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m17:45:58.385817 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060b75e0>]}
[0m17:45:58.386487 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.20s]
[0m17:45:58.387090 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m17:45:58.387484 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m17:45:58.387963 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m17:45:58.388576 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m17:45:58.389036 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m17:45:58.392270 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m17:45:58.394354 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 17:45:58.389322 => 17:45:58.394194
[0m17:45:58.394688 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m17:45:58.397913 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m17:45:58.398852 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:45:58.399155 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m17:45:58.399432 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:45:58.497176 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:45:58.497817 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:45:58.498305 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m17:45:58.510252 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:45:58.514029 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:45:58.514450 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m17:45:58.523272 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:58.526585 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:45:58.527008 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m17:45:58.538086 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:58.539970 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m17:45:58.540373 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:45:58.540719 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m17:45:58.550265 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:45:58.552884 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m17:45:58.553298 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m17:45:58.566540 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:45:58.568361 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 17:45:58.394919 => 17:45:58.568129
[0m17:45:58.568836 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m17:45:58.569807 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062185e0>]}
[0m17:45:58.570483 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.18s]
[0m17:45:58.571131 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m17:45:58.571589 [debug] [Thread-4 (]: Began running node model.bde.stg_fact
[0m17:45:58.572355 [info ] [Thread-4 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m17:45:58.573194 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_fact)
[0m17:45:58.573625 [debug] [Thread-4 (]: Began compiling node model.bde.stg_fact
[0m17:45:58.577369 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m17:45:58.579846 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (compile): 17:45:58.573932 => 17:45:58.579663
[0m17:45:58.580269 [debug] [Thread-4 (]: Began executing node model.bde.stg_fact
[0m17:45:58.583993 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m17:45:58.584795 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:45:58.585080 [debug] [Thread-4 (]: On model.bde.stg_fact: BEGIN
[0m17:45:58.585339 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:45:58.699677 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:45:58.701131 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:45:58.702292 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        LISTING_NEIGHBOURHOOD,
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m17:45:58.720394 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:45:58.728009 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:45:58.728841 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m17:45:58.739807 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:58.789227 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:45:58.789723 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m17:45:58.799345 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:58.800591 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m17:45:58.800893 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:45:58.801124 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m17:45:58.811027 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:45:58.812754 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m17:45:58.813014 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m17:45:58.823746 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:45:58.824624 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (execute): 17:45:58.580529 => 17:45:58.824509
[0m17:45:58.824873 [debug] [Thread-4 (]: On model.bde.stg_fact: Close
[0m17:45:58.825456 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10625fee0>]}
[0m17:45:58.825857 [info ] [Thread-4 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.25s]
[0m17:45:58.826240 [debug] [Thread-4 (]: Finished running node model.bde.stg_fact
[0m17:45:58.826510 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m17:45:58.826914 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m17:45:58.827320 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_host)
[0m17:45:58.827548 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m17:45:58.829798 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m17:45:58.831577 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 17:45:58.827714 => 17:45:58.831466
[0m17:45:58.831802 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m17:45:58.834281 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m17:45:58.834761 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:45:58.834992 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m17:45:58.835208 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:45:58.941735 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:45:58.942297 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:45:58.942839 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m17:45:58.958638 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:45:58.962342 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:45:58.962754 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m17:45:58.972059 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:58.974953 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:45:58.975352 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m17:45:58.985147 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:58.986781 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m17:45:58.987174 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:45:58.987516 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m17:45:58.997810 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:45:59.000568 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m17:45:59.000954 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m17:45:59.012016 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:45:59.013420 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 17:45:58.831954 => 17:45:59.013244
[0m17:45:59.013827 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m17:45:59.014718 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10626ca90>]}
[0m17:45:59.015365 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.19s]
[0m17:45:59.015986 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m17:45:59.016450 [debug] [Thread-4 (]: Began running node model.bde.stg_property
[0m17:45:59.017081 [info ] [Thread-4 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m17:45:59.017772 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_property)
[0m17:45:59.018159 [debug] [Thread-4 (]: Began compiling node model.bde.stg_property
[0m17:45:59.021417 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_property"
[0m17:45:59.023666 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (compile): 17:45:59.018424 => 17:45:59.023486
[0m17:45:59.024018 [debug] [Thread-4 (]: Began executing node model.bde.stg_property
[0m17:45:59.028806 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_property"
[0m17:45:59.029345 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:45:59.029622 [debug] [Thread-4 (]: On model.bde.stg_property: BEGIN
[0m17:45:59.029889 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:45:59.133920 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:45:59.134522 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:45:59.134975 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m17:45:59.149093 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:45:59.153444 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:45:59.153920 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m17:45:59.166321 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:59.169504 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:45:59.169913 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m17:45:59.180584 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:59.182602 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m17:45:59.183107 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:45:59.183477 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m17:45:59.195023 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:45:59.198334 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m17:45:59.198746 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m17:45:59.213466 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:45:59.215104 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (execute): 17:45:59.024246 => 17:45:59.214917
[0m17:45:59.215483 [debug] [Thread-4 (]: On model.bde.stg_property: Close
[0m17:45:59.216411 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10614a320>]}
[0m17:45:59.217039 [info ] [Thread-4 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.20s]
[0m17:45:59.217582 [debug] [Thread-4 (]: Finished running node model.bde.stg_property
[0m17:45:59.218011 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m17:45:59.218571 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m17:45:59.219436 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_room)
[0m17:45:59.219914 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m17:45:59.223352 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m17:45:59.224394 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 17:45:59.220173 => 17:45:59.224217
[0m17:45:59.224726 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m17:45:59.228548 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m17:45:59.229681 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:45:59.230018 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m17:45:59.230298 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:45:59.335899 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:45:59.336571 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:45:59.336974 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m17:45:59.350183 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:45:59.353313 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:45:59.353641 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m17:45:59.362842 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:59.365156 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:45:59.365453 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m17:45:59.374891 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:59.376553 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m17:45:59.376899 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:45:59.377181 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m17:45:59.387721 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:45:59.390035 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m17:45:59.390370 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m17:45:59.401825 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:45:59.404667 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 17:45:59.224932 => 17:45:59.404495
[0m17:45:59.405027 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m17:45:59.405767 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10602be80>]}
[0m17:45:59.406323 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.19s]
[0m17:45:59.406797 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m17:45:59.407104 [debug] [Thread-4 (]: Began running node model.bde.stg_suburb
[0m17:45:59.407557 [info ] [Thread-4 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m17:45:59.408057 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.stg_suburb)
[0m17:45:59.408338 [debug] [Thread-4 (]: Began compiling node model.bde.stg_suburb
[0m17:45:59.410547 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m17:45:59.411249 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (compile): 17:45:59.408530 => 17:45:59.411123
[0m17:45:59.411533 [debug] [Thread-4 (]: Began executing node model.bde.stg_suburb
[0m17:45:59.414223 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m17:45:59.414659 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:45:59.414887 [debug] [Thread-4 (]: On model.bde.stg_suburb: BEGIN
[0m17:45:59.415106 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:45:59.543676 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:45:59.544344 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:45:59.544752 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m17:45:59.559047 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m17:45:59.562437 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:45:59.562905 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m17:45:59.572282 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:59.574914 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:45:59.575218 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m17:45:59.584741 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:59.586143 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m17:45:59.586475 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:45:59.586707 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m17:45:59.596861 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:45:59.598647 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m17:45:59.598903 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m17:45:59.610865 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m17:45:59.612079 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (execute): 17:45:59.411715 => 17:45:59.611956
[0m17:45:59.612364 [debug] [Thread-4 (]: On model.bde.stg_suburb: Close
[0m17:45:59.613043 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060e0850>]}
[0m17:45:59.613430 [info ] [Thread-4 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.21s]
[0m17:45:59.613793 [debug] [Thread-4 (]: Finished running node model.bde.stg_suburb
[0m17:45:59.614083 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m17:45:59.614619 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m17:45:59.615063 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.dim_LGA)
[0m17:45:59.615273 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m17:45:59.617148 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m17:45:59.619163 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 17:45:59.615412 => 17:45:59.618985
[0m17:45:59.619455 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m17:45:59.622143 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m17:45:59.622806 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:45:59.623066 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m17:45:59.623254 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:45:59.771705 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:45:59.772388 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:45:59.772771 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m17:45:59.787964 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m17:45:59.791441 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:45:59.791844 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m17:45:59.800715 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:59.805493 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:45:59.805871 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m17:45:59.814667 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:59.819516 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m17:45:59.819863 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:45:59.820144 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m17:45:59.831595 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:45:59.835527 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m17:45:59.835838 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m17:45:59.862161 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:45:59.863370 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 17:45:59.619622 => 17:45:59.863222
[0m17:45:59.863682 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m17:45:59.864372 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106192ce0>]}
[0m17:45:59.864804 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.25s]
[0m17:45:59.865223 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m17:45:59.865518 [debug] [Thread-4 (]: Began running node model.bde.fact_G01
[0m17:45:59.865890 [info ] [Thread-4 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m17:45:59.866405 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G01)
[0m17:45:59.866676 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G01
[0m17:45:59.868960 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m17:45:59.870433 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (compile): 17:45:59.866855 => 17:45:59.870314
[0m17:45:59.870686 [debug] [Thread-4 (]: Began executing node model.bde.fact_G01
[0m17:45:59.873452 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m17:45:59.873909 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:45:59.874144 [debug] [Thread-4 (]: On model.bde.fact_G01: BEGIN
[0m17:45:59.874362 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:45:59.951732 [debug] [Thread-1 (]: SQL status: SELECT 217 in 2.0 seconds
[0m17:45:59.954747 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:45:59.955081 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m17:45:59.979239 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:59.981996 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:45:59.982350 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m17:45:59.992487 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:45:59.993944 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m17:45:59.994225 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:45:59.994475 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m17:46:00.004745 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:46:00.006577 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m17:46:00.006844 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m17:46:00.012168 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:46:00.012501 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:46:00.012757 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m17:46:00.021466 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:46:00.022353 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 17:45:57.907698 => 17:46:00.022251
[0m17:46:00.022588 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m17:46:00.023122 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060b1ab0>]}
[0m17:46:00.023416 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 217[0m in 2.14s]
[0m17:46:00.023742 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m17:46:00.024008 [debug] [Thread-1 (]: Began running node model.bde.fact_G02
[0m17:46:00.024392 [info ] [Thread-1 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m17:46:00.024889 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.fact_G02)
[0m17:46:00.025152 [debug] [Thread-1 (]: Began compiling node model.bde.fact_G02
[0m17:46:00.027245 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m17:46:00.027764 [debug] [Thread-1 (]: Timing info for model.bde.fact_G02 (compile): 17:46:00.025319 => 17:46:00.027664
[0m17:46:00.027992 [debug] [Thread-1 (]: Began executing node model.bde.fact_G02
[0m17:46:00.031377 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m17:46:00.031785 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m17:46:00.032003 [debug] [Thread-1 (]: On model.bde.fact_G02: BEGIN
[0m17:46:00.032199 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:46:00.039225 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m17:46:00.040926 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:46:00.041175 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m17:46:00.050791 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:00.052499 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:46:00.052727 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m17:46:00.062146 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:00.063308 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m17:46:00.063532 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:46:00.063731 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m17:46:00.076201 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:46:00.077811 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m17:46:00.078055 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m17:46:00.091742 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:46:00.092711 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (execute): 17:45:59.870859 => 17:46:00.092591
[0m17:46:00.092965 [debug] [Thread-4 (]: On model.bde.fact_G01: Close
[0m17:46:00.093536 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106218a00>]}
[0m17:46:00.093949 [info ] [Thread-4 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.23s]
[0m17:46:00.094338 [debug] [Thread-4 (]: Finished running node model.bde.fact_G01
[0m17:46:00.094626 [debug] [Thread-4 (]: Began running node model.bde.fact_listing
[0m17:46:00.095004 [info ] [Thread-4 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m17:46:00.095479 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_listing)
[0m17:46:00.095733 [debug] [Thread-4 (]: Began compiling node model.bde.fact_listing
[0m17:46:00.097910 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m17:46:00.099221 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (compile): 17:46:00.095911 => 17:46:00.099105
[0m17:46:00.099452 [debug] [Thread-4 (]: Began executing node model.bde.fact_listing
[0m17:46:00.101989 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m17:46:00.102398 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m17:46:00.102621 [debug] [Thread-4 (]: On model.bde.fact_listing: BEGIN
[0m17:46:00.102825 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:46:00.144253 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:46:00.144771 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m17:46:00.145036 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m17:46:00.165091 [debug] [Thread-1 (]: SQL status: SELECT 129 in 0.0 seconds
[0m17:46:00.167930 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m17:46:00.168284 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m17:46:00.184545 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:00.186827 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m17:46:00.187107 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m17:46:00.195735 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:00.197035 [debug] [Thread-1 (]: On model.bde.fact_G02: COMMIT
[0m17:46:00.197298 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m17:46:00.197528 [debug] [Thread-1 (]: On model.bde.fact_G02: COMMIT
[0m17:46:00.207294 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:46:00.210960 [debug] [Thread-1 (]: Using postgres connection "model.bde.fact_G02"
[0m17:46:00.211294 [debug] [Thread-1 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m17:46:00.215043 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m17:46:00.215335 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m17:46:00.215659 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    UPPER(LISTING_NEIGHBOURHOOD) as LISTING_NEIGHBOURHOOD,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m17:46:00.225581 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:46:00.226795 [debug] [Thread-1 (]: Timing info for model.bde.fact_G02 (execute): 17:46:00.028150 => 17:46:00.226642
[0m17:46:00.227110 [debug] [Thread-1 (]: On model.bde.fact_G02: Close
[0m17:46:00.227855 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10628a140>]}
[0m17:46:00.228380 [info ] [Thread-1 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.20s]
[0m17:46:00.228840 [debug] [Thread-1 (]: Finished running node model.bde.fact_G02
[0m17:46:00.229186 [debug] [Thread-1 (]: Began running node model.bde.dim_host
[0m17:46:00.229620 [info ] [Thread-1 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m17:46:00.230224 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.dim_host)
[0m17:46:00.230566 [debug] [Thread-1 (]: Began compiling node model.bde.dim_host
[0m17:46:00.233196 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_host"
[0m17:46:00.234891 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (compile): 17:46:00.230800 => 17:46:00.234768
[0m17:46:00.235156 [debug] [Thread-1 (]: Began executing node model.bde.dim_host
[0m17:46:00.238021 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_host"
[0m17:46:00.238757 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:46:00.239021 [debug] [Thread-1 (]: On model.bde.dim_host: BEGIN
[0m17:46:00.239266 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:46:00.340684 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:46:00.341214 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:46:00.341666 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    scraped_date,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m17:46:00.990607 [debug] [Thread-1 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m17:46:00.998396 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:46:00.999179 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m17:46:02.425592 [debug] [Thread-2 (]: SQL status: SELECT 296 in 4.0 seconds
[0m17:46:02.433362 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:46:02.434006 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m17:46:02.444869 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:02.448153 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:46:02.448597 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m17:46:02.457915 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:02.459876 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m17:46:02.460282 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:46:02.460648 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m17:46:02.482283 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m17:46:02.485503 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m17:46:02.486009 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m17:46:02.505911 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:46:02.509219 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 17:45:57.946632 => 17:46:02.508855
[0m17:46:02.509764 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m17:46:02.510922 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106188370>]}
[0m17:46:02.511722 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 4.62s]
[0m17:46:02.512468 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m17:46:02.512980 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m17:46:02.513512 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m17:46:02.514230 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m17:46:02.514639 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m17:46:02.518631 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m17:46:02.521622 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 17:46:02.514911 => 17:46:02.521399
[0m17:46:02.522048 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m17:46:02.527465 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m17:46:02.529164 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:46:02.529469 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m17:46:02.529737 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m17:46:02.627602 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m17:46:02.628333 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:46:02.628903 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m17:46:03.243625 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m17:46:03.251010 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:46:03.251628 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m17:46:03.652993 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 6.0 seconds
[0m17:46:03.660479 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:46:03.661426 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m17:46:03.687353 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:03.690181 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:46:03.690540 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m17:46:03.700071 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:03.701529 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m17:46:03.701812 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:46:03.702038 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m17:46:03.724722 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:03.724992 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 3.0 seconds
[0m17:46:03.726759 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:46:03.726984 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m17:46:03.728605 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:46:03.728844 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m17:46:03.730275 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m17:46:03.730531 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m17:46:03.730847 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m17:46:03.739276 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:03.740397 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m17:46:03.740624 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:03.740834 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:46:03.741858 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m17:46:03.742076 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m17:46:03.742273 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:46:03.742506 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m17:46:03.760652 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m17:46:03.760878 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:46:03.762607 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m17:46:03.763495 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 17:45:57.944053 => 17:46:03.763366
[0m17:46:03.763716 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:46:03.763966 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m17:46:03.764233 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m17:46:03.766765 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m17:46:03.767086 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m17:46:03.767547 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062d84f0>]}
[0m17:46:03.767933 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 5.88s]
[0m17:46:03.768294 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m17:46:03.768544 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m17:46:03.768840 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m17:46:03.769232 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m17:46:03.769443 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m17:46:03.771384 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m17:46:03.772090 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 17:46:03.769590 => 17:46:03.771979
[0m17:46:03.772326 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m17:46:03.774721 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m17:46:03.775475 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:46:03.775679 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m17:46:03.775864 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m17:46:03.793173 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:46:03.793423 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:46:03.794347 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (execute): 17:46:00.235338 => 17:46:03.794243
[0m17:46:03.795129 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 17:46:02.522281 => 17:46:03.795031
[0m17:46:03.795376 [debug] [Thread-1 (]: On model.bde.dim_host: Close
[0m17:46:03.795600 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m17:46:03.796165 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10606d2a0>]}
[0m17:46:03.796556 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062a8430>]}
[0m17:46:03.796931 [info ] [Thread-1 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 3.57s]
[0m17:46:03.797346 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 1.28s]
[0m17:46:03.797711 [debug] [Thread-1 (]: Finished running node model.bde.dim_host
[0m17:46:03.798037 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m17:46:03.798292 [debug] [Thread-1 (]: Began running node model.bde.dim_suburb
[0m17:46:03.798650 [info ] [Thread-1 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m17:46:03.799014 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dim_host, now model.bde.dim_suburb)
[0m17:46:03.799215 [debug] [Thread-1 (]: Began compiling node model.bde.dim_suburb
[0m17:46:03.801137 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m17:46:03.802119 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (compile): 17:46:03.799355 => 17:46:03.802014
[0m17:46:03.802325 [debug] [Thread-1 (]: Began executing node model.bde.dim_suburb
[0m17:46:03.804674 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m17:46:03.805424 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:46:03.805639 [debug] [Thread-1 (]: On model.bde.dim_suburb: BEGIN
[0m17:46:03.805834 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:46:03.882475 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m17:46:03.882849 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:46:03.883168 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m17:46:03.935621 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:46:03.936084 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:46:03.936508 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m17:46:03.955728 [debug] [Thread-1 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m17:46:03.959081 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:46:03.959492 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m17:46:03.968956 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:03.971773 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:46:03.972168 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m17:46:03.981668 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:03.983615 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m17:46:03.984033 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:46:03.984406 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m17:46:04.083443 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:46:04.089315 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m17:46:04.090062 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m17:46:04.113989 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:46:04.118548 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (execute): 17:46:03.802463 => 17:46:04.118237
[0m17:46:04.119041 [debug] [Thread-1 (]: On model.bde.dim_suburb: Close
[0m17:46:04.119994 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062a8430>]}
[0m17:46:04.120587 [info ] [Thread-1 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.32s]
[0m17:46:04.121123 [debug] [Thread-1 (]: Finished running node model.bde.dim_suburb
[0m17:46:04.134697 [debug] [Thread-4 (]: SQL status: SELECT 340945 in 4.0 seconds
[0m17:46:04.137828 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m17:46:04.138298 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m17:46:04.147495 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:04.152232 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m17:46:04.152593 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m17:46:04.163097 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:04.164817 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m17:46:04.165159 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m17:46:04.165539 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m17:46:04.168202 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:46:04.168562 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m17:46:04.168907 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m17:46:04.177908 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:04.180251 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:46:04.180594 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m17:46:04.185766 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m17:46:04.189227 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m17:46:04.189670 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m17:46:04.190091 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:46:04.192031 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m17:46:04.192392 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:46:04.192722 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m17:46:04.202897 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m17:46:04.205504 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m17:46:04.205854 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m17:46:04.221129 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:46:04.221467 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:46:04.222732 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 17:46:03.772484 => 17:46:04.222568
[0m17:46:04.223902 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (execute): 17:46:00.099609 => 17:46:04.223756
[0m17:46:04.224257 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m17:46:04.224584 [debug] [Thread-4 (]: On model.bde.fact_listing: Close
[0m17:46:04.225504 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10621b5b0>]}
[0m17:46:04.226101 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a715cf2-0c9b-47df-a96e-2f9d70ac89df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061dfb20>]}
[0m17:46:04.226678 [info ] [Thread-4 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 4.13s]
[0m17:46:04.227218 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.46s]
[0m17:46:04.227867 [debug] [Thread-4 (]: Finished running node model.bde.fact_listing
[0m17:46:04.228416 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m17:46:04.230004 [debug] [MainThread]: Using postgres connection "master"
[0m17:46:04.230305 [debug] [MainThread]: On master: BEGIN
[0m17:46:04.230579 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:46:04.344313 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:46:04.346578 [debug] [MainThread]: On master: COMMIT
[0m17:46:04.347636 [debug] [MainThread]: Using postgres connection "master"
[0m17:46:04.348603 [debug] [MainThread]: On master: COMMIT
[0m17:46:04.358319 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:46:04.358992 [debug] [MainThread]: On master: Close
[0m17:46:04.359978 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:46:04.360346 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m17:46:04.360662 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m17:46:04.360979 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m17:46:04.361281 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m17:46:04.361783 [info ] [MainThread]: 
[0m17:46:04.362196 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 7.02 seconds (7.02s).
[0m17:46:04.364947 [debug] [MainThread]: Command end result
[0m17:46:04.375585 [info ] [MainThread]: 
[0m17:46:04.376013 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:46:04.376298 [info ] [MainThread]: 
[0m17:46:04.376576 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m17:46:04.377200 [debug] [MainThread]: Command `dbt run` succeeded at 17:46:04.377119 after 7.19 seconds
[0m17:46:04.377560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103711810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106193a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061ee2f0>]}
[0m17:46:04.377906 [debug] [MainThread]: Flushing usage events
[0m13:44:54.835758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107206500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10915dab0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10915d390>]}


============================== 13:44:54.838446 | 8f916ad8-30c9-490e-8e92-300e9aec67ff ==============================
[0m13:44:54.838446 [info ] [MainThread]: Running with dbt=1.6.6
[0m13:44:54.838897 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'version_check': 'True', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --full-refresh', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:44:54.904634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10915d600>]}
[0m13:44:54.912711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095a5150>]}
[0m13:44:54.913292 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m13:44:54.923017 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m13:44:54.949906 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:44:54.950190 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:44:54.950841 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.median
- models.bde.raw
[0m13:44:54.954232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c700d0>]}
[0m13:44:54.962300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b06cb0>]}
[0m13:44:54.962569 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m13:44:54.962758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b040a0>]}
[0m13:44:54.964109 [info ] [MainThread]: 
[0m13:44:54.964483 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:44:54.965363 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m13:44:54.965791 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m13:44:54.971236 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m13:44:54.971626 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m13:44:54.972697 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m13:44:54.972912 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m13:44:54.974124 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m13:44:54.974304 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m13:44:54.974468 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:44:54.974684 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m13:44:54.974896 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:44:54.975945 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:44:55.214098 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m13:44:55.214554 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m13:44:55.216111 [debug] [ThreadPool]: On list_postgres: Close
[0m13:44:55.216970 [debug] [ThreadPool]: On list_postgres: Close
[0m13:44:55.217219 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m13:44:55.218253 [debug] [ThreadPool]: On list_postgres: Close
[0m13:44:55.220796 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_staging)
[0m13:44:55.221446 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m13:44:55.225935 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m13:44:55.226388 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m13:44:55.226979 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_warehouse'
[0m13:44:55.228187 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m13:44:55.228441 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m13:44:55.229560 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m13:44:55.230677 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m13:44:55.230857 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m13:44:55.231029 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:44:55.231192 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m13:44:55.231367 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m13:44:55.231537 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:44:55.231842 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:44:55.232056 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:44:55.349294 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:44:55.349755 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m13:44:55.350016 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m13:44:55.351467 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:44:55.351691 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m13:44:55.351925 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m13:44:55.353567 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:44:55.353801 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m13:44:55.354028 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m13:44:55.373162 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m13:44:55.374336 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m13:44:55.374620 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m13:44:55.375622 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m13:44:55.376465 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m13:44:55.377295 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m13:44:55.383829 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m13:44:55.384492 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m13:44:55.385562 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m13:44:55.427580 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:44:55.427887 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m13:44:55.428178 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m13:44:55.443165 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m13:44:55.444330 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m13:44:55.460032 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m13:44:55.466232 [debug] [MainThread]: Using postgres connection "master"
[0m13:44:55.466576 [debug] [MainThread]: On master: BEGIN
[0m13:44:55.466845 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:44:55.573195 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:44:55.573873 [debug] [MainThread]: Using postgres connection "master"
[0m13:44:55.574416 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:44:55.598662 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m13:44:55.602433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b06260>]}
[0m13:44:55.603180 [debug] [MainThread]: On master: ROLLBACK
[0m13:44:55.613467 [debug] [MainThread]: Using postgres connection "master"
[0m13:44:55.614171 [debug] [MainThread]: On master: BEGIN
[0m13:44:55.633631 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:44:55.634171 [debug] [MainThread]: On master: COMMIT
[0m13:44:55.634599 [debug] [MainThread]: Using postgres connection "master"
[0m13:44:55.634943 [debug] [MainThread]: On master: COMMIT
[0m13:44:55.643661 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:44:55.644149 [debug] [MainThread]: On master: Close
[0m13:44:55.645209 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:44:55.645657 [info ] [MainThread]: 
[0m13:44:55.650428 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m13:44:55.650941 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m13:44:55.651438 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m13:44:55.651912 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m13:44:55.652475 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m13:44:55.653039 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m13:44:55.653497 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m13:44:55.653907 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m13:44:55.654573 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.dm_host_neighbourhod)
[0m13:44:55.655105 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_listing_neighbourhood)
[0m13:44:55.655619 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_property_type)
[0m13:44:55.656123 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.stg_G01)
[0m13:44:55.656471 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m13:44:55.656793 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m13:44:55.657129 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m13:44:55.657528 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m13:44:55.665216 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m13:44:55.667697 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m13:44:55.671052 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m13:44:55.673442 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m13:44:55.675072 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 13:44:55.671280 => 13:44:55.674866
[0m13:44:55.675420 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 13:44:55.657827 => 13:44:55.675285
[0m13:44:55.675791 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m13:44:55.676188 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 13:44:55.667944 => 13:44:55.676054
[0m13:44:55.676482 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m13:44:55.676784 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 13:44:55.665473 => 13:44:55.676653
[0m13:44:55.698664 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m13:44:55.698938 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m13:44:55.712206 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m13:44:55.712545 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m13:44:55.714842 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m13:44:55.715231 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m13:44:55.717533 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m13:44:55.717928 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m13:44:55.718250 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m13:44:55.718607 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:44:55.718843 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m13:44:55.719149 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m13:44:55.719342 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m13:44:55.719623 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m13:44:55.719813 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:44:55.720013 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m13:44:55.720208 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m13:44:55.720439 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:44:55.818293 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:55.818619 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:55.818924 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m13:44:55.819152 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m13:44:55.819584 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type

-- Set the configuration for the materialized view



-- Create a Common Table Expression (CTE) called sorted_listing
-- This CTE retrieves data from multiple tables and calculates various metrics
-- It includes property_type, room_type, accommodates, and more.


WITH sorted_listing AS (
    SELECT 
        prop.property_type,-- Property type
        room.room_type,-- Room type
        list.accommodates,-- Accommodates
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year, -- Truncate the date to the month
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id, -- Host ID
        host.host_is_superhost,-- Host is superhost flag
        review_scores_rating,-- Review scores rating
        availability_30-- Availability for the next 30 days
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
-- Select the aggregated metrics for the property_type, room_type, accommodates, and month_year
SELECT 
    property_type,-- Property type
    room_type,-- Room type
    accommodates,-- Number of accommodates
    month_year,-- Truncated month and year
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,-- Calculate the minimum price for active listings
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,-- Calculate the maximum price for active listings
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing, -- Calculate the median price for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts, -- Count the number of distinct hosts
     -- Calculate the superhost rate
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
     -- Calculate the average review scores rating for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


     -- Calculate the percentage change for active listing
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing

    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m13:44:55.820000 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:55.820394 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m13:44:55.820808 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m13:44:55.821244 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,     
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m13:44:55.826569 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:55.826805 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m13:44:55.827130 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    -- Set the configuration for the materialized view


-- Create a Common Table Expression (CTE) called host_neighbourhood_lga_transform
-- This CTE retrieves data from the dim_host and dim_suburb tables and transforms it.
-- It includes host data, host neighborhood's local government area, and month_year.

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM warehouse.dim_host host
    LEFT JOIN warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
-- Create a CTE called distinct_host_count
-- This CTE calculates the number of distinct hosts for each host_neighbourhood_lga and month_year.
distinct_host_count AS (
    SELECT
        TO_CHAR(ht.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        COUNT(DISTINCT ht.host_id) AS num_distinct_hosts
    FROM host_neighbourhood_lga_transform ht
    GROUP BY TO_CHAR(ht.scraped_date, 'MM/YYYY'),ht.host_neighbourhood_lga
),
-- Create a CTE called estimated_revenue
-- This CTE calculates the total estimated revenue for each host_neighbourhood_lga and month_year.
estimated_revenue AS (
    SELECT
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        SUM((30 - list.availability_30) * list.price) AS total_estimated_revenue
    FROM warehouse.fact_listing list
    LEFT JOIN host_neighbourhood_lga_transform ht ON list.surrogate_key_host = ht.surrogate_key_host
    WHERE list.has_availability = 't'
    GROUP BY
        TO_CHAR(list.scraped_date, 'MM/YYYY'),
        ht.host_neighbourhood_lga
)
-- Select the aggregated metrics including month_year, host_neighbourhood_lga, number of distinct hosts, total estimated revenue, and estimated revenue per host.
SELECT
    dh.host_neighbourhood_lga,
    dh.month_year,
    dh.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dh.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dh.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM distinct_host_count dh
LEFT JOIN estimated_revenue er ON dh.month_year = er.month_year AND dh.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY dh.host_neighbourhood_lga, dh.month_year
  );
  
[0m13:44:55.858869 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m13:44:55.864606 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m13:44:55.864948 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m13:44:55.876638 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:55.878779 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m13:44:55.879063 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m13:44:55.889483 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:55.900682 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m13:44:55.900965 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m13:44:55.901199 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m13:44:55.913656 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m13:44:55.918897 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m13:44:55.919171 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m13:44:55.931916 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m13:44:55.932873 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 13:44:55.676967 => 13:44:55.932745
[0m13:44:55.933147 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m13:44:55.933782 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cf2110>]}
[0m13:44:55.934236 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.28s]
[0m13:44:55.934666 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m13:44:55.934944 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m13:44:55.935331 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m13:44:55.935817 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m13:44:55.936065 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m13:44:55.938209 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m13:44:55.940030 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 13:44:55.936243 => 13:44:55.939891
[0m13:44:55.940298 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m13:44:55.942798 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m13:44:55.943552 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m13:44:55.943768 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m13:44:55.943971 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:44:56.054558 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:56.055112 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m13:44:56.055636 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m13:44:56.073728 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m13:44:56.077220 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m13:44:56.077628 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m13:44:56.087153 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:56.090187 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m13:44:56.090601 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m13:44:56.102919 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:56.104790 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m13:44:56.105197 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m13:44:56.105547 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m13:44:56.115858 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m13:44:56.120612 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m13:44:56.121109 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m13:44:56.133882 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m13:44:56.135614 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 13:44:55.940462 => 13:44:56.135384
[0m13:44:56.136142 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m13:44:56.137211 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d22aa0>]}
[0m13:44:56.137971 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.20s]
[0m13:44:56.138685 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m13:44:56.139131 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m13:44:56.139725 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m13:44:56.140517 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m13:44:56.140934 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m13:44:56.144477 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m13:44:56.147175 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 13:44:56.141214 => 13:44:56.147001
[0m13:44:56.147523 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m13:44:56.151158 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m13:44:56.152317 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m13:44:56.152682 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m13:44:56.152950 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:44:56.298930 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:56.300126 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m13:44:56.300810 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m13:44:56.320839 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m13:44:56.329339 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m13:44:56.330076 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m13:44:56.340133 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:56.343117 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m13:44:56.343528 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m13:44:56.353535 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:56.355578 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m13:44:56.356034 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m13:44:56.356414 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m13:44:56.366701 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m13:44:56.369532 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m13:44:56.369956 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m13:44:56.382932 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m13:44:56.384211 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 13:44:56.147752 => 13:44:56.384056
[0m13:44:56.384565 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m13:44:56.385329 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af352d0>]}
[0m13:44:56.385852 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.25s]
[0m13:44:56.386371 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m13:44:56.386742 [debug] [Thread-4 (]: Began running node model.bde.stg_fact
[0m13:44:56.387290 [info ] [Thread-4 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m13:44:56.387976 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_fact)
[0m13:44:56.388390 [debug] [Thread-4 (]: Began compiling node model.bde.stg_fact
[0m13:44:56.391417 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m13:44:56.393376 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (compile): 13:44:56.388649 => 13:44:56.393239
[0m13:44:56.393657 [debug] [Thread-4 (]: Began executing node model.bde.stg_fact
[0m13:44:56.396727 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m13:44:56.397541 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m13:44:56.397856 [debug] [Thread-4 (]: On model.bde.stg_fact: BEGIN
[0m13:44:56.398131 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:44:56.576536 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:56.576959 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m13:44:56.577327 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        LISTING_NEIGHBOURHOOD,
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m13:44:56.634725 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m13:44:56.637676 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m13:44:56.637965 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m13:44:56.670222 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:56.674284 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m13:44:56.674656 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m13:44:56.683931 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:56.685364 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m13:44:56.685718 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m13:44:56.686049 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m13:44:56.695788 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m13:44:56.697932 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m13:44:56.698255 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m13:44:56.709832 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m13:44:56.711191 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (execute): 13:44:56.393852 => 13:44:56.711022
[0m13:44:56.711558 [debug] [Thread-4 (]: On model.bde.stg_fact: Close
[0m13:44:56.712431 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af5f9d0>]}
[0m13:44:56.712985 [info ] [Thread-4 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.32s]
[0m13:44:56.713507 [debug] [Thread-4 (]: Finished running node model.bde.stg_fact
[0m13:44:56.713912 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m13:44:56.714329 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m13:44:56.715158 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_host)
[0m13:44:56.715582 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m13:44:56.718520 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m13:44:56.720502 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 13:44:56.715853 => 13:44:56.720361
[0m13:44:56.720797 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m13:44:56.724177 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m13:44:56.725031 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m13:44:56.725315 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m13:44:56.725574 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:44:56.977593 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:56.978411 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m13:44:56.979049 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m13:44:56.999900 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m13:44:57.004949 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m13:44:57.005826 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m13:44:57.015289 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:57.019266 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m13:44:57.019758 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m13:44:57.030029 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:57.032048 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m13:44:57.032519 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m13:44:57.032915 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m13:44:57.043076 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m13:44:57.046623 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m13:44:57.047154 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m13:44:57.063921 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m13:44:57.065622 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 13:44:56.720992 => 13:44:57.065419
[0m13:44:57.066066 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m13:44:57.067056 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d42950>]}
[0m13:44:57.067743 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.35s]
[0m13:44:57.068408 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m13:44:57.068891 [debug] [Thread-4 (]: Began running node model.bde.stg_property
[0m13:44:57.069587 [info ] [Thread-4 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m13:44:57.070400 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_property)
[0m13:44:57.070844 [debug] [Thread-4 (]: Began compiling node model.bde.stg_property
[0m13:44:57.073586 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_property"
[0m13:44:57.074903 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (compile): 13:44:57.071155 => 13:44:57.074786
[0m13:44:57.075122 [debug] [Thread-4 (]: Began executing node model.bde.stg_property
[0m13:44:57.078080 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_property"
[0m13:44:57.078746 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m13:44:57.079029 [debug] [Thread-4 (]: On model.bde.stg_property: BEGIN
[0m13:44:57.079205 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:44:57.210563 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:57.211817 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m13:44:57.213249 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m13:44:57.227877 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m13:44:57.285564 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m13:44:57.285978 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m13:44:57.295507 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:57.298247 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m13:44:57.298538 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m13:44:57.308529 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:57.309702 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m13:44:57.309936 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m13:44:57.310124 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m13:44:57.321278 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m13:44:57.322997 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m13:44:57.323246 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m13:44:57.333955 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m13:44:57.335428 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (execute): 13:44:57.075268 => 13:44:57.335321
[0m13:44:57.335678 [debug] [Thread-4 (]: On model.bde.stg_property: Close
[0m13:44:57.336247 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cbeda0>]}
[0m13:44:57.336598 [info ] [Thread-4 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.27s]
[0m13:44:57.336898 [debug] [Thread-4 (]: Finished running node model.bde.stg_property
[0m13:44:57.337115 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m13:44:57.337325 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m13:44:57.338028 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_room)
[0m13:44:57.338428 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m13:44:57.340323 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m13:44:57.341109 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 13:44:57.338625 => 13:44:57.340935
[0m13:44:57.341394 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m13:44:57.343700 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m13:44:57.344492 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m13:44:57.344752 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m13:44:57.344938 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:44:57.491878 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:57.492446 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m13:44:57.492690 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m13:44:57.507805 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m13:44:57.512730 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m13:44:57.513305 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m13:44:57.523143 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:57.526659 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m13:44:57.527033 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m13:44:57.535597 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:57.537638 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m13:44:57.537925 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m13:44:57.538108 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m13:44:57.547237 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m13:44:57.550171 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m13:44:57.550456 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m13:44:57.561091 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m13:44:57.562803 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 13:44:57.341546 => 13:44:57.562717
[0m13:44:57.563007 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m13:44:57.563477 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af1dd80>]}
[0m13:44:57.563772 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.23s]
[0m13:44:57.564050 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m13:44:57.564253 [debug] [Thread-4 (]: Began running node model.bde.stg_suburb
[0m13:44:57.564728 [info ] [Thread-4 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m13:44:57.565284 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.stg_suburb)
[0m13:44:57.565513 [debug] [Thread-4 (]: Began compiling node model.bde.stg_suburb
[0m13:44:57.567064 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m13:44:57.567484 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (compile): 13:44:57.565671 => 13:44:57.567399
[0m13:44:57.567653 [debug] [Thread-4 (]: Began executing node model.bde.stg_suburb
[0m13:44:57.569451 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m13:44:57.569751 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m13:44:57.569912 [debug] [Thread-4 (]: On model.bde.stg_suburb: BEGIN
[0m13:44:57.570073 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:44:57.679321 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:57.680309 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m13:44:57.680970 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m13:44:57.693216 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m13:44:57.699516 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m13:44:57.699982 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m13:44:57.723257 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:57.728817 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m13:44:57.729395 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m13:44:57.738909 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:57.741171 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m13:44:57.741649 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m13:44:57.742080 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m13:44:57.753544 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m13:44:57.757138 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m13:44:57.757629 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m13:44:57.776944 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m13:44:57.779882 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (execute): 13:44:57.567767 => 13:44:57.779587
[0m13:44:57.780544 [debug] [Thread-4 (]: On model.bde.stg_suburb: Close
[0m13:44:57.781806 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c5be50>]}
[0m13:44:57.782613 [info ] [Thread-4 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.22s]
[0m13:44:57.783335 [debug] [Thread-4 (]: Finished running node model.bde.stg_suburb
[0m13:44:57.783875 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m13:44:57.784795 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m13:44:57.785318 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.dim_LGA)
[0m13:44:57.785611 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m13:44:57.787494 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m13:44:57.788977 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 13:44:57.785785 => 13:44:57.788863
[0m13:44:57.789256 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m13:44:57.791338 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m13:44:57.791691 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m13:44:57.791859 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m13:44:57.792011 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:44:58.020084 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:58.021510 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m13:44:58.021858 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m13:44:58.037440 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m13:44:58.040057 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m13:44:58.040369 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m13:44:58.049768 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:58.053248 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m13:44:58.053523 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m13:44:58.062811 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:58.066678 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m13:44:58.066996 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m13:44:58.067246 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m13:44:58.079074 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m13:44:58.084890 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m13:44:58.085429 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m13:44:58.103184 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:44:58.104976 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 13:44:57.789406 => 13:44:58.104747
[0m13:44:58.105485 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m13:44:58.106590 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cefca0>]}
[0m13:44:58.107388 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.32s]
[0m13:44:58.108073 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m13:44:58.108526 [debug] [Thread-4 (]: Began running node model.bde.fact_G01
[0m13:44:58.109048 [info ] [Thread-4 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m13:44:58.109722 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G01)
[0m13:44:58.110100 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G01
[0m13:44:58.113539 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m13:44:58.115326 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (compile): 13:44:58.110369 => 13:44:58.115146
[0m13:44:58.115729 [debug] [Thread-4 (]: Began executing node model.bde.fact_G01
[0m13:44:58.119594 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m13:44:58.120244 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m13:44:58.120569 [debug] [Thread-4 (]: On model.bde.fact_G01: BEGIN
[0m13:44:58.120886 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:44:58.265921 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:58.267883 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m13:44:58.269115 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m13:44:58.303786 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m13:44:58.310552 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m13:44:58.311281 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m13:44:58.322425 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:58.327210 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m13:44:58.327894 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m13:44:58.337198 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:58.339509 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m13:44:58.339969 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m13:44:58.340360 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m13:44:58.351077 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m13:44:58.353403 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m13:44:58.353718 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m13:44:58.369653 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:44:58.370836 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (execute): 13:44:58.115979 => 13:44:58.370689
[0m13:44:58.371166 [debug] [Thread-4 (]: On model.bde.fact_G01: Close
[0m13:44:58.371965 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cbf0d0>]}
[0m13:44:58.372498 [info ] [Thread-4 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.26s]
[0m13:44:58.372998 [debug] [Thread-4 (]: Finished running node model.bde.fact_G01
[0m13:44:58.373345 [debug] [Thread-4 (]: Began running node model.bde.fact_G02
[0m13:44:58.373827 [info ] [Thread-4 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m13:44:58.374473 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_G02)
[0m13:44:58.374804 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G02
[0m13:44:58.377836 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m13:44:58.378668 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (compile): 13:44:58.375018 => 13:44:58.378524
[0m13:44:58.378972 [debug] [Thread-4 (]: Began executing node model.bde.fact_G02
[0m13:44:58.383605 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m13:44:58.384131 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m13:44:58.384408 [debug] [Thread-4 (]: On model.bde.fact_G02: BEGIN
[0m13:44:58.384663 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:44:58.498763 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:58.500204 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m13:44:58.500871 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m13:44:58.525162 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m13:44:58.532590 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m13:44:58.533388 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m13:44:58.543355 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:58.548074 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m13:44:58.548855 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m13:44:58.557936 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:58.560693 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m13:44:58.561190 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m13:44:58.561635 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m13:44:58.578450 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m13:44:58.580834 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m13:44:58.581135 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m13:44:58.587861 [debug] [Thread-1 (]: SQL status: SELECT 217 in 3.0 seconds
[0m13:44:58.590480 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m13:44:58.590919 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m13:44:58.595856 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:44:58.596809 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (execute): 13:44:58.379178 => 13:44:58.596695
[0m13:44:58.597061 [debug] [Thread-4 (]: On model.bde.fact_G02: Close
[0m13:44:58.597624 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095a7dc0>]}
[0m13:44:58.598020 [info ] [Thread-4 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.22s]
[0m13:44:58.598389 [debug] [Thread-4 (]: Finished running node model.bde.fact_G02
[0m13:44:58.598662 [debug] [Thread-4 (]: Began running node model.bde.fact_listing
[0m13:44:58.599092 [info ] [Thread-4 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m13:44:58.599632 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.fact_listing)
[0m13:44:58.599908 [debug] [Thread-4 (]: Began compiling node model.bde.fact_listing
[0m13:44:58.602316 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m13:44:58.602621 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:58.604793 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m13:44:58.605158 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m13:44:58.605601 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (compile): 13:44:58.600082 => 13:44:58.605459
[0m13:44:58.605876 [debug] [Thread-4 (]: Began executing node model.bde.fact_listing
[0m13:44:58.608505 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m13:44:58.609131 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m13:44:58.609414 [debug] [Thread-4 (]: On model.bde.fact_listing: BEGIN
[0m13:44:58.609625 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:44:58.615072 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:44:58.616286 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m13:44:58.616547 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m13:44:58.616759 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m13:44:58.626634 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:44:58.629583 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m13:44:58.629839 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m13:44:58.648533 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:44:58.649443 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 13:44:55.699130 => 13:44:58.649333
[0m13:44:58.649695 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m13:44:58.650273 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af788b0>]}
[0m13:44:58.650682 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 217[0m in 3.00s]
[0m13:44:58.651060 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m13:44:58.651331 [debug] [Thread-1 (]: Began running node model.bde.dim_host
[0m13:44:58.651698 [info ] [Thread-1 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m13:44:58.652167 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.dim_host)
[0m13:44:58.652410 [debug] [Thread-1 (]: Began compiling node model.bde.dim_host
[0m13:44:58.654498 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_host"
[0m13:44:58.655158 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (compile): 13:44:58.652569 => 13:44:58.655057
[0m13:44:58.655370 [debug] [Thread-1 (]: Began executing node model.bde.dim_host
[0m13:44:58.657872 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_host"
[0m13:44:58.658474 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m13:44:58.658684 [debug] [Thread-1 (]: On model.bde.dim_host: BEGIN
[0m13:44:58.658874 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:44:58.716471 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:58.716853 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m13:44:58.717173 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    UPPER(LISTING_NEIGHBOURHOOD) as LISTING_NEIGHBOURHOOD,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m13:44:58.776244 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:44:58.776642 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m13:44:58.776910 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    scraped_date,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m13:44:59.513598 [debug] [Thread-1 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m13:44:59.518134 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m13:44:59.518817 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m13:45:00.449058 [debug] [Thread-2 (]: SQL status: SELECT 296 in 5.0 seconds
[0m13:45:00.457181 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m13:45:00.458118 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m13:45:00.481105 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:45:00.487093 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m13:45:00.487813 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m13:45:00.497033 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:45:00.500334 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m13:45:00.500981 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m13:45:00.501461 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m13:45:00.529915 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m13:45:00.535621 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m13:45:00.536329 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m13:45:00.567314 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:45:00.572019 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 13:44:55.715423 => 13:45:00.571440
[0m13:45:00.573284 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m13:45:00.575369 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af1c6d0>]}
[0m13:45:00.576884 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 4.92s]
[0m13:45:00.577674 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m13:45:00.578175 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m13:45:00.578667 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m13:45:00.579907 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m13:45:00.580573 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m13:45:00.584344 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m13:45:00.586384 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 13:45:00.580881 => 13:45:00.586194
[0m13:45:00.586750 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m13:45:00.592000 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m13:45:00.592673 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m13:45:00.592982 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m13:45:00.593271 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:45:00.739177 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m13:45:00.742939 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m13:45:00.743773 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m13:45:01.351432 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m13:45:01.359402 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m13:45:01.360281 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m13:45:01.816736 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 6.0 seconds
[0m13:45:01.824313 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m13:45:01.824981 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m13:45:01.836197 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:45:01.839506 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m13:45:01.839894 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m13:45:01.848698 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:45:01.850384 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m13:45:01.850740 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m13:45:01.851048 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m13:45:01.966521 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m13:45:01.967774 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 1.0 seconds
[0m13:45:01.968366 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 2.0 seconds
[0m13:45:01.974116 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m13:45:01.978966 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m13:45:01.982303 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m13:45:01.982772 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m13:45:01.983190 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m13:45:01.983580 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m13:45:01.992943 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:45:01.995003 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m13:45:01.995407 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m13:45:01.995753 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m13:45:01.998558 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:45:02.000312 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m13:45:02.000703 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m13:45:02.001049 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m13:45:02.011081 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m13:45:02.013725 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m13:45:02.014114 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m13:45:02.017634 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:45:02.021716 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m13:45:02.022128 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:45:02.022618 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m13:45:02.024186 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 13:44:55.712804 => 13:45:02.023993
[0m13:45:02.024707 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m13:45:02.025766 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d07b80>]}
[0m13:45:02.026432 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 6.37s]
[0m13:45:02.026971 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m13:45:02.027346 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m13:45:02.027793 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m13:45:02.028408 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m13:45:02.028734 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m13:45:02.031802 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m13:45:02.032793 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 13:45:02.028957 => 13:45:02.032660
[0m13:45:02.033075 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m13:45:02.036933 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m13:45:02.037391 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:45:02.038838 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 13:45:00.586981 => 13:45:02.038704
[0m13:45:02.039221 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m13:45:02.039563 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m13:45:02.039960 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m13:45:02.040641 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afb3f70>]}
[0m13:45:02.041024 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m13:45:02.041594 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 1.46s]
[0m13:45:02.042410 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m13:45:02.042724 [debug] [Thread-2 (]: Began running node model.bde.dim_suburb
[0m13:45:02.043340 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:45:02.043119 [info ] [Thread-2 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m13:45:02.044461 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (execute): 13:44:58.655520 => 13:45:02.044332
[0m13:45:02.044976 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dim_property, now model.bde.dim_suburb)
[0m13:45:02.045271 [debug] [Thread-1 (]: On model.bde.dim_host: Close
[0m13:45:02.045537 [debug] [Thread-2 (]: Began compiling node model.bde.dim_suburb
[0m13:45:02.048016 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m13:45:02.048546 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cca800>]}
[0m13:45:02.049098 [info ] [Thread-1 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 3.40s]
[0m13:45:02.049562 [debug] [Thread-1 (]: Finished running node model.bde.dim_host
[0m13:45:02.050004 [debug] [Thread-2 (]: Timing info for model.bde.dim_suburb (compile): 13:45:02.045758 => 13:45:02.049868
[0m13:45:02.050264 [debug] [Thread-2 (]: Began executing node model.bde.dim_suburb
[0m13:45:02.053056 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m13:45:02.053499 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m13:45:02.053736 [debug] [Thread-2 (]: On model.bde.dim_suburb: BEGIN
[0m13:45:02.053959 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:45:02.152674 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m13:45:02.153232 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m13:45:02.153616 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m13:45:02.169825 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m13:45:02.170248 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m13:45:02.170661 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m13:45:02.193984 [debug] [Thread-2 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m13:45:02.198216 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m13:45:02.198699 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m13:45:02.208983 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:45:02.211899 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m13:45:02.212318 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m13:45:02.235664 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:45:02.237920 [debug] [Thread-2 (]: On model.bde.dim_suburb: COMMIT
[0m13:45:02.238396 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m13:45:02.238820 [debug] [Thread-2 (]: On model.bde.dim_suburb: COMMIT
[0m13:45:02.272914 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m13:45:02.276167 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_suburb"
[0m13:45:02.276553 [debug] [Thread-2 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m13:45:02.299407 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:45:02.300891 [debug] [Thread-2 (]: Timing info for model.bde.dim_suburb (execute): 13:45:02.050463 => 13:45:02.300730
[0m13:45:02.301226 [debug] [Thread-2 (]: On model.bde.dim_suburb: Close
[0m13:45:02.302019 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afeb9d0>]}
[0m13:45:02.302571 [info ] [Thread-2 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.26s]
[0m13:45:02.303062 [debug] [Thread-2 (]: Finished running node model.bde.dim_suburb
[0m13:45:02.423894 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m13:45:02.430603 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m13:45:02.431128 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m13:45:02.441083 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:45:02.446353 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m13:45:02.446778 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m13:45:02.457123 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:45:02.459391 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m13:45:02.459866 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m13:45:02.460229 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m13:45:02.482030 [debug] [Thread-4 (]: SQL status: SELECT 340945 in 4.0 seconds
[0m13:45:02.485706 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m13:45:02.486248 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m13:45:02.496069 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:45:02.499416 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m13:45:02.499893 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m13:45:02.508547 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:45:02.510677 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m13:45:02.511121 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m13:45:02.511533 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m13:45:02.551332 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m13:45:02.554462 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m13:45:02.554847 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m13:45:02.555306 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m13:45:02.557696 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m13:45:02.558158 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m13:45:02.580535 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:45:02.581958 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 13:45:02.033274 => 13:45:02.581788
[0m13:45:02.582320 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m13:45:02.583259 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afde350>]}
[0m13:45:02.583904 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.56s]
[0m13:45:02.584494 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m13:45:02.595977 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:45:02.597297 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (execute): 13:44:58.606042 => 13:45:02.597080
[0m13:45:02.597656 [debug] [Thread-4 (]: On model.bde.fact_listing: Close
[0m13:45:02.598389 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f916ad8-30c9-490e-8e92-300e9aec67ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af4faf0>]}
[0m13:45:02.598992 [info ] [Thread-4 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 4.00s]
[0m13:45:02.599608 [debug] [Thread-4 (]: Finished running node model.bde.fact_listing
[0m13:45:02.601371 [debug] [MainThread]: Using postgres connection "master"
[0m13:45:02.601731 [debug] [MainThread]: On master: BEGIN
[0m13:45:02.602009 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:45:02.712658 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:45:02.713100 [debug] [MainThread]: On master: COMMIT
[0m13:45:02.713345 [debug] [MainThread]: Using postgres connection "master"
[0m13:45:02.713572 [debug] [MainThread]: On master: COMMIT
[0m13:45:02.729869 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:45:02.730224 [debug] [MainThread]: On master: Close
[0m13:45:02.730764 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:45:02.730952 [debug] [MainThread]: Connection 'model.bde.dim_host' was properly closed.
[0m13:45:02.731110 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m13:45:02.731271 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m13:45:02.731416 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m13:45:02.731642 [info ] [MainThread]: 
[0m13:45:02.731873 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 7.77 seconds (7.77s).
[0m13:45:02.733450 [debug] [MainThread]: Command end result
[0m13:45:02.739616 [info ] [MainThread]: 
[0m13:45:02.739903 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:45:02.740115 [info ] [MainThread]: 
[0m13:45:02.740326 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m13:45:02.740704 [debug] [MainThread]: Command `dbt run` succeeded at 13:45:02.740650 after 7.92 seconds
[0m13:45:02.740944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107206500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d38100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d36860>]}
[0m13:45:02.741165 [debug] [MainThread]: Flushing usage events
[0m15:57:41.593934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103385f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052dda80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052dd3c0>]}


============================== 15:57:41.596493 | 0ea38ae4-6db2-48b6-ab0e-0cf7180e276d ==============================
[0m15:57:41.596493 [info ] [MainThread]: Running with dbt=1.6.6
[0m15:57:41.596826 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev', 'log_path': '/Users/yasamanmohammadi/Documents/GitHub/dbt-dev/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m15:57:41.654920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052dd5d0>]}
[0m15:57:41.662397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10571d120>]}
[0m15:57:41.662791 [info ] [MainThread]: Registered adapter: postgres=1.6.6
[0m15:57:41.672406 [debug] [MainThread]: checksum: 546b81fb56652c304d87abd676e84d4737d8a0c6b62160f4a6e79dcddbc842bb, vars: {}, profile: , target: , version: 1.6.6
[0m15:57:41.698447 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m15:57:41.698906 [debug] [MainThread]: Partial parsing: updated file: bde://models/staging/stg_fact.sql
[0m15:57:41.699125 [debug] [MainThread]: Partial parsing: updated file: bde://models/warehouse/fact_listing.sql
[0m15:57:41.722255 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.bde.median
- models.bde.raw
[0m15:57:41.725305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d30d90>]}
[0m15:57:41.732470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b42c80>]}
[0m15:57:41.732755 [info ] [MainThread]: Found 19 models, 3 snapshots, 8 sources, 0 exposures, 0 metrics, 353 macros, 0 groups, 0 semantic models
[0m15:57:41.732937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b42e90>]}
[0m15:57:41.734149 [info ] [MainThread]: 
[0m15:57:41.734574 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:57:41.735594 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m15:57:41.736124 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m15:57:41.736571 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres'
[0m15:57:41.741824 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m15:57:41.742823 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m15:57:41.743734 [debug] [ThreadPool]: Using postgres connection "list_postgres"
[0m15:57:41.743915 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m15:57:41.744084 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m15:57:41.744245 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
[0m15:57:41.744392 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:57:41.744549 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:57:41.744697 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:57:41.955432 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:57:41.956971 [debug] [ThreadPool]: On list_postgres: Close
[0m15:57:41.960901 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:57:41.961727 [debug] [ThreadPool]: On list_postgres: Close
[0m15:57:41.965774 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:57:41.966817 [debug] [ThreadPool]: On list_postgres: Close
[0m15:57:41.968587 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_raw)
[0m15:57:41.969109 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_staging)
[0m15:57:41.973975 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m15:57:41.974412 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_postgres, now list_postgres_datamart)
[0m15:57:41.974893 [debug] [ThreadPool]: Acquiring new postgres connection 'list_postgres_warehouse'
[0m15:57:41.976270 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m15:57:41.976521 [debug] [ThreadPool]: On list_postgres_raw: BEGIN
[0m15:57:41.977680 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m15:57:41.978798 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m15:57:41.979011 [debug] [ThreadPool]: On list_postgres_staging: BEGIN
[0m15:57:41.979201 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:57:41.979392 [debug] [ThreadPool]: On list_postgres_datamart: BEGIN
[0m15:57:41.979573 [debug] [ThreadPool]: On list_postgres_warehouse: BEGIN
[0m15:57:41.979754 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:57:41.980062 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:57:41.980267 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:57:42.089482 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:57:42.089955 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:57:42.090364 [debug] [ThreadPool]: Using postgres connection "list_postgres_staging"
[0m15:57:42.090674 [debug] [ThreadPool]: Using postgres connection "list_postgres_raw"
[0m15:57:42.091015 [debug] [ThreadPool]: On list_postgres_staging: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_staging"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'staging'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'staging'
  
[0m15:57:42.091369 [debug] [ThreadPool]: On list_postgres_raw: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_raw"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'raw'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'raw'
  
[0m15:57:42.093333 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:57:42.093609 [debug] [ThreadPool]: Using postgres connection "list_postgres_warehouse"
[0m15:57:42.093879 [debug] [ThreadPool]: On list_postgres_warehouse: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_warehouse"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'warehouse'
  
[0m15:57:42.098103 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:57:42.098377 [debug] [ThreadPool]: Using postgres connection "list_postgres_datamart"
[0m15:57:42.098628 [debug] [ThreadPool]: On list_postgres_datamart: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "list_postgres_datamart"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'datamart'
    union all
    select
      'postgres' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'datamart'
  
[0m15:57:42.125309 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:57:42.126864 [debug] [ThreadPool]: On list_postgres_raw: ROLLBACK
[0m15:57:42.127917 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:57:42.129186 [debug] [ThreadPool]: On list_postgres_staging: ROLLBACK
[0m15:57:42.134721 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:57:42.135930 [debug] [ThreadPool]: On list_postgres_warehouse: ROLLBACK
[0m15:57:42.136245 [debug] [ThreadPool]: On list_postgres_raw: Close
[0m15:57:42.136575 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m15:57:42.137796 [debug] [ThreadPool]: On list_postgres_datamart: ROLLBACK
[0m15:57:42.138106 [debug] [ThreadPool]: On list_postgres_staging: Close
[0m15:57:42.146317 [debug] [ThreadPool]: On list_postgres_warehouse: Close
[0m15:57:42.147928 [debug] [ThreadPool]: On list_postgres_datamart: Close
[0m15:57:42.153735 [debug] [MainThread]: Using postgres connection "master"
[0m15:57:42.154094 [debug] [MainThread]: On master: BEGIN
[0m15:57:42.154364 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:57:42.256333 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:57:42.257272 [debug] [MainThread]: Using postgres connection "master"
[0m15:57:42.257929 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:57:42.291808 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m15:57:42.297063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d3ff40>]}
[0m15:57:42.297753 [debug] [MainThread]: On master: ROLLBACK
[0m15:57:42.308580 [debug] [MainThread]: Using postgres connection "master"
[0m15:57:42.308998 [debug] [MainThread]: On master: BEGIN
[0m15:57:42.326756 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:57:42.327295 [debug] [MainThread]: On master: COMMIT
[0m15:57:42.327814 [debug] [MainThread]: Using postgres connection "master"
[0m15:57:42.328224 [debug] [MainThread]: On master: COMMIT
[0m15:57:42.336506 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:57:42.336873 [debug] [MainThread]: On master: Close
[0m15:57:42.337683 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:57:42.338023 [info ] [MainThread]: 
[0m15:57:42.341728 [debug] [Thread-1 (]: Began running node model.bde.dm_host_neighbourhod
[0m15:57:42.342124 [debug] [Thread-2 (]: Began running node model.bde.dm_listing_neighbourhood
[0m15:57:42.342504 [debug] [Thread-3 (]: Began running node model.bde.dm_property_type
[0m15:57:42.342854 [debug] [Thread-4 (]: Began running node model.bde.stg_G01
[0m15:57:42.343282 [info ] [Thread-1 (]: 1 of 19 START sql table model datamart.dm_host_neighbourhod .................... [RUN]
[0m15:57:42.343760 [info ] [Thread-2 (]: 2 of 19 START sql table model datamart.dm_listing_neighbourhood ................ [RUN]
[0m15:57:42.344191 [info ] [Thread-3 (]: 3 of 19 START sql table model datamart.dm_property_type ........................ [RUN]
[0m15:57:42.344560 [info ] [Thread-4 (]: 4 of 19 START sql view model staging.stg_G01 ................................... [RUN]
[0m15:57:42.345112 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_postgres_raw, now model.bde.dm_host_neighbourhod)
[0m15:57:42.345590 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_postgres_staging, now model.bde.dm_listing_neighbourhood)
[0m15:57:42.346047 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_postgres_datamart, now model.bde.dm_property_type)
[0m15:57:42.346494 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_postgres_warehouse, now model.bde.stg_G01)
[0m15:57:42.346811 [debug] [Thread-1 (]: Began compiling node model.bde.dm_host_neighbourhod
[0m15:57:42.347119 [debug] [Thread-2 (]: Began compiling node model.bde.dm_listing_neighbourhood
[0m15:57:42.347388 [debug] [Thread-3 (]: Began compiling node model.bde.dm_property_type
[0m15:57:42.347646 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G01
[0m15:57:42.354133 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dm_host_neighbourhod"
[0m15:57:42.356332 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dm_listing_neighbourhood"
[0m15:57:42.358514 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dm_property_type"
[0m15:57:42.362035 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G01"
[0m15:57:42.363544 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (compile): 15:57:42.347857 => 15:57:42.363257
[0m15:57:42.364474 [debug] [Thread-1 (]: Began executing node model.bde.dm_host_neighbourhod
[0m15:57:42.364848 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (compile): 15:57:42.358739 => 15:57:42.364665
[0m15:57:42.365186 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (compile): 15:57:42.356556 => 15:57:42.365022
[0m15:57:42.365485 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (compile): 15:57:42.354383 => 15:57:42.365367
[0m15:57:42.372819 [debug] [Thread-4 (]: Began executing node model.bde.stg_G01
[0m15:57:42.389276 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dm_host_neighbourhod"
[0m15:57:42.389533 [debug] [Thread-3 (]: Began executing node model.bde.dm_property_type
[0m15:57:42.389768 [debug] [Thread-2 (]: Began executing node model.bde.dm_listing_neighbourhood
[0m15:57:42.399441 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G01"
[0m15:57:42.401520 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dm_property_type"
[0m15:57:42.403391 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dm_listing_neighbourhood"
[0m15:57:42.403667 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m15:57:42.404034 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: BEGIN
[0m15:57:42.404246 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m15:57:42.404437 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m15:57:42.404629 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:57:42.404856 [debug] [Thread-3 (]: On model.bde.dm_property_type: BEGIN
[0m15:57:42.405036 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m15:57:42.405213 [debug] [Thread-4 (]: On model.bde.stg_G01: BEGIN
[0m15:57:42.405467 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m15:57:42.405673 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: BEGIN
[0m15:57:42.405877 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:57:42.406121 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m15:57:42.506425 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:42.506778 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m15:57:42.507254 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */

  
    

  create  table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_listing_neighbourhood view
-- Set configuration options for the materialized view

-- Create a common table expression (CTE) named sorted_listing
WITH sorted_listing AS (
    -- Select relevant columns from fact_listing and join with dimension tables
    SELECT 
        prop.listing_neighbourhood,
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,     
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id,
        host.host_is_superhost,
        review_scores_rating,
        availability_30
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
)
-- Select and calculate various metrics from the sorted_listing CTE
SELECT 
    listing_neighbourhood,
    month_year,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts,
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,

    -- Calculate percentage change for active listings
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listings
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY listing_neighbourhood ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
-- Group the results by listing_neighbourhood and month_year
GROUP BY listing_neighbourhood, month_year
  );
  
[0m15:57:42.511198 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:42.511458 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m15:57:42.511879 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */

  create view "postgres"."staging"."stg_G01__dbt_tmp"
    
    
  as (
    -- stg_G01.sql

-- This SQL script is identified as 'stg_G01.sql' and it performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g01_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g01_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

              -- Rename and alias various demographic data columns.
              Tot_P_M AS Total_Population_Male,
              Tot_P_F AS Total_Population_Female,
              Tot_P_P AS Total_Population,
              Age_0_4_yr_M AS Age_0_4_Male,
              Age_0_4_yr_F AS Age_0_4_Female,
              Age_0_4_yr_P AS Age_0_4_Population,
              Age_5_14_yr_M AS Age_5_14_Male,
              Age_5_14_yr_F AS Age_5_14_Female,
              Age_5_14_yr_P AS Age_5_14_Population,
              Age_15_19_yr_M AS Age_15_19_Male,
              Age_15_19_yr_F AS Age_15_19_Female,
              Age_15_19_yr_P AS Age_15_19_Population,
              Age_20_24_yr_M AS Age_20_24_Male,
              Age_20_24_yr_F AS Age_20_24_Female,
              Age_20_24_yr_P AS Age_20_24_Population,
              Age_25_34_yr_M AS Age_25_34_Male,
              Age_25_34_yr_F AS Age_25_34_Female,
              Age_25_34_yr_P AS Age_25_34_Population,
              Age_35_44_yr_M AS Age_35_44_Male,
              Age_35_44_yr_F AS Age_35_44_Female,
              Age_35_44_yr_P AS Age_35_44_Population,
              Age_45_54_yr_M AS Age_45_54_Male,
              Age_45_54_yr_F AS Age_45_54_Female,
              Age_45_54_yr_P AS Age_45_54_Population,
              Age_55_64_yr_M AS Age_55_64_Male,
              Age_55_64_yr_F AS Age_55_64_Female,
              Age_55_64_yr_P AS Age_55_64_Population,
              Age_65_74_yr_M AS Age_65_74_Male,
              Age_65_74_yr_F AS Age_65_74_Female,
              Age_65_74_yr_P AS Age_65_74_Population,
              Age_75_84_yr_M AS Age_75_84_Male,
              Age_75_84_yr_F AS Age_75_84_Female,
              Age_75_84_yr_P AS Age_75_84_Population,
              Age_85ov_M AS Age_85_and_Over_Male,
              Age_85ov_F AS Age_85_and_Over_Female,
              Age_85ov_P AS Age_85_and_Over_Population,
              Australian_citizen_M AS Male_Australian_Citizens,
              Australian_citizen_F AS Female_Australian_Citizens,
              Australian_citizen_P AS Total_Australian_Population,
              Birthplace_Australia_M AS Male_Birthplace_Australia,
              Birthplace_Australia_F AS Female_Birthplace_Australia,
              Birthplace_Australia_P AS Total_Birthplace_Australia_Population,
              Birthplace_Elsewhere_M AS Male_Birthplace_Elsewhere,
              Birthplace_Elsewhere_F AS Female_Birthplace_Elsewhere,
              Birthplace_Elsewhere_P AS Total_Birthplace_Elsewhere_Population
              
              from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m15:57:42.515894 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:42.516147 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m15:57:42.516510 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */

  
    

  create  table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp"
  
  
    as
  
  (
    -- Set the configuration for the materialized view


-- Create a Common Table Expression (CTE) called host_neighbourhood_lga_transform
-- This CTE retrieves data from the dim_host and dim_suburb tables and transforms it.
-- It includes host data, host neighborhood's local government area, and month_year.

WITH host_neighbourhood_lga_transform AS (
    SELECT 
        host.*,
        suburb.Local_Government_Area AS host_neighbourhood_lga,
        TO_CHAR(host.scraped_date, 'MM/YYYY') AS month_year
    FROM warehouse.dim_host host
    LEFT JOIN warehouse.dim_suburb suburb ON host.host_neighbourhood = suburb.Local_Government_Area_SUBURB
),
-- Create a CTE called distinct_host_count
-- This CTE calculates the number of distinct hosts for each host_neighbourhood_lga and month_year.
distinct_host_count AS (
    SELECT
        TO_CHAR(ht.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        COUNT(DISTINCT ht.host_id) AS num_distinct_hosts
    FROM host_neighbourhood_lga_transform ht
    GROUP BY TO_CHAR(ht.scraped_date, 'MM/YYYY'),ht.host_neighbourhood_lga
),
-- Create a CTE called estimated_revenue
-- This CTE calculates the total estimated revenue for each host_neighbourhood_lga and month_year.
estimated_revenue AS (
    SELECT
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year,
        ht.host_neighbourhood_lga,
        SUM((30 - list.availability_30) * list.price) AS total_estimated_revenue
    FROM warehouse.fact_listing list
    LEFT JOIN host_neighbourhood_lga_transform ht ON list.surrogate_key_host = ht.surrogate_key_host
    WHERE list.has_availability = 't'
    GROUP BY
        TO_CHAR(list.scraped_date, 'MM/YYYY'),
        ht.host_neighbourhood_lga
)
-- Select the aggregated metrics including month_year, host_neighbourhood_lga, number of distinct hosts, total estimated revenue, and estimated revenue per host.
SELECT
    dh.host_neighbourhood_lga,
    dh.month_year,
    dh.num_distinct_hosts,
    er.total_estimated_revenue,
    CASE 
        WHEN dh.num_distinct_hosts > 0 THEN ROUND(er.total_estimated_revenue / dh.num_distinct_hosts, 2)
        ELSE 0
    END AS estimated_revenue_per_host
FROM distinct_host_count dh
LEFT JOIN estimated_revenue er ON dh.month_year = er.month_year AND dh.host_neighbourhood_lga = er.host_neighbourhood_lga
ORDER BY dh.host_neighbourhood_lga, dh.month_year
  );
  
[0m15:57:42.524987 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:42.525260 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m15:57:42.525835 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */

  
    

  create  table "postgres"."datamart"."dm_property_type__dbt_tmp"
  
  
    as
  
  (
    -- Datamart dm_property_type

-- Set the configuration for the materialized view



-- Create a Common Table Expression (CTE) called sorted_listing
-- This CTE retrieves data from multiple tables and calculates various metrics
-- It includes property_type, room_type, accommodates, and more.


WITH sorted_listing AS (
    SELECT 
        prop.property_type,-- Property type
        room.room_type,-- Room type
        list.accommodates,-- Accommodates
        TO_CHAR(list.scraped_date, 'MM/YYYY') AS month_year, -- Truncate the date to the month
        list.has_availability, -- Including the has_availability column
        list.listing_id, -- Including the listing_id column
        CASE 
            WHEN list.has_availability = 't' THEN list.price 
            ELSE NULL 
        END AS price,
        host.host_id, -- Host ID
        host.host_is_superhost,-- Host is superhost flag
        review_scores_rating,-- Review scores rating
        availability_30-- Availability for the next 30 days
    FROM warehouse.fact_listing list
    LEFT JOIN warehouse.dim_property prop ON list.surrogate_key_property = prop.surrogate_key_property -- Left join for dim_property
    LEFT JOIN warehouse.dim_host host ON list.surrogate_key_host = host.surrogate_key_host -- Left join for dim_host
    LEFT JOIN warehouse.dim_room room ON list.surrogate_key_room = room.surrogate_key_room -- Left join for dim_room
)
-- Select the aggregated metrics for the property_type, room_type, accommodates, and month_year
SELECT 
    property_type,-- Property type
    room_type,-- Room type
    accommodates,-- Number of accommodates
    month_year,-- Truncated month and year
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) * 1.0 / NULLIF(COUNT(DISTINCT sorted_listing.listing_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS active_listing_rate,
    MIN(CASE WHEN has_availability = 't' THEN price END) AS min_price_active_listing,-- Calculate the minimum price for active listings
    MAX(CASE WHEN has_availability = 't' THEN price END) AS max_price_active_listing,-- Calculate the maximum price for active listings
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price_active_listing, -- Calculate the median price for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN price END), 2
    ) AS avg_price_active_listing,
    COUNT(DISTINCT host_id) AS number_of_distinct_hosts, -- Count the number of distinct hosts
     -- Calculate the superhost rate
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) > 0 THEN (COUNT(DISTINCT CASE WHEN host_is_superhost = '1' THEN host_id END) * 1.0 / NULLIF(COUNT(DISTINCT host_id), 0)) * 100 
            ELSE 0 
        END), 2
    ) AS superhost_rate,
     -- Calculate the average review scores rating for active listings
    ROUND(
        AVG(CASE WHEN has_availability = 't' THEN review_scores_rating END), 2
    ) AS avg_review_scores_rating_active,


     -- Calculate the percentage change for active listing
    ROUND(
        ((COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0 / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100, 2
    ) AS active_listings_percentage_change,
    -- Calculate percentage change for inactive listing
    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) > 0 THEN (((COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END) - LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year)) * 1.0) / NULLIF(LAG(COUNT(DISTINCT CASE WHEN has_availability = 'f' THEN listing_id END)) OVER (PARTITION BY property_type, room_type, accommodates, month_year ORDER BY month_year), 0)) * 100
            ELSE 0
        END), 2
    ) AS inactive_listings_percentage_change,
    -- Calculate the total number of stays
    SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) END) AS number_of_stays,
    -- Calculate the average estimated revenue per active listing

    ROUND(
        (CASE 
            WHEN COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END) > 0 THEN (SUM(CASE WHEN has_availability = 't' THEN (30 - availability_30) * price END) * 1.0 / NULLIF(COUNT(DISTINCT CASE WHEN has_availability = 't' THEN listing_id END), 0))
            ELSE 0
        END), 2
    ) AS avg_estimated_revenue_per_active_listing
FROM sorted_listing
GROUP BY property_type, room_type, accommodates, month_year
  );
  
[0m15:57:42.542628 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:57:42.548712 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m15:57:42.549054 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01" rename to "stg_G01__dbt_backup"
[0m15:57:42.561654 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:42.563922 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m15:57:42.564203 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
alter table "postgres"."staging"."stg_G01__dbt_tmp" rename to "stg_G01"
[0m15:57:42.574478 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:42.586011 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m15:57:42.586294 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m15:57:42.586524 [debug] [Thread-4 (]: On model.bde.stg_G01: COMMIT
[0m15:57:42.598282 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:42.603370 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G01"
[0m15:57:42.603642 [debug] [Thread-4 (]: On model.bde.stg_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G01"} */
drop view if exists "postgres"."staging"."stg_G01__dbt_backup" cascade
[0m15:57:42.619040 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:57:42.620070 [debug] [Thread-4 (]: Timing info for model.bde.stg_G01 (execute): 15:57:42.389924 => 15:57:42.619931
[0m15:57:42.620361 [debug] [Thread-4 (]: On model.bde.stg_G01: Close
[0m15:57:42.621008 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e2b0d0>]}
[0m15:57:42.621448 [info ] [Thread-4 (]: 4 of 19 OK created sql view model staging.stg_G01 .............................. [[32mCREATE VIEW[0m in 0.27s]
[0m15:57:42.621892 [debug] [Thread-4 (]: Finished running node model.bde.stg_G01
[0m15:57:42.622197 [debug] [Thread-4 (]: Began running node model.bde.stg_G02
[0m15:57:42.622574 [info ] [Thread-4 (]: 5 of 19 START sql view model staging.stg_G02 ................................... [RUN]
[0m15:57:42.623028 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G01, now model.bde.stg_G02)
[0m15:57:42.623282 [debug] [Thread-4 (]: Began compiling node model.bde.stg_G02
[0m15:57:42.625439 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_G02"
[0m15:57:42.627075 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (compile): 15:57:42.623457 => 15:57:42.626958
[0m15:57:42.627329 [debug] [Thread-4 (]: Began executing node model.bde.stg_G02
[0m15:57:42.630054 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_G02"
[0m15:57:42.630714 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m15:57:42.630951 [debug] [Thread-4 (]: On model.bde.stg_G02: BEGIN
[0m15:57:42.631169 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:57:42.733502 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:42.733952 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m15:57:42.734420 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */

  create view "postgres"."staging"."stg_G02__dbt_tmp"
    
    
  as (
    -- stg_G02.sql

-- This SQL script is identified as 'stg_G02.sql' and it to performs data transformations on census data for LGA (Local Government Area) in New South Wales, Australia.

-- Begin configuration section with the 'config' block, setting the unique key to 'LGA_CODE_2016' and 
--  this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'census_g02_nsw_lga_2016' source.

with source as (
    select * from "postgres"."raw"."census_g02_nsw_lga_2016"
),

-- Create another CTE named "renamed" to perform data transformations and aliasing of columns.

renamed as (
    select
              cast(substring(LGA_CODE_2016, 4) as int) as LGA_CODE,-- removing 'LGA' in this columns and turn them to int only 

               -- Rename and alias various demographic data columns.

                  Median_age_persons AS Median_Age,
                  Median_mortgage_repay_monthly AS Median_Mortgage_Repayment_Monthly,
                  Median_tot_prsnl_inc_weekly AS Median_Total_Personal_Income_Weekly,
                  Median_rent_weekly AS Median_Rent_Weekly,
                  Median_tot_fam_inc_weekly AS Median_Total_Family_Income_Weekly,
                  Average_num_psns_per_bedroom AS Average_Persons_Per_Bedroom,
                  Median_tot_hhd_inc_weekly AS Median_Total_Household_Income_Weekly,
                  Average_household_size AS Average_Household_Size
                  from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m15:57:42.749426 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:57:42.753086 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m15:57:42.753498 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02" rename to "stg_G02__dbt_backup"
[0m15:57:42.762994 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:42.765891 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m15:57:42.766298 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
alter table "postgres"."staging"."stg_G02__dbt_tmp" rename to "stg_G02"
[0m15:57:42.774719 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:42.776542 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m15:57:42.776960 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m15:57:42.777325 [debug] [Thread-4 (]: On model.bde.stg_G02: COMMIT
[0m15:57:42.787053 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:42.790910 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_G02"
[0m15:57:42.791332 [debug] [Thread-4 (]: On model.bde.stg_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_G02"} */
drop view if exists "postgres"."staging"."stg_G02__dbt_backup" cascade
[0m15:57:42.804525 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:57:42.805879 [debug] [Thread-4 (]: Timing info for model.bde.stg_G02 (execute): 15:57:42.627494 => 15:57:42.805695
[0m15:57:42.806284 [debug] [Thread-4 (]: On model.bde.stg_G02: Close
[0m15:57:42.807144 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d73a00>]}
[0m15:57:42.807770 [info ] [Thread-4 (]: 5 of 19 OK created sql view model staging.stg_G02 .............................. [[32mCREATE VIEW[0m in 0.18s]
[0m15:57:42.808382 [debug] [Thread-4 (]: Finished running node model.bde.stg_G02
[0m15:57:42.808795 [debug] [Thread-4 (]: Began running node model.bde.stg_LGA
[0m15:57:42.809176 [info ] [Thread-4 (]: 6 of 19 START sql view model staging.stg_LGA ................................... [RUN]
[0m15:57:42.809910 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_G02, now model.bde.stg_LGA)
[0m15:57:42.810314 [debug] [Thread-4 (]: Began compiling node model.bde.stg_LGA
[0m15:57:42.813548 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_LGA"
[0m15:57:42.815245 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (compile): 15:57:42.810569 => 15:57:42.814997
[0m15:57:42.815690 [debug] [Thread-4 (]: Began executing node model.bde.stg_LGA
[0m15:57:42.819093 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_LGA"
[0m15:57:42.819697 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m15:57:42.819996 [debug] [Thread-4 (]: On model.bde.stg_LGA: BEGIN
[0m15:57:42.820265 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:57:42.929531 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:42.931036 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m15:57:42.931911 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */

  create view "postgres"."staging"."stg_LGA__dbt_tmp"
    
    
  as (
    -- stg_LGA.sql

-- Configuration section: Set the unique key to 'LGA_CODE' for this data and this SQL script defines a materialized view.



-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'nsw_lga_code' raw source.

with source as (
    select * from "postgres"."raw"."nsw_lga_code"
),

-- Create another CTE named "renamed" to rename and transform columns for clarity.


renamed as (
    select
        -- Rename the 'LGA_CODE' column as 'Local_Government_Area_Code'.
        LGA_CODE as Local_Government_Area_Code,
        -- Convert 'LGA_NAME' to uppercase for consistency,  to match it with other data.
        UPPER(LGA_NAME) as Local_Government_Area
    from source
)

-- Select and return the transformed data from the "renamed" CTE.

select * from renamed
  );
[0m15:57:42.944781 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:57:42.950536 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m15:57:42.951063 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA" rename to "stg_LGA__dbt_backup"
[0m15:57:42.960192 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:42.963758 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m15:57:42.964166 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
alter table "postgres"."staging"."stg_LGA__dbt_tmp" rename to "stg_LGA"
[0m15:57:42.973421 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:42.975278 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m15:57:42.975653 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m15:57:42.975991 [debug] [Thread-4 (]: On model.bde.stg_LGA: COMMIT
[0m15:57:42.985768 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:42.988937 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_LGA"
[0m15:57:42.989409 [debug] [Thread-4 (]: On model.bde.stg_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_LGA"} */
drop view if exists "postgres"."staging"."stg_LGA__dbt_backup" cascade
[0m15:57:43.001874 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:57:43.003502 [debug] [Thread-4 (]: Timing info for model.bde.stg_LGA (execute): 15:57:42.815942 => 15:57:43.003283
[0m15:57:43.003975 [debug] [Thread-4 (]: On model.bde.stg_LGA: Close
[0m15:57:43.005024 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d32620>]}
[0m15:57:43.005783 [info ] [Thread-4 (]: 6 of 19 OK created sql view model staging.stg_LGA .............................. [[32mCREATE VIEW[0m in 0.20s]
[0m15:57:43.006517 [debug] [Thread-4 (]: Finished running node model.bde.stg_LGA
[0m15:57:43.007054 [debug] [Thread-4 (]: Began running node model.bde.stg_fact
[0m15:57:43.007869 [info ] [Thread-4 (]: 7 of 19 START sql view model staging.stg_fact .................................. [RUN]
[0m15:57:43.008708 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_LGA, now model.bde.stg_fact)
[0m15:57:43.009123 [debug] [Thread-4 (]: Began compiling node model.bde.stg_fact
[0m15:57:43.012743 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_fact"
[0m15:57:43.014674 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (compile): 15:57:43.009385 => 15:57:43.014436
[0m15:57:43.015141 [debug] [Thread-4 (]: Began executing node model.bde.stg_fact
[0m15:57:43.019074 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_fact"
[0m15:57:43.020048 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m15:57:43.020429 [debug] [Thread-4 (]: On model.bde.stg_fact: BEGIN
[0m15:57:43.020733 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:57:43.122932 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:43.124122 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m15:57:43.124829 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */

  create view "postgres"."staging"."stg_fact__dbt_tmp"
    
    
  as (
    --stg_fact


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) called "source" by selecting data from a source table named 'listing'.

WITH source AS (
    SELECT * FROM "postgres"."raw"."listing"
), -- Create another CTE named "filter_data" to transform and filter data from the "source" CTE.
filter_data AS (  
    SELECT 
        SCRAPED_DATE,                  -- Extract the scraped date
        LISTING_ID,                   -- Extract the listing ID
        HOST_ID,                      -- Extract the host ID
        PRICE,                        -- Extract the price
        AVAILABILITY_30,              -- Extract the availability for the next 30 days
        has_availability,             -- Extract the availability status
        number_of_reviews,            -- Extract the number of reviews
        accommodates,                -- Extract the accommodation capacity
        CASE WHEN review_scores_rating BETWEEN 0 AND 100 THEN review_scores_rating ELSE NULL END AS review_scores_rating, -- Normalize the review score for rating
        CASE WHEN review_scores_accuracy BETWEEN 0 AND 100 THEN review_scores_accuracy ELSE NULL END AS review_scores_accuracy,  -- Normalize the review score for accuracy
        CASE WHEN review_scores_cleanliness BETWEEN 0 AND 100 THEN review_scores_cleanliness ELSE NULL END AS review_scores_cleanliness, -- Normalize the review score for cleanliness    
        CASE WHEN review_scores_checkin BETWEEN 0 AND 100 THEN review_scores_checkin ELSE NULL END AS review_scores_checkin,  -- Normalize the review score for check-in  
        CASE WHEN review_scores_communication BETWEEN 0 AND 100 THEN review_scores_communication ELSE NULL END AS review_scores_communication, -- Normalize the review score for value
        CASE WHEN review_scores_value BETWEEN 0 AND 100 THEN review_scores_value ELSE NULL END AS review_scores_value
    FROM source            
    

    
)
-- Finally, select all columns from the "filter_data" CTE, which represents the filtered and transformed data.
SELECT *
FROM filter_data
  );
[0m15:57:43.176665 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:57:43.184379 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m15:57:43.185325 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact" rename to "stg_fact__dbt_backup"
[0m15:57:43.195843 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:43.236150 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m15:57:43.236622 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
alter table "postgres"."staging"."stg_fact__dbt_tmp" rename to "stg_fact"
[0m15:57:43.248640 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:43.249893 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m15:57:43.250170 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m15:57:43.250412 [debug] [Thread-4 (]: On model.bde.stg_fact: COMMIT
[0m15:57:43.261639 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:43.263454 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_fact"
[0m15:57:43.263728 [debug] [Thread-4 (]: On model.bde.stg_fact: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_fact"} */
drop view if exists "postgres"."staging"."stg_fact__dbt_backup" cascade
[0m15:57:43.280746 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:57:43.281825 [debug] [Thread-4 (]: Timing info for model.bde.stg_fact (execute): 15:57:43.015435 => 15:57:43.281690
[0m15:57:43.282125 [debug] [Thread-4 (]: On model.bde.stg_fact: Close
[0m15:57:43.282817 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ed74c0>]}
[0m15:57:43.283299 [info ] [Thread-4 (]: 7 of 19 OK created sql view model staging.stg_fact ............................. [[32mCREATE VIEW[0m in 0.27s]
[0m15:57:43.283757 [debug] [Thread-4 (]: Finished running node model.bde.stg_fact
[0m15:57:43.284103 [debug] [Thread-4 (]: Began running node model.bde.stg_host
[0m15:57:43.284559 [info ] [Thread-4 (]: 8 of 19 START sql view model staging.stg_host .................................. [RUN]
[0m15:57:43.285154 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_fact, now model.bde.stg_host)
[0m15:57:43.285459 [debug] [Thread-4 (]: Began compiling node model.bde.stg_host
[0m15:57:43.287907 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_host"
[0m15:57:43.289432 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (compile): 15:57:43.285661 => 15:57:43.289311
[0m15:57:43.289691 [debug] [Thread-4 (]: Began executing node model.bde.stg_host
[0m15:57:43.292974 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_host"
[0m15:57:43.293829 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m15:57:43.294092 [debug] [Thread-4 (]: On model.bde.stg_host: BEGIN
[0m15:57:43.294322 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:57:43.466923 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:43.468925 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m15:57:43.470426 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */

  create view "postgres"."staging"."stg_host__dbt_tmp"
    
    
  as (
    --dim_host.sql

-- This SQL script, 'dim_host.sql,' is designed to create a dimension table for host information, as part of an ELT process.


-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Start by defining a Common Table Expression (CTE) named "source" to retrieve data from the 'host_snapshot' reference.
with source as (
    select * from "postgres"."raw"."host_snapshot"
),

-- Next, create a CTE named "cleaned_host" for data cleaning and transformation.

cleaned_host as ( 
    select 
        HOST_ID,                -- Extract host ID
        scraped_date,           -- Extract scraped date
        HOST_NAME,              -- Extract host name

         -- Convert 'host_since' column to DATE format if it matches the expected pattern (DD/MM/YYYY), otherwise set to NULL.
    
    CASE
        WHEN host_since ~ '^\d{1,2}/\d{1,2}/\d{4}$' THEN TO_DATE(host_since, 'DD/MM/YYYY') --format host_since column to DATE
        ELSE NULL
    END AS host_since_date, 
    
    host_is_superhost, -- Extract superhost status

    -- Convert 'HOST_NEIGHBOURHOOD' to uppercase and set to NULL if it's 'NAN' ( for case-insensitive matching with LGA).

    CASE 
        WHEN UPPER(HOST_NEIGHBOURHOOD) = 'NAN' THEN NULL
        ELSE UPPER(HOST_NEIGHBOURHOOD) --MAKE IT UPPER CASE TO MATCH LGA
    END as HOST_NEIGHBOURHOOD,
    dbt_valid_to,  -- Extract 'dbt_valid_to'
    dbt_valid_from as last_updated_at -- Extract 'dbt_valid_from' as 'last_updated_at'


    from source
    where dbt_valid_to IS NULL -- Filter for current records
)

    -- Finally, select and return the cleaned host data for the dimension table.

select
    HOST_ID,
    scraped_date, 
    HOST_NAME,
    host_since_date,
    host_is_superhost,
    HOST_NEIGHBOURHOOD,
    last_updated_at

 from cleaned_host
  );
[0m15:57:43.490988 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:57:43.497549 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m15:57:43.498419 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host" rename to "stg_host__dbt_backup"
[0m15:57:43.519152 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:43.522568 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m15:57:43.523033 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
alter table "postgres"."staging"."stg_host__dbt_tmp" rename to "stg_host"
[0m15:57:43.533676 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:43.535350 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m15:57:43.535702 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m15:57:43.536004 [debug] [Thread-4 (]: On model.bde.stg_host: COMMIT
[0m15:57:43.546566 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:43.549422 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_host"
[0m15:57:43.549828 [debug] [Thread-4 (]: On model.bde.stg_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_host"} */
drop view if exists "postgres"."staging"."stg_host__dbt_backup" cascade
[0m15:57:43.564550 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:57:43.566025 [debug] [Thread-4 (]: Timing info for model.bde.stg_host (execute): 15:57:43.289874 => 15:57:43.565816
[0m15:57:43.566435 [debug] [Thread-4 (]: On model.bde.stg_host: Close
[0m15:57:43.567415 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e1f730>]}
[0m15:57:43.568092 [info ] [Thread-4 (]: 8 of 19 OK created sql view model staging.stg_host ............................. [[32mCREATE VIEW[0m in 0.28s]
[0m15:57:43.568734 [debug] [Thread-4 (]: Finished running node model.bde.stg_host
[0m15:57:43.569185 [debug] [Thread-4 (]: Began running node model.bde.stg_property
[0m15:57:43.569926 [info ] [Thread-4 (]: 9 of 19 START sql view model staging.stg_property .............................. [RUN]
[0m15:57:43.570769 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_host, now model.bde.stg_property)
[0m15:57:43.571201 [debug] [Thread-4 (]: Began compiling node model.bde.stg_property
[0m15:57:43.574534 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_property"
[0m15:57:43.575526 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (compile): 15:57:43.571488 => 15:57:43.575340
[0m15:57:43.575898 [debug] [Thread-4 (]: Began executing node model.bde.stg_property
[0m15:57:43.580903 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_property"
[0m15:57:43.581500 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m15:57:43.581797 [debug] [Thread-4 (]: On model.bde.stg_property: BEGIN
[0m15:57:43.582084 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:57:43.768442 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:43.770288 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m15:57:43.771703 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */

  create view "postgres"."staging"."stg_property__dbt_tmp"
    
    
  as (
    -- This SQL script appears to define a materialized view configuration and extracts data from a 'property_snapshot' reference.

-- Configuration section: Specifies that this SQL script defines a materialized view.


-- Define a Common Table Expression (CTE) named "source" to retrieve data from the 'property_snapshot' reference.

WITH source AS (
    SELECT * FROM "postgres"."raw"."property_snapshot"
),
-- Create another CTE named "current_data" to filter and transform the data.
current_data AS ( 
    SELECT
        SCRAPED_DATE,                   -- Extract the scraped date
        LISTING_ID,                     -- Extract the listing ID
        PROPERTY_TYPE,                  -- Extract the property type
        UPPER(LISTING_NEIGHBOURHOOD) AS LISTING_NEIGHBOURHOOD,  -- Convert the neighborhood name to uppercase
        dbt_valid_to,                   -- Extract 'dbt_valid_to'
        dbt_valid_from as last_updated_at  -- Extract 'dbt_valid_from' as 'last_updated_at'
    FROM source
    WHERE dbt_valid_to IS NULL --current data
)
-- Select and return specific columns from the "current_data" CTE.
SELECT
    SCRAPED_DATE,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD
FROM current_data
  );
[0m15:57:43.802569 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:57:43.805728 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m15:57:43.806054 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property" rename to "stg_property__dbt_backup"
[0m15:57:43.815816 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:43.817608 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m15:57:43.817823 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
alter table "postgres"."staging"."stg_property__dbt_tmp" rename to "stg_property"
[0m15:57:43.831836 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:43.832969 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m15:57:43.833245 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m15:57:43.833454 [debug] [Thread-4 (]: On model.bde.stg_property: COMMIT
[0m15:57:43.859364 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:43.861318 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_property"
[0m15:57:43.861595 [debug] [Thread-4 (]: On model.bde.stg_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_property"} */
drop view if exists "postgres"."staging"."stg_property__dbt_backup" cascade
[0m15:57:43.874048 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:57:43.874985 [debug] [Thread-4 (]: Timing info for model.bde.stg_property (execute): 15:57:43.576138 => 15:57:43.874862
[0m15:57:43.875254 [debug] [Thread-4 (]: On model.bde.stg_property: Close
[0m15:57:43.875859 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e1f2b0>]}
[0m15:57:43.876335 [info ] [Thread-4 (]: 9 of 19 OK created sql view model staging.stg_property ......................... [[32mCREATE VIEW[0m in 0.31s]
[0m15:57:43.876789 [debug] [Thread-4 (]: Finished running node model.bde.stg_property
[0m15:57:43.877092 [debug] [Thread-4 (]: Began running node model.bde.stg_room
[0m15:57:43.877505 [info ] [Thread-4 (]: 10 of 19 START sql view model staging.stg_room ................................. [RUN]
[0m15:57:43.877957 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_property, now model.bde.stg_room)
[0m15:57:43.878207 [debug] [Thread-4 (]: Began compiling node model.bde.stg_room
[0m15:57:43.880447 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_room"
[0m15:57:43.881948 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (compile): 15:57:43.878381 => 15:57:43.881824
[0m15:57:43.882218 [debug] [Thread-4 (]: Began executing node model.bde.stg_room
[0m15:57:43.884932 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_room"
[0m15:57:43.885564 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m15:57:43.885797 [debug] [Thread-4 (]: On model.bde.stg_room: BEGIN
[0m15:57:43.886017 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:57:44.029708 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:44.030858 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m15:57:44.031520 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */

  create view "postgres"."staging"."stg_room__dbt_tmp"
    
    
  as (
    -- stg_room.sql



with

source  as (

    select * from "postgres"."raw"."room_snapshot"

),

current_record as (
    select
        SCRAPED_DATE,
        LISTING_ID,
        ROOM_TYPE,
        dbt_valid_to,
        dbt_valid_from as last_updated_at
    from source
    where dbt_valid_to IS NULL --when dbt_valid_to is equal to null it means data is still valid
)
select 
        last_updated_at,
        LISTING_ID,
        ROOM_TYPE,
        SCRAPED_DATE
        
from current_record
  );
[0m15:57:44.045882 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:57:44.053183 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m15:57:44.053902 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room" rename to "stg_room__dbt_backup"
[0m15:57:44.066287 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:44.071353 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m15:57:44.071917 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
alter table "postgres"."staging"."stg_room__dbt_tmp" rename to "stg_room"
[0m15:57:44.081901 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:44.084066 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m15:57:44.084586 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m15:57:44.085098 [debug] [Thread-4 (]: On model.bde.stg_room: COMMIT
[0m15:57:44.095707 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:44.098652 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_room"
[0m15:57:44.099049 [debug] [Thread-4 (]: On model.bde.stg_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_room"} */
drop view if exists "postgres"."staging"."stg_room__dbt_backup" cascade
[0m15:57:44.112361 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:57:44.115502 [debug] [Thread-4 (]: Timing info for model.bde.stg_room (execute): 15:57:43.882411 => 15:57:44.115415
[0m15:57:44.115701 [debug] [Thread-4 (]: On model.bde.stg_room: Close
[0m15:57:44.116212 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e6e4a0>]}
[0m15:57:44.116610 [info ] [Thread-4 (]: 10 of 19 OK created sql view model staging.stg_room ............................ [[32mCREATE VIEW[0m in 0.24s]
[0m15:57:44.116926 [debug] [Thread-4 (]: Finished running node model.bde.stg_room
[0m15:57:44.117192 [debug] [Thread-4 (]: Began running node model.bde.stg_suburb
[0m15:57:44.117574 [info ] [Thread-4 (]: 11 of 19 START sql view model staging.stg_suburb ............................... [RUN]
[0m15:57:44.117948 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_room, now model.bde.stg_suburb)
[0m15:57:44.118124 [debug] [Thread-4 (]: Began compiling node model.bde.stg_suburb
[0m15:57:44.120074 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.stg_suburb"
[0m15:57:44.120757 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (compile): 15:57:44.118243 => 15:57:44.120610
[0m15:57:44.121063 [debug] [Thread-4 (]: Began executing node model.bde.stg_suburb
[0m15:57:44.124375 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.stg_suburb"
[0m15:57:44.124992 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m15:57:44.125280 [debug] [Thread-4 (]: On model.bde.stg_suburb: BEGIN
[0m15:57:44.125526 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:57:44.252907 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:44.254049 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m15:57:44.254597 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */

  create view "postgres"."staging"."stg_suburb__dbt_tmp"
    
    
  as (
    -- stg_suburb.sql

with

source as (

    select * from "postgres"."raw"."nsw_lga_suburb"

),

renamed as (

    select
    -- str
    LGA_NAME as Local_Government_Area , --renaming column

    --str
    SUBURB_NAME as Local_Government_Area_SUBURB --renaming column

    from source

)

select * from renamed
  );
[0m15:57:44.269039 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:57:44.275659 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m15:57:44.276354 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb" rename to "stg_suburb__dbt_backup"
[0m15:57:44.287863 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:44.293046 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m15:57:44.293637 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
alter table "postgres"."staging"."stg_suburb__dbt_tmp" rename to "stg_suburb"
[0m15:57:44.303918 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:44.307162 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m15:57:44.308040 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m15:57:44.308687 [debug] [Thread-4 (]: On model.bde.stg_suburb: COMMIT
[0m15:57:44.328867 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:44.331698 [debug] [Thread-4 (]: Using postgres connection "model.bde.stg_suburb"
[0m15:57:44.332072 [debug] [Thread-4 (]: On model.bde.stg_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.stg_suburb"} */
drop view if exists "postgres"."staging"."stg_suburb__dbt_backup" cascade
[0m15:57:44.354549 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:57:44.356357 [debug] [Thread-4 (]: Timing info for model.bde.stg_suburb (execute): 15:57:44.121264 => 15:57:44.356181
[0m15:57:44.356761 [debug] [Thread-4 (]: On model.bde.stg_suburb: Close
[0m15:57:44.357802 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056e78b0>]}
[0m15:57:44.358490 [info ] [Thread-4 (]: 11 of 19 OK created sql view model staging.stg_suburb .......................... [[32mCREATE VIEW[0m in 0.24s]
[0m15:57:44.359106 [debug] [Thread-4 (]: Finished running node model.bde.stg_suburb
[0m15:57:44.359527 [debug] [Thread-4 (]: Began running node model.bde.dim_LGA
[0m15:57:44.360147 [info ] [Thread-4 (]: 12 of 19 START sql table model warehouse.dim_LGA ............................... [RUN]
[0m15:57:44.360749 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.stg_suburb, now model.bde.dim_LGA)
[0m15:57:44.361064 [debug] [Thread-4 (]: Began compiling node model.bde.dim_LGA
[0m15:57:44.363967 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.dim_LGA"
[0m15:57:44.366310 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (compile): 15:57:44.361276 => 15:57:44.366114
[0m15:57:44.366678 [debug] [Thread-4 (]: Began executing node model.bde.dim_LGA
[0m15:57:44.370124 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.dim_LGA"
[0m15:57:44.370685 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m15:57:44.370937 [debug] [Thread-4 (]: On model.bde.dim_LGA: BEGIN
[0m15:57:44.371183 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:57:44.503399 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:44.503933 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m15:57:44.504260 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */

  
    

  create  table "postgres"."warehouse"."dim_LGA__dbt_tmp"
  
  
    as
  
  (
    --dim_LGA.sql


select * from "postgres"."staging"."stg_LGA"
  );
  
[0m15:57:44.531353 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m15:57:44.534443 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m15:57:44.534795 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA" rename to "dim_LGA__dbt_backup"
[0m15:57:44.544989 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:44.548833 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m15:57:44.549149 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
alter table "postgres"."warehouse"."dim_LGA__dbt_tmp" rename to "dim_LGA"
[0m15:57:44.559768 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:44.563920 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m15:57:44.564249 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m15:57:44.564521 [debug] [Thread-4 (]: On model.bde.dim_LGA: COMMIT
[0m15:57:44.576298 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:44.580026 [debug] [Thread-4 (]: Using postgres connection "model.bde.dim_LGA"
[0m15:57:44.580356 [debug] [Thread-4 (]: On model.bde.dim_LGA: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_LGA"} */
drop table if exists "postgres"."warehouse"."dim_LGA__dbt_backup" cascade
[0m15:57:44.597900 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:57:44.599052 [debug] [Thread-4 (]: Timing info for model.bde.dim_LGA (execute): 15:57:44.366896 => 15:57:44.598916
[0m15:57:44.599344 [debug] [Thread-4 (]: On model.bde.dim_LGA: Close
[0m15:57:44.599992 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105dcc3d0>]}
[0m15:57:44.600446 [info ] [Thread-4 (]: 12 of 19 OK created sql table model warehouse.dim_LGA .......................... [[32mSELECT 129[0m in 0.24s]
[0m15:57:44.600868 [debug] [Thread-4 (]: Finished running node model.bde.dim_LGA
[0m15:57:44.601171 [debug] [Thread-4 (]: Began running node model.bde.fact_G01
[0m15:57:44.601566 [info ] [Thread-4 (]: 13 of 19 START sql table model warehouse.fact_G01 .............................. [RUN]
[0m15:57:44.602074 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.dim_LGA, now model.bde.fact_G01)
[0m15:57:44.602360 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G01
[0m15:57:44.604771 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G01"
[0m15:57:44.606401 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (compile): 15:57:44.602551 => 15:57:44.606283
[0m15:57:44.606673 [debug] [Thread-4 (]: Began executing node model.bde.fact_G01
[0m15:57:44.609383 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G01"
[0m15:57:44.609897 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m15:57:44.610159 [debug] [Thread-4 (]: On model.bde.fact_G01: BEGIN
[0m15:57:44.610406 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:57:44.717061 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:44.717542 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m15:57:44.717904 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */

  
    

  create  table "postgres"."warehouse"."fact_G01__dbt_tmp"
  
  
    as
  
  (
    --dim_G01.sql


SELECT
    g1.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G01" g1
JOIN "postgres"."staging"."stg_LGA" lga ON g1.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m15:57:44.747661 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m15:57:44.751332 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m15:57:44.751777 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01" rename to "fact_G01__dbt_backup"
[0m15:57:44.761139 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:44.764081 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m15:57:44.764503 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
alter table "postgres"."warehouse"."fact_G01__dbt_tmp" rename to "fact_G01"
[0m15:57:44.773728 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:44.775837 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m15:57:44.776210 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m15:57:44.776528 [debug] [Thread-4 (]: On model.bde.fact_G01: COMMIT
[0m15:57:44.788734 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:44.791082 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G01"
[0m15:57:44.791440 [debug] [Thread-4 (]: On model.bde.fact_G01: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G01"} */
drop table if exists "postgres"."warehouse"."fact_G01__dbt_backup" cascade
[0m15:57:44.807344 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:57:44.808941 [debug] [Thread-4 (]: Timing info for model.bde.fact_G01 (execute): 15:57:44.606866 => 15:57:44.808732
[0m15:57:44.809427 [debug] [Thread-4 (]: On model.bde.fact_G01: Close
[0m15:57:44.810486 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ea0790>]}
[0m15:57:44.811120 [info ] [Thread-4 (]: 13 of 19 OK created sql table model warehouse.fact_G01 ......................... [[32mSELECT 129[0m in 0.21s]
[0m15:57:44.811749 [debug] [Thread-4 (]: Finished running node model.bde.fact_G01
[0m15:57:44.812519 [debug] [Thread-4 (]: Began running node model.bde.fact_G02
[0m15:57:44.813172 [info ] [Thread-4 (]: 14 of 19 START sql table model warehouse.fact_G02 .............................. [RUN]
[0m15:57:44.813913 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G01, now model.bde.fact_G02)
[0m15:57:44.814267 [debug] [Thread-4 (]: Began compiling node model.bde.fact_G02
[0m15:57:44.817599 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_G02"
[0m15:57:44.818370 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (compile): 15:57:44.814511 => 15:57:44.818200
[0m15:57:44.818686 [debug] [Thread-4 (]: Began executing node model.bde.fact_G02
[0m15:57:44.823413 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_G02"
[0m15:57:44.824012 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m15:57:44.824336 [debug] [Thread-4 (]: On model.bde.fact_G02: BEGIN
[0m15:57:44.824615 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:57:44.954740 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:44.955322 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m15:57:44.955608 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */

  
    

  create  table "postgres"."warehouse"."fact_G02__dbt_tmp"
  
  
    as
  
  (
    --dim_G02.sql


SELECT
    g2.*,
    lga.Local_Government_Area
FROM "postgres"."staging"."stg_G02" g2
JOIN "postgres"."staging"."stg_LGA" lga ON g2.LGA_CODE = lga.Local_Government_Area_Code
  );
  
[0m15:57:44.977404 [debug] [Thread-4 (]: SQL status: SELECT 129 in 0.0 seconds
[0m15:57:44.979888 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m15:57:44.980178 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02" rename to "fact_G02__dbt_backup"
[0m15:57:44.994420 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:44.996541 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m15:57:44.996834 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
alter table "postgres"."warehouse"."fact_G02__dbt_tmp" rename to "fact_G02"
[0m15:57:45.006795 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:45.008236 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m15:57:45.008511 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m15:57:45.008742 [debug] [Thread-4 (]: On model.bde.fact_G02: COMMIT
[0m15:57:45.021163 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:45.023235 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_G02"
[0m15:57:45.023551 [debug] [Thread-4 (]: On model.bde.fact_G02: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_G02"} */
drop table if exists "postgres"."warehouse"."fact_G02__dbt_backup" cascade
[0m15:57:45.049160 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:57:45.050104 [debug] [Thread-4 (]: Timing info for model.bde.fact_G02 (execute): 15:57:44.818902 => 15:57:45.049997
[0m15:57:45.050340 [debug] [Thread-4 (]: On model.bde.fact_G02: Close
[0m15:57:45.050881 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d789a0>]}
[0m15:57:45.051244 [info ] [Thread-4 (]: 14 of 19 OK created sql table model warehouse.fact_G02 ......................... [[32mSELECT 129[0m in 0.24s]
[0m15:57:45.051577 [debug] [Thread-4 (]: Finished running node model.bde.fact_G02
[0m15:57:45.051827 [debug] [Thread-4 (]: Began running node model.bde.fact_listing
[0m15:57:45.052290 [info ] [Thread-4 (]: 15 of 19 START sql table model warehouse.fact_listing .......................... [RUN]
[0m15:57:45.052871 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.bde.fact_G02, now model.bde.fact_listing)
[0m15:57:45.053136 [debug] [Thread-4 (]: Began compiling node model.bde.fact_listing
[0m15:57:45.055360 [debug] [Thread-4 (]: Writing injected SQL for node "model.bde.fact_listing"
[0m15:57:45.055949 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (compile): 15:57:45.053295 => 15:57:45.055824
[0m15:57:45.056171 [debug] [Thread-4 (]: Began executing node model.bde.fact_listing
[0m15:57:45.058833 [debug] [Thread-4 (]: Writing runtime sql for node "model.bde.fact_listing"
[0m15:57:45.059435 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m15:57:45.059664 [debug] [Thread-4 (]: On model.bde.fact_listing: BEGIN
[0m15:57:45.059876 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:57:45.306597 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:45.307297 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m15:57:45.307777 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */

  
    

  create  table "postgres"."warehouse"."fact_listing__dbt_tmp"
  
  
    as
  
  (
    -- listings fact table


SELECT
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    listing_id,
    scraped_date,
    host_id,
    price,
    accommodates,
    has_availability,
    availability_30,
    review_scores_accuracy,
    review_scores_cleanliness,
    review_scores_checkin,
    review_scores_communication,
    review_scores_value,
    number_of_reviews,
    review_scores_rating

FROM "postgres"."staging"."stg_fact"
  );
  
[0m15:57:45.683445 [debug] [Thread-1 (]: SQL status: SELECT 217 in 3.0 seconds
[0m15:57:45.691549 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m15:57:45.692548 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod" rename to "dm_host_neighbourhod__dbt_backup"
[0m15:57:45.702881 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:45.707285 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m15:57:45.707755 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
alter table "postgres"."datamart"."dm_host_neighbourhod__dbt_tmp" rename to "dm_host_neighbourhod"
[0m15:57:45.716541 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:45.718836 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m15:57:45.719294 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m15:57:45.719656 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: COMMIT
[0m15:57:45.758349 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:45.767250 [debug] [Thread-1 (]: Using postgres connection "model.bde.dm_host_neighbourhod"
[0m15:57:45.767832 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_host_neighbourhod"} */
drop table if exists "postgres"."datamart"."dm_host_neighbourhod__dbt_backup" cascade
[0m15:57:45.834358 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:57:45.839169 [debug] [Thread-1 (]: Timing info for model.bde.dm_host_neighbourhod (execute): 15:57:42.365667 => 15:57:45.838612
[0m15:57:45.840422 [debug] [Thread-1 (]: On model.bde.dm_host_neighbourhod: Close
[0m15:57:45.842399 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d49630>]}
[0m15:57:45.843552 [info ] [Thread-1 (]: 1 of 19 OK created sql table model datamart.dm_host_neighbourhod ............... [[32mSELECT 217[0m in 3.50s]
[0m15:57:45.844717 [debug] [Thread-1 (]: Finished running node model.bde.dm_host_neighbourhod
[0m15:57:45.845349 [debug] [Thread-1 (]: Began running node model.bde.dim_host
[0m15:57:45.846216 [info ] [Thread-1 (]: 16 of 19 START sql table model warehouse.dim_host .............................. [RUN]
[0m15:57:45.847377 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dm_host_neighbourhod, now model.bde.dim_host)
[0m15:57:45.847829 [debug] [Thread-1 (]: Began compiling node model.bde.dim_host
[0m15:57:45.851704 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_host"
[0m15:57:45.852677 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (compile): 15:57:45.848133 => 15:57:45.852494
[0m15:57:45.853042 [debug] [Thread-1 (]: Began executing node model.bde.dim_host
[0m15:57:45.856801 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_host"
[0m15:57:45.857432 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m15:57:45.857765 [debug] [Thread-1 (]: On model.bde.dim_host: BEGIN
[0m15:57:45.858196 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:57:45.965894 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:45.966605 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m15:57:45.967064 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */

  
    

  create  table "postgres"."warehouse"."dim_host__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_host"
)

SELECT 
    CONCAT(CAST(host_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_host,
    host_id,
    scraped_date,
    last_updated_at,
    host_name, 
    host_since_date, 
    host_is_superhost, 
    host_neighbourhood

FROM current_data
  );
  
[0m15:57:46.711466 [debug] [Thread-1 (]: SQL status: SELECT 28839 in 1.0 seconds
[0m15:57:46.718012 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m15:57:46.718673 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host" rename to "dim_host__dbt_backup"
[0m15:57:47.936281 [debug] [Thread-2 (]: SQL status: SELECT 296 in 5.0 seconds
[0m15:57:47.944590 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m15:57:47.945366 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood" rename to "dm_listing_neighbourhood__dbt_backup"
[0m15:57:47.957353 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:47.961015 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m15:57:47.961537 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
alter table "postgres"."datamart"."dm_listing_neighbourhood__dbt_tmp" rename to "dm_listing_neighbourhood"
[0m15:57:47.971691 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:47.974250 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m15:57:47.974732 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m15:57:47.975168 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: COMMIT
[0m15:57:47.996610 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:48.001726 [debug] [Thread-2 (]: Using postgres connection "model.bde.dm_listing_neighbourhood"
[0m15:57:48.002308 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_listing_neighbourhood"} */
drop table if exists "postgres"."datamart"."dm_listing_neighbourhood__dbt_backup" cascade
[0m15:57:48.025862 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:57:48.029149 [debug] [Thread-2 (]: Timing info for model.bde.dm_listing_neighbourhood (execute): 15:57:42.401715 => 15:57:48.028809
[0m15:57:48.029928 [debug] [Thread-2 (]: On model.bde.dm_listing_neighbourhood: Close
[0m15:57:48.031679 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ddf5b0>]}
[0m15:57:48.032681 [info ] [Thread-2 (]: 2 of 19 OK created sql table model datamart.dm_listing_neighbourhood ........... [[32mSELECT 296[0m in 5.69s]
[0m15:57:48.033538 [debug] [Thread-2 (]: Finished running node model.bde.dm_listing_neighbourhood
[0m15:57:48.034160 [debug] [Thread-2 (]: Began running node model.bde.dim_property
[0m15:57:48.034932 [info ] [Thread-2 (]: 17 of 19 START sql table model warehouse.dim_property .......................... [RUN]
[0m15:57:48.035970 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.bde.dm_listing_neighbourhood, now model.bde.dim_property)
[0m15:57:48.036522 [debug] [Thread-2 (]: Began compiling node model.bde.dim_property
[0m15:57:48.040898 [debug] [Thread-2 (]: Writing injected SQL for node "model.bde.dim_property"
[0m15:57:48.042140 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (compile): 15:57:48.036873 => 15:57:48.041927
[0m15:57:48.042562 [debug] [Thread-2 (]: Began executing node model.bde.dim_property
[0m15:57:48.048631 [debug] [Thread-2 (]: Writing runtime sql for node "model.bde.dim_property"
[0m15:57:48.049498 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m15:57:48.049845 [debug] [Thread-2 (]: On model.bde.dim_property: BEGIN
[0m15:57:48.050179 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m15:57:48.180515 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:48.182583 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m15:57:48.183330 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */

  
    

  create  table "postgres"."warehouse"."dim_property__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_property"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_property,
    LISTING_ID,
    PROPERTY_TYPE,
    last_updated_at,
    LISTING_NEIGHBOURHOOD

FROM current_data
  );
  
[0m15:57:48.754950 [debug] [Thread-2 (]: SQL status: SELECT 45410 in 1.0 seconds
[0m15:57:48.759715 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m15:57:48.760338 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property" rename to "dim_property__dbt_backup"
[0m15:57:49.386337 [debug] [Thread-4 (]: SQL status: SELECT 340945 in 4.0 seconds
[0m15:57:49.390555 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m15:57:49.390985 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing" rename to "fact_listing__dbt_backup"
[0m15:57:49.394586 [debug] [Thread-3 (]: SQL status: SELECT 1614 in 7.0 seconds
[0m15:57:49.396921 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m15:57:49.397234 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type" rename to "dm_property_type__dbt_backup"
[0m15:57:49.410418 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:49.413074 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m15:57:49.413493 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
alter table "postgres"."datamart"."dm_property_type__dbt_tmp" rename to "dm_property_type"
[0m15:57:49.434733 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:49.436701 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m15:57:49.437075 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m15:57:49.437333 [debug] [Thread-3 (]: On model.bde.dm_property_type: COMMIT
[0m15:57:49.523919 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:49.524504 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:49.524896 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 1.0 seconds
[0m15:57:49.525251 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 3.0 seconds
[0m15:57:49.528603 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m15:57:49.531293 [debug] [Thread-3 (]: Using postgres connection "model.bde.dm_property_type"
[0m15:57:49.533688 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m15:57:49.535921 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m15:57:49.536234 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
alter table "postgres"."warehouse"."fact_listing__dbt_tmp" rename to "fact_listing"
[0m15:57:49.536537 [debug] [Thread-3 (]: On model.bde.dm_property_type: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dm_property_type"} */
drop table if exists "postgres"."datamart"."dm_property_type__dbt_backup" cascade
[0m15:57:49.536832 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
alter table "postgres"."warehouse"."dim_property__dbt_tmp" rename to "dim_property"
[0m15:57:49.537128 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
alter table "postgres"."warehouse"."dim_host__dbt_tmp" rename to "dim_host"
[0m15:57:49.548166 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:49.548623 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:49.548942 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:49.552625 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m15:57:49.554257 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m15:57:49.555744 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m15:57:49.556064 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:57:49.556493 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m15:57:49.556783 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m15:57:49.557055 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m15:57:49.558288 [debug] [Thread-3 (]: Timing info for model.bde.dm_property_type (execute): 15:57:42.399701 => 15:57:49.558147
[0m15:57:49.558572 [debug] [Thread-4 (]: On model.bde.fact_listing: COMMIT
[0m15:57:49.558827 [debug] [Thread-2 (]: On model.bde.dim_property: COMMIT
[0m15:57:49.559126 [debug] [Thread-1 (]: On model.bde.dim_host: COMMIT
[0m15:57:49.559488 [debug] [Thread-3 (]: On model.bde.dm_property_type: Close
[0m15:57:49.560557 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f36110>]}
[0m15:57:49.561068 [info ] [Thread-3 (]: 3 of 19 OK created sql table model datamart.dm_property_type ................... [[32mSELECT 1614[0m in 7.21s]
[0m15:57:49.561471 [debug] [Thread-3 (]: Finished running node model.bde.dm_property_type
[0m15:57:49.561778 [debug] [Thread-3 (]: Began running node model.bde.dim_room
[0m15:57:49.562228 [info ] [Thread-3 (]: 18 of 19 START sql table model warehouse.dim_room .............................. [RUN]
[0m15:57:49.562880 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.bde.dm_property_type, now model.bde.dim_room)
[0m15:57:49.563210 [debug] [Thread-3 (]: Began compiling node model.bde.dim_room
[0m15:57:49.565934 [debug] [Thread-3 (]: Writing injected SQL for node "model.bde.dim_room"
[0m15:57:49.567528 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (compile): 15:57:49.563389 => 15:57:49.567388
[0m15:57:49.567804 [debug] [Thread-3 (]: Began executing node model.bde.dim_room
[0m15:57:49.570586 [debug] [Thread-3 (]: Writing runtime sql for node "model.bde.dim_room"
[0m15:57:49.571104 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m15:57:49.571345 [debug] [Thread-3 (]: On model.bde.dim_room: BEGIN
[0m15:57:49.571558 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m15:57:49.574342 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:49.576013 [debug] [Thread-2 (]: Using postgres connection "model.bde.dim_property"
[0m15:57:49.576263 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:49.576508 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:49.576712 [debug] [Thread-2 (]: On model.bde.dim_property: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_property"} */
drop table if exists "postgres"."warehouse"."dim_property__dbt_backup" cascade
[0m15:57:49.578254 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_host"
[0m15:57:49.579876 [debug] [Thread-4 (]: Using postgres connection "model.bde.fact_listing"
[0m15:57:49.580239 [debug] [Thread-1 (]: On model.bde.dim_host: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_host"} */
drop table if exists "postgres"."warehouse"."dim_host__dbt_backup" cascade
[0m15:57:49.580501 [debug] [Thread-4 (]: On model.bde.fact_listing: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.fact_listing"} */
drop table if exists "postgres"."warehouse"."fact_listing__dbt_backup" cascade
[0m15:57:49.604595 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:57:49.605636 [debug] [Thread-1 (]: Timing info for model.bde.dim_host (execute): 15:57:45.853271 => 15:57:49.605515
[0m15:57:49.605891 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:57:49.606143 [debug] [Thread-1 (]: On model.bde.dim_host: Close
[0m15:57:49.607055 [debug] [Thread-2 (]: Timing info for model.bde.dim_property (execute): 15:57:48.042838 => 15:57:49.606942
[0m15:57:49.607357 [debug] [Thread-2 (]: On model.bde.dim_property: Close
[0m15:57:49.607822 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056e5840>]}
[0m15:57:49.608670 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f1ae30>]}
[0m15:57:49.608285 [info ] [Thread-1 (]: 16 of 19 OK created sql table model warehouse.dim_host ......................... [[32mSELECT 28839[0m in 3.76s]
[0m15:57:49.609098 [info ] [Thread-2 (]: 17 of 19 OK created sql table model warehouse.dim_property ..................... [[32mSELECT 45410[0m in 1.57s]
[0m15:57:49.609490 [debug] [Thread-1 (]: Finished running node model.bde.dim_host
[0m15:57:49.609828 [debug] [Thread-2 (]: Finished running node model.bde.dim_property
[0m15:57:49.610132 [debug] [Thread-1 (]: Began running node model.bde.dim_suburb
[0m15:57:49.610603 [info ] [Thread-1 (]: 19 of 19 START sql table model warehouse.dim_suburb ............................ [RUN]
[0m15:57:49.611106 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.bde.dim_host, now model.bde.dim_suburb)
[0m15:57:49.611359 [debug] [Thread-1 (]: Began compiling node model.bde.dim_suburb
[0m15:57:49.613764 [debug] [Thread-1 (]: Writing injected SQL for node "model.bde.dim_suburb"
[0m15:57:49.614366 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (compile): 15:57:49.611521 => 15:57:49.614249
[0m15:57:49.614596 [debug] [Thread-1 (]: Began executing node model.bde.dim_suburb
[0m15:57:49.617049 [debug] [Thread-1 (]: Writing runtime sql for node "model.bde.dim_suburb"
[0m15:57:49.617457 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m15:57:49.617667 [debug] [Thread-1 (]: On model.bde.dim_suburb: BEGIN
[0m15:57:49.617871 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:57:49.666557 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:57:49.667912 [debug] [Thread-4 (]: Timing info for model.bde.fact_listing (execute): 15:57:45.056322 => 15:57:49.667772
[0m15:57:49.668218 [debug] [Thread-4 (]: On model.bde.fact_listing: Close
[0m15:57:49.668859 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f255d0>]}
[0m15:57:49.669281 [info ] [Thread-4 (]: 15 of 19 OK created sql table model warehouse.fact_listing ..................... [[32mSELECT 340945[0m in 4.62s]
[0m15:57:49.669698 [debug] [Thread-4 (]: Finished running node model.bde.fact_listing
[0m15:57:49.729639 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:49.730131 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m15:57:49.730484 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */

  
    

  create  table "postgres"."warehouse"."dim_room__dbt_tmp"
  
  
    as
  
  (
    -- dim_host table


WITH current_data AS (
    SELECT *

    FROM "postgres"."staging"."stg_room"
)

SELECT 
    CONCAT(CAST(listing_id AS VARCHAR), '_', CAST(scraped_date AS VARCHAR)) as surrogate_key_room,
        last_updated_at,
        ROOM_TYPE

FROM current_data
  );
  
[0m15:57:49.777869 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:57:49.778227 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m15:57:49.778551 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */

  
    

  create  table "postgres"."warehouse"."dim_suburb__dbt_tmp"
  
  
    as
  
  (
    --dim_room.sql


select * from "postgres"."staging"."stg_suburb"
  );
  
[0m15:57:49.798859 [debug] [Thread-1 (]: SQL status: SELECT 4470 in 0.0 seconds
[0m15:57:49.801832 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m15:57:49.802180 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb" rename to "dim_suburb__dbt_backup"
[0m15:57:49.812485 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:49.816586 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m15:57:49.816930 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
alter table "postgres"."warehouse"."dim_suburb__dbt_tmp" rename to "dim_suburb"
[0m15:57:49.826412 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:49.828025 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m15:57:49.828341 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m15:57:49.828609 [debug] [Thread-1 (]: On model.bde.dim_suburb: COMMIT
[0m15:57:49.847289 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:49.849349 [debug] [Thread-1 (]: Using postgres connection "model.bde.dim_suburb"
[0m15:57:49.849651 [debug] [Thread-1 (]: On model.bde.dim_suburb: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_suburb"} */
drop table if exists "postgres"."warehouse"."dim_suburb__dbt_backup" cascade
[0m15:57:49.870913 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:57:49.872141 [debug] [Thread-1 (]: Timing info for model.bde.dim_suburb (execute): 15:57:49.614754 => 15:57:49.871964
[0m15:57:49.872464 [debug] [Thread-1 (]: On model.bde.dim_suburb: Close
[0m15:57:49.873225 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0592a0>]}
[0m15:57:49.873720 [info ] [Thread-1 (]: 19 of 19 OK created sql table model warehouse.dim_suburb ....................... [[32mSELECT 4470[0m in 0.26s]
[0m15:57:49.874194 [debug] [Thread-1 (]: Finished running node model.bde.dim_suburb
[0m15:57:49.895699 [debug] [Thread-3 (]: SQL status: SELECT 45410 in 0.0 seconds
[0m15:57:49.898341 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m15:57:49.898640 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room" rename to "dim_room__dbt_backup"
[0m15:57:49.908502 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:49.910628 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m15:57:49.910989 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
alter table "postgres"."warehouse"."dim_room__dbt_tmp" rename to "dim_room"
[0m15:57:49.920279 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:57:49.921790 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m15:57:49.922096 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m15:57:49.922337 [debug] [Thread-3 (]: On model.bde.dim_room: COMMIT
[0m15:57:49.932860 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m15:57:49.934690 [debug] [Thread-3 (]: Using postgres connection "model.bde.dim_room"
[0m15:57:49.934955 [debug] [Thread-3 (]: On model.bde.dim_room: /* {"app": "dbt", "dbt_version": "1.6.6", "profile_name": "bde", "target_name": "dev", "node_id": "model.bde.dim_room"} */
drop table if exists "postgres"."warehouse"."dim_room__dbt_backup" cascade
[0m15:57:49.951360 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:57:49.952626 [debug] [Thread-3 (]: Timing info for model.bde.dim_room (execute): 15:57:49.567969 => 15:57:49.952478
[0m15:57:49.952980 [debug] [Thread-3 (]: On model.bde.dim_room: Close
[0m15:57:49.953695 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ea38ae4-6db2-48b6-ab0e-0cf7180e276d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d732e0>]}
[0m15:57:49.954165 [info ] [Thread-3 (]: 18 of 19 OK created sql table model warehouse.dim_room ......................... [[32mSELECT 45410[0m in 0.39s]
[0m15:57:49.954601 [debug] [Thread-3 (]: Finished running node model.bde.dim_room
[0m15:57:49.955827 [debug] [MainThread]: Using postgres connection "master"
[0m15:57:49.956173 [debug] [MainThread]: On master: BEGIN
[0m15:57:49.956411 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:57:50.067512 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:57:50.068079 [debug] [MainThread]: On master: COMMIT
[0m15:57:50.068328 [debug] [MainThread]: Using postgres connection "master"
[0m15:57:50.068543 [debug] [MainThread]: On master: COMMIT
[0m15:57:50.078293 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:57:50.078733 [debug] [MainThread]: On master: Close
[0m15:57:50.079479 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:57:50.079681 [debug] [MainThread]: Connection 'model.bde.dim_suburb' was properly closed.
[0m15:57:50.079853 [debug] [MainThread]: Connection 'model.bde.dim_property' was properly closed.
[0m15:57:50.080011 [debug] [MainThread]: Connection 'model.bde.dim_room' was properly closed.
[0m15:57:50.080168 [debug] [MainThread]: Connection 'model.bde.fact_listing' was properly closed.
[0m15:57:50.080458 [info ] [MainThread]: 
[0m15:57:50.080693 [info ] [MainThread]: Finished running 8 view models, 11 table models in 0 hours 0 minutes and 8.35 seconds (8.35s).
[0m15:57:50.082347 [debug] [MainThread]: Command end result
[0m15:57:50.089978 [info ] [MainThread]: 
[0m15:57:50.090314 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:57:50.090525 [info ] [MainThread]: 
[0m15:57:50.090728 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m15:57:50.091170 [debug] [MainThread]: Command `dbt run` succeeded at 15:57:50.091115 after 8.51 seconds
[0m15:57:50.091428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103385f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10571d120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d3ff40>]}
[0m15:57:50.091686 [debug] [MainThread]: Flushing usage events
